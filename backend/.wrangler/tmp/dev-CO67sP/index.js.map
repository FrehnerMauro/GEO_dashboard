{
  "version": 3,
  "sources": ["wrangler-modules-watch:wrangler:modules-watch", "../../../../node_modules/wrangler/templates/modules-watch-stub.js", "../../../../shared/utils/text-extraction.ts", "../../../../shared/persistence/db.ts", "../../../../shared/persistence/index.ts", "../bundle-Ad2mz9/middleware-loader.entry.ts", "../bundle-Ad2mz9/middleware-insertion-facade.js", "../../../src/index.ts", "../../../src/api/router.ts", "../../../src/api/routes/route-definitions.ts", "../../../src/api/middleware/index.ts", "../../../src/api/middleware/cors.ts", "../../../src/api/middleware/error-handler.ts", "../../../src/api/handlers/workflow.ts", "../../../../shared/llm_execution/index.ts", "../../../../shared/config.ts", "../../../../shared/analysis/index.ts", "../../../../shared/analysis/brand_mention.ts", "../../../../shared/analysis/sentiment.ts", "../../../src/api/utils.ts", "../../../src/api/utils/sitemap.ts", "../../../src/api/handlers/analysis.ts", "../../../../shared/engine_workflow.ts", "../../../../shared/ingestion/sitemap.ts", "../../../../shared/ingestion/index.ts", "../../../../shared/ingestion/crawler.ts", "../../../../shared/ingestion/scraper.ts", "../../../../shared/categorization/index.ts", "../../../../shared/prompt_generation/index.ts", "../../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../node_modules/wrangler/templates/middleware/common.ts"],
  "sourceRoot": "/Users/maurofrehner/GitHub/GEO_dashboard/backend/.wrangler/tmp/dev-CO67sP",
  "sourcesContent": ["", "// `esbuild` doesn't support returning `watch*` options from `onStart()`\n// plugin callbacks. Instead, we define an empty virtual module that is\n// imported by this injected file. Importing the module registers watchers.\nimport \"wrangler:modules-watch\";\n", "/**\n * Utility functions for extracting specific sections from text\n */\n\n/**\n * Extrahiert den Abschnitt \"## Empfehlung\" oder \"## Fazit\" aus dem Text\n * \n * @param answerText Der vollst\u00E4ndige Antworttext\n * @returns Der extrahierte Fazit-Abschnitt oder der gesamte Text, falls kein Fazit gefunden wird\n */\nexport function extractConclusion(answerText: string | null): string | null {\n  if (!answerText || answerText.trim().length === 0) {\n    return answerText;\n  }\n\n  // Finde die Position der \"## Empfehlung\" \u00DCberschrift\n  const empfehlungIndex = answerText.search(/##\\s+Empfehlung/im);\n  if (empfehlungIndex !== -1) {\n    // Finde alles nach \"## Empfehlung\\n\" bis zum Ende oder bis zur n\u00E4chsten ## \u00DCberschrift\n    const startIndex = answerText.indexOf('\\n', empfehlungIndex) + 1;\n    const restOfText = answerText.substring(startIndex);\n    \n    // Suche nach der n\u00E4chsten ## \u00DCberschrift\n    const nextHeadingMatch = restOfText.match(/^\\n##\\s+/m);\n    if (nextHeadingMatch && nextHeadingMatch.index !== undefined) {\n      return restOfText.substring(0, nextHeadingMatch.index).trim();\n    } else {\n      // Keine weitere \u00DCberschrift gefunden, nimm alles bis zum Ende\n      return restOfText.trim();\n    }\n  }\n  \n  // Fallback: Suche nach anderen m\u00F6glichen \u00DCberschriften\n  const conclusionPatterns = [\n    /##\\s+Fazit\\s*\\n([\\s\\S]*?)(?=\\n##\\s+|$)/im,\n    /##\\s+Zusammenfassung\\s*\\n([\\s\\S]*?)(?=\\n##\\s+|$)/im,\n    /##\\s+Summary\\s*\\n([\\s\\S]*?)(?=\\n##\\s+|$)/im,\n    /##\\s+Conclusion\\s*\\n([\\s\\S]*?)(?=\\n##\\s+|$)/im,\n    /##\\s+Recommendation\\s*\\n([\\s\\S]*?)(?=\\n##\\s+|$)/im,\n  ];\n\n  for (const pattern of conclusionPatterns) {\n    const match = answerText.match(pattern);\n    if (match && match[1]) {\n      return match[1].trim();\n    }\n  }\n\n  // Fallback: Wenn keine \u00DCberschrift gefunden wird, gib den gesamten Text zur\u00FCck\n  return answerText;\n}\n\n/**\n * Extrahiert Statistiken aus einem Text:\n * - Anzahl Zitierungen (Markdown-Links zur eigenen Marke)\n * - Anzahl Erw\u00E4hnungen (Text-Erw\u00E4hnungen der Marke, au\u00DFerhalb von Citations)\n * - Anzahl andere Links (Links, die nicht zur eigenen Marke geh\u00F6ren)\n * \n * @param text Der Text, aus dem extrahiert werden soll\n * @param brandName Der Markenname (z.B. \"FrehnerTec\")\n * @returns Objekt mit citations, mentions und otherLinks\n */\nexport function extractTextStats(\n  text: string,\n  brandName: string\n): {\n  citations: number;\n  mentions: number;\n  otherLinks: number;\n  citationUrls: string[];\n  otherLinkUrls: string[];\n} {\n  if (!text || text.trim().length === 0) {\n    return {\n      citations: 0,\n      mentions: 0,\n      otherLinks: 0,\n      citationUrls: [],\n      otherLinkUrls: [],\n    };\n  }\n\n  // Performance-Optimierung: Begrenze Text-L\u00E4nge f\u00FCr sehr lange Texte\n  const MAX_TEXT_LENGTH = 50000; // Max 50KB Text verarbeiten\n  const processedText = text.length > MAX_TEXT_LENGTH \n    ? text.substring(0, MAX_TEXT_LENGTH) \n    : text;\n\n  const brandLower = brandName.toLowerCase();\n  const brandDomain = brandLower.replace(/\\s+/g, \"\"); // \"frehnertec\" aus \"FrehnerTec\"\n\n  // 1. Finde alle Markdown-Links: [text](url)\n  // Performance: Verwende eine optimierte Regex und sammle alle Matches auf einmal\n  const markdownLinkRegex = /\\[([^\\]]*)\\]\\(([^)]+)\\)/g;\n  const allLinks: Array<{ text: string; url: string; index: number; length: number }> = [];\n  let match;\n\n  while ((match = markdownLinkRegex.exec(processedText)) !== null) {\n    allLinks.push({\n      text: match[1],\n      url: match[2],\n      index: match.index,\n      length: match[0].length,\n    });\n  }\n\n  // 2. Finde Zitierungen (Links zur eigenen Marke) und andere Links in einem Durchlauf\n  const citationRanges: Array<{ start: number; end: number }> = [];\n  const citationUrlsSet = new Set<string>();\n  const otherLinkUrlsSet = new Set<string>();\n\n  for (const link of allLinks) {\n    const urlLower = link.url.toLowerCase();\n    // Pr\u00FCfe, ob die URL die Brand-Domain enth\u00E4lt\n    if (urlLower.includes(brandDomain)) {\n      citationRanges.push({\n        start: link.index,\n        end: link.index + link.length,\n      });\n      citationUrlsSet.add(link.url);\n    } else {\n      otherLinkUrlsSet.add(link.url);\n    }\n  }\n\n  // 3. Z\u00E4hle Erw\u00E4hnungen (Text-Erw\u00E4hnungen der Marke, au\u00DFerhalb von Citations)\n  // Performance: Sortiere citationRanges f\u00FCr effizientere Suche\n  const sortedRanges = citationRanges.sort((a, b) => a.start - b.start);\n  \n  const escapedBrand = brandLower.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n  const mentionRegex = new RegExp(`\\\\b${escapedBrand}\\\\b`, \"gi\");\n  \n  let mentions = 0;\n  let mentionMatch;\n  \n  while ((mentionMatch = mentionRegex.exec(processedText)) !== null) {\n    const mentionIndex = mentionMatch.index;\n    const mentionEnd = mentionIndex + mentionMatch[0].length;\n    \n    // Pr\u00FCfe, ob diese Erw\u00E4hnung in einem Citation-Bereich liegt\n    // Optimiert: Bin\u00E4re Suche w\u00E4re besser, aber f\u00FCr kleine Arrays ist linear search OK\n    const isInCitation = sortedRanges.some(\n      (range) => mentionIndex >= range.start && mentionEnd <= range.end\n    );\n    \n    if (!isInCitation) {\n      mentions++;\n    }\n  }\n\n  return {\n    citations: citationRanges.length,\n    mentions,\n    otherLinks: otherLinkUrlsSet.size,\n    citationUrls: Array.from(citationUrlsSet), // Bereits dedupliziert durch Set\n    otherLinkUrls: Array.from(otherLinkUrlsSet), // Bereits dedupliziert durch Set\n  };\n}\n", "/**\n * Database persistence layer for D1\n */\n\nimport type {\n  UserInput,\n  Category,\n  Prompt,\n  LLMResponse,\n  PromptAnalysis,\n  CategoryMetrics,\n  CompetitiveAnalysis,\n  TimeSeriesData,\n  AnalysisResult,\n  Company,\n  CompanyPrompt,\n  ScheduledRun,\n  AnalysisSummary,\n} from \"../types.js\";\n\nexport interface D1Database {\n  prepare(query: string): D1PreparedStatement;\n  batch(statements: D1PreparedStatement[]): Promise<D1Result[]>;\n  exec(query: string): Promise<D1ExecResult>;\n}\n\nexport interface D1PreparedStatement {\n  bind(...values: any[]): D1PreparedStatement;\n  first<T = any>(colName?: string): Promise<T | null>;\n  run(): Promise<D1Result>;\n  all<T = any>(): Promise<D1Result<T>>;\n}\n\nexport interface D1Result<T = any> {\n  success: boolean;\n  meta: {\n    changes: number;\n    last_row_id: number;\n    duration: number;\n  };\n  results?: T[];\n}\n\nexport interface D1ExecResult {\n  count: number;\n  duration: number;\n}\n\nexport class Database {\n  public db: D1Database;\n  constructor(db?: D1Database) {\n    // No-op: create a mock db object if none provided\n    this.db = db || {\n      prepare: () => ({\n        bind: () => ({ first: async () => null, run: async () => ({ success: true }), all: async () => ({ success: true, results: [] }) }),\n        first: async () => null,\n        run: async () => ({ success: true }),\n        all: async () => ({ success: true, results: [] })\n      } as any),\n      batch: async () => [],\n      exec: async () => ({ count: 0, duration: 0 })\n    } as D1Database;\n  }\n\n  /**\n   * Retry wrapper for D1 operations to handle transient errors\n   * Retries on D1_ERROR, timeout, or reset errors\n   */\n  async retryD1Operation<T>(\n    operation: () => Promise<T>,\n    maxRetries: number = 3,\n    baseDelay: number = 100,\n    operationName?: string\n  ): Promise<T> {\n    let lastError: any;\n    const opName = operationName || \"D1 operation\";\n    \n    for (let attempt = 0; attempt < maxRetries; attempt++) {\n      try {\n        const startTime = Date.now();\n        const result = await operation();\n        const duration = Date.now() - startTime;\n        \n        if (duration > 1000) {\n          console.log(`[D1 DEBUG] ${opName} completed in ${duration}ms`);\n        }\n        \n        return result;\n      } catch (error: any) {\n        lastError = error;\n        const errorMessage = error?.message || String(error);\n        \n        // Check if this is a retryable D1 error\n        const isRetryable = \n          errorMessage.includes(\"D1_ERROR\") ||\n          errorMessage.includes(\"timeout\") ||\n          errorMessage.includes(\"reset\") ||\n          errorMessage.includes(\"Internal error while starting up\") ||\n          errorMessage.includes(\"storage operation exceeded timeout\");\n        \n        if (!isRetryable || attempt === maxRetries - 1) {\n          console.error(`[D1 ERROR] ${opName} failed after ${attempt + 1} attempts:`, errorMessage);\n          throw error;\n        }\n        \n        // For startup errors, use longer delays to give D1 time to initialize\n        const isStartupError = errorMessage.includes(\"Internal error while starting up\");\n        const delayMultiplier = isStartupError ? 3 : 1; // 3x longer delay for startup errors\n        const delay = baseDelay * Math.pow(2, attempt) * delayMultiplier;\n        \n        console.warn(`[D1 RETRY] ${opName} failed (attempt ${attempt + 1}/${maxRetries}), retrying in ${delay}ms:`, errorMessage);\n        await new Promise(resolve => setTimeout(resolve, delay));\n      }\n    }\n    \n    throw lastError;\n  }\n\n  /**\n   * Execute batch operations in chunks to avoid D1 timeout limits\n   * D1 has a limit of ~100 statements per batch, so we chunk larger batches\n   */\n  private async batchInChunks(\n    statements: D1PreparedStatement[],\n    chunkSize: number = 50,\n    operationName?: string\n  ): Promise<void> {\n    if (statements.length === 0) {\n      return;\n    }\n\n    const opName = operationName || `batch operation (${statements.length} statements)`;\n    console.log(`[D1 DEBUG] Executing ${opName} in chunks of ${chunkSize}`);\n\n    // Process in chunks to avoid timeout\n    for (let i = 0; i < statements.length; i += chunkSize) {\n      const chunk = statements.slice(i, i + chunkSize);\n      const chunkNum = Math.floor(i / chunkSize) + 1;\n      const totalChunks = Math.ceil(statements.length / chunkSize);\n      \n      await this.retryD1Operation(async () => {\n        const startTime = Date.now();\n        await this.db.batch(chunk);\n        const duration = Date.now() - startTime;\n        console.log(`[D1 DEBUG] ${opName} chunk ${chunkNum}/${totalChunks} (${chunk.length} statements) completed in ${duration}ms`);\n      }, 3, 100, `${opName} chunk ${chunkNum}/${totalChunks}`);\n      \n      // Add a small delay between chunks to avoid overwhelming D1\n      if (i + chunkSize < statements.length) {\n        await new Promise(resolve => setTimeout(resolve, 50)); // 50ms delay between chunks\n      }\n    }\n  }\n\n  async saveAnalysisRun(\n    runId: string,\n    userInput: UserInput,\n    status: string = \"pending\"\n  ): Promise<void> {\n    const now = new Date().toISOString();\n    try {\n      await this.db\n        .prepare(\n          `INSERT INTO analysis_runs (id, website_url, country, region, language, status, created_at, updated_at)\n           VALUES (?, ?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          runId,\n          userInput.websiteUrl,\n          userInput.country,\n          userInput.region || null,\n          userInput.language,\n          status,\n          now,\n          now\n        )\n        .run();\n    } catch (error: any) {\n      if (error.message?.includes(\"no such table: analysis_runs\")) {\n        throw new Error(\n          \"Database tables not found. Please run the database setup first: POST /api/setup/database\"\n        );\n      }\n      throw error;\n    }\n  }\n\n  async updateAnalysisStatus(\n    runId: string,\n    status: string,\n    progress?: { step: string; progress: number; message?: string }\n  ): Promise<void> {\n    const progressJson = progress ? JSON.stringify(progress) : null;\n    await this.retryD1Operation(async () => {\n      await this.db\n        .prepare(\n          `UPDATE analysis_runs SET status = ?, progress = ?, updated_at = ? WHERE id = ?`\n        )\n        .bind(status, progressJson, new Date().toISOString(), runId)\n        .run();\n    }, 3, 150, \"updateAnalysisStatus\");\n  }\n\n  async getAnalysisStatus(runId: string): Promise<{\n    status: string;\n    progress: { step: string; progress: number; message?: string } | null;\n    error?: string;\n    step?: string;\n  } | null> {\n    const run = await this.db\n      .prepare(\"SELECT status, progress, error_message, step FROM analysis_runs WHERE id = ?\")\n      .bind(runId)\n      .first<{\n        status: string;\n        progress: string | null;\n        error_message: string | null;\n        step: string | null;\n      }>();\n\n    if (!run) return null;\n\n    return {\n      status: run.status || \"pending\",\n      progress: run.progress ? JSON.parse(run.progress) : null,\n      error: run.error_message || undefined,\n      step: run.step || \"sitemap\",\n    };\n  }\n\n  async saveCategories(\n    runId: string,\n    categories: Category[]\n  ): Promise<void> {\n    if (categories.length === 0) {\n      return; // Skip empty batches\n    }\n\n    // Use INSERT OR REPLACE to handle cases where categories already exist\n    // This prevents UNIQUE constraint errors when the same category ID is saved multiple times\n    // Preserve created_at if category already exists, otherwise use current timestamp\n    const statements = categories.map((cat) =>\n      this.db\n        .prepare(\n          `INSERT OR REPLACE INTO categories (id, analysis_run_id, name, description, confidence, source_pages, created_at)\n           VALUES (?, ?, ?, ?, ?, ?, \n             COALESCE((SELECT created_at FROM categories WHERE id = ?), ?)\n           )`\n        )\n        .bind(\n          cat.id,\n          runId,\n          cat.name,\n          cat.description,\n          cat.confidence,\n          JSON.stringify(cat.sourcePages),\n          cat.id, // For COALESCE subquery to preserve existing created_at\n          new Date().toISOString() // Fallback timestamp if category doesn't exist\n        )\n    );\n\n    await this.retryD1Operation(async () => {\n      await this.batchInChunks(statements, 50, `saveCategories (${categories.length} categories)`);\n    }, 3, 100, \"saveCategories\");\n  }\n\n  async savePrompts(runId: string, prompts: Prompt[]): Promise<void> {\n    if (prompts.length === 0) {\n      return; // Skip empty batches\n    }\n\n    const statements = prompts.map((prompt) =>\n      this.db\n        .prepare(\n          `INSERT OR REPLACE INTO prompts (id, analysis_run_id, category_id, question, language, country, region, intent, created_at)\n           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          prompt.id,\n          runId,\n          prompt.categoryId,\n          prompt.question,\n          prompt.language,\n          prompt.country || null,\n          prompt.region || null,\n          prompt.intent,\n          prompt.createdAt\n        )\n    );\n\n    // Use smaller chunks for prompts to avoid timeout\n    await this.retryD1Operation(async () => {\n      await this.batchInChunks(statements, 30, `savePrompts (${prompts.length} prompts)`);\n    }, 3, 150, \"savePrompts\");\n  }\n\n  async saveLLMResponses(responses: LLMResponse[]): Promise<void> {\n    if (responses.length === 0) {\n      return; // Skip empty batches\n    }\n\n    // First, save all responses (without citations) to get response IDs\n    const responseStatements = responses.map((response) => {\n      const responseId = `resp_${response.promptId}_${Date.now()}_${Math.random().toString(36).substring(7)}`;\n      return {\n        responseId,\n        statement: this.db\n          .prepare(\n            `INSERT INTO llm_responses (id, prompt_id, output_text, model, timestamp)\n             VALUES (?, ?, ?, ?, ?)`\n          )\n          .bind(\n            responseId,\n            response.promptId,\n            response.outputText,\n            response.model,\n            response.timestamp\n          ),\n        citations: response.citations,\n      };\n    });\n\n    // Save responses first in smaller chunks\n    const responseOnlyStatements = responseStatements.map(rs => rs.statement);\n    if (responseOnlyStatements.length > 0) {\n      console.log(`[D1 DEBUG] Saving ${responseOnlyStatements.length} responses first...`);\n      await this.retryD1Operation(async () => {\n        await this.batchInChunks(responseOnlyStatements, 20, `saveLLMResponses - responses only`);\n      }, 3, 200, \"saveLLMResponses - responses\");\n    }\n\n    // Then save citations separately in smaller chunks\n    const citationStatements: D1PreparedStatement[] = [];\n    for (const { responseId, citations } of responseStatements) {\n      for (const citation of citations) {\n        const citationId = `cite_${responseId}_${Date.now()}_${Math.random().toString(36).substring(7)}`;\n        citationStatements.push(\n          this.db\n            .prepare(\n              `INSERT INTO citations (id, llm_response_id, url, title, snippet)\n               VALUES (?, ?, ?, ?, ?)`\n            )\n            .bind(\n              citationId,\n              responseId,\n              citation.url,\n              citation.title || null,\n              citation.snippet || null\n            )\n        );\n      }\n    }\n\n    if (citationStatements.length > 0) {\n      console.log(`[D1 DEBUG] Saving ${citationStatements.length} citations in separate batches...`);\n      await this.retryD1Operation(async () => {\n        // Use even smaller chunks for citations to avoid timeout\n        await this.batchInChunks(citationStatements, 15, `saveLLMResponses - citations (${citationStatements.length} total)`);\n      }, 3, 200, \"saveLLMResponses - citations\");\n    }\n\n    console.log(`[D1 DEBUG] Completed saving ${responses.length} responses with ${citationStatements.length} citations`);\n  }\n\n  async savePromptAnalyses(analyses: PromptAnalysis[]): Promise<void> {\n    if (analyses.length === 0) {\n      return; // Skip empty batches\n    }\n\n    const statements = analyses.map((analysis) => {\n      const analysisId = `analysis_${analysis.promptId}_${Date.now()}`;\n      return {\n        analysis: this.db\n          .prepare(\n            `INSERT INTO prompt_analyses \n             (id, prompt_id, brand_mentions_exact, brand_mentions_fuzzy, brand_mentions_contexts,\n              citation_count, citation_urls, sentiment_tone, sentiment_confidence, sentiment_keywords, timestamp)\n             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`\n          )\n          .bind(\n            analysisId,\n            analysis.promptId,\n            analysis.brandMentions.exact,\n            analysis.brandMentions.fuzzy,\n            JSON.stringify(analysis.brandMentions.contexts),\n            analysis.citationCount,\n            JSON.stringify(analysis.citationUrls),\n            analysis.sentiment.tone,\n            analysis.sentiment.confidence,\n            JSON.stringify(analysis.sentiment.keywords),\n            analysis.timestamp\n          ),\n        competitors: analysis.competitors.map((competitor) => {\n          const competitorId = `comp_${analysisId}_${Date.now()}_${Math.random()}`;\n          return this.db\n            .prepare(\n              `INSERT INTO competitor_mentions \n               (id, prompt_analysis_id, competitor_name, mention_count, contexts, citation_urls)\n               VALUES (?, ?, ?, ?, ?, ?)`\n            )\n            .bind(\n              competitorId,\n              analysisId,\n              competitor.name,\n              competitor.count,\n              JSON.stringify(competitor.contexts),\n              JSON.stringify(competitor.citations)\n            );\n        }),\n      };\n    });\n\n    const allStatements: D1PreparedStatement[] = [];\n    for (const { analysis, competitors } of statements) {\n      allStatements.push(analysis);\n      allStatements.push(...competitors);\n    }\n\n    if (allStatements.length > 0) {\n      await this.retryD1Operation(async () => {\n        // Use smaller chunks for analyses to avoid timeout\n      await this.batchInChunks(allStatements, 25, `savePromptAnalyses (${analyses.length} analyses, ${allStatements.length} total statements)`);\n      }, 3, 100, \"savePromptAnalyses\");\n    }\n  }\n\n  async saveCategoryMetrics(\n    runId: string,\n    metrics: CategoryMetrics[]\n  ): Promise<void> {\n    if (metrics.length === 0) {\n      return; // Skip empty batches\n    }\n\n    const statements = metrics.map((metric) => {\n      const metricId = `metric_${metric.categoryId}_${Date.now()}`;\n      return this.db\n        .prepare(\n          `INSERT INTO category_metrics \n           (id, analysis_run_id, category_id, visibility_score, citation_rate, \n            brand_mention_rate, competitor_mention_rate, timestamp)\n           VALUES (?, ?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          metricId,\n          runId,\n          metric.categoryId,\n          metric.visibilityScore,\n          metric.citationRate,\n          metric.brandMentionRate,\n          metric.competitorMentionRate,\n          metric.timestamp\n        );\n    });\n\n    await this.retryD1Operation(async () => {\n      await this.batchInChunks(statements, 50, `saveCategoryMetrics (${metrics.length} metrics)`);\n    }, 3, 100, \"saveCategoryMetrics\");\n  }\n\n  async saveCompetitiveAnalysis(\n    runId: string,\n    analysis: CompetitiveAnalysis\n  ): Promise<void> {\n    const analysisId = `comp_analysis_${runId}_${Date.now()}`;\n    await this.retryD1Operation(async () => {\n      await this.db\n        .prepare(\n          `INSERT INTO competitive_analyses \n           (id, analysis_run_id, brand_share, competitor_shares, white_space_topics, \n            dominated_prompts, missing_brand_prompts, timestamp)\n           VALUES (?, ?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          analysisId,\n          runId,\n          analysis.brandShare,\n          JSON.stringify(analysis.competitorShares),\n          JSON.stringify(analysis.whiteSpaceTopics),\n          JSON.stringify(analysis.dominatedPrompts),\n          JSON.stringify(analysis.missingBrandPrompts),\n          analysis.timestamp\n        )\n        .run();\n    });\n  }\n\n  async saveTimeSeriesData(\n    runId: string,\n    data: TimeSeriesData\n  ): Promise<void> {\n    const dataId = `ts_${runId}_${Date.now()}`;\n    await this.retryD1Operation(async () => {\n      await this.db\n        .prepare(\n          `INSERT INTO time_series \n           (id, analysis_run_id, timestamp, visibility_score, citation_count, \n            brand_mention_count, competitor_mention_count)\n           VALUES (?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          dataId,\n          runId,\n          data.timestamp,\n          data.visibilityScore,\n          data.citationCount,\n          data.brandMentionCount,\n          data.competitorMentionCount\n        )\n        .run();\n    });\n  }\n\n  async saveSummary(\n    runId: string,\n    summary: AnalysisSummary\n  ): Promise<void> {\n    // Use a more unique ID with random component to avoid collisions\n    const randomSuffix = Math.random().toString(36).substring(2, 9);\n    const summaryId = `summary_${runId}_${Date.now()}_${randomSuffix}`;\n    const now = new Date().toISOString();\n    \n    // First, delete any existing summaries for this runId to avoid duplicates\n    // Then insert the new one\n    await this.retryD1Operation(async () => {\n      // Delete existing summaries for this runId\n      await this.db\n        .prepare(\"DELETE FROM analysis_summaries WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .run();\n      \n      // Insert the new summary\n      await this.db\n        .prepare(\n          `INSERT INTO analysis_summaries \n           (id, analysis_run_id, total_mentions, total_citations, best_prompts, other_sources, created_at)\n           VALUES (?, ?, ?, ?, ?, ?, ?)`\n        )\n        .bind(\n          summaryId,\n          runId,\n          summary.totalMentions,\n          summary.totalCitations,\n          JSON.stringify(summary.bestPrompts),\n          JSON.stringify(summary.otherSources),\n          now\n        )\n        .run();\n    }, 3, 150, \"saveSummary\");\n  }\n\n  async getSummary(runId: string): Promise<AnalysisSummary | null> {\n    const result = await this.db\n      .prepare(\n        `SELECT * FROM analysis_summaries \n         WHERE analysis_run_id = ? \n         ORDER BY created_at DESC \n         LIMIT 1`\n      )\n      .bind(runId)\n      .first<{\n        total_mentions: number;\n        total_citations: number;\n        best_prompts: string;\n        other_sources: string;\n        created_at: string;\n      }>();\n\n    if (!result) return null;\n\n    return {\n      totalMentions: result.total_mentions,\n      totalCitations: result.total_citations,\n      bestPrompts: JSON.parse(result.best_prompts || '[]'),\n      otherSources: JSON.parse(result.other_sources || '{}'),\n    };\n  }\n\n  async getPromptsForAnalysis(runId: string): Promise<Array<{\n    id: string;\n    question: string;\n    answer: string | null;\n    categoryId: string;\n    categoryName: string | null;\n    createdAt: string;\n    citations?: number;\n    mentions?: number;\n    otherLinks?: number;\n    citationUrls?: string[];\n    otherLinkUrls?: string[];\n  }>> {\n    return this.retryD1Operation(async () => {\n      const { extractConclusion, extractTextStats } = await import(\"../utils/text-extraction.js\");\n      \n      // Hole die website_url, um den Brand-Namen zu extrahieren\n      const runInfo = await this.db\n        .prepare(\"SELECT website_url FROM analysis_runs WHERE id = ?\")\n        .bind(runId)\n        .first<{ website_url: string }>();\n      \n      // Extrahiere Brand-Namen aus URL\n      let brandName = \"the brand\";\n      if (runInfo?.website_url) {\n        try {\n          const domain = new URL(runInfo.website_url).hostname;\n          const parts = domain.split(\".\");\n          brandName = parts[0].charAt(0).toUpperCase() + parts[0].slice(1);\n        } catch {\n          // Fallback: verwende \"the brand\"\n        }\n      }\n      \n      const result = await this.db\n        .prepare(\n          `SELECT \n            p.id,\n            p.question,\n            p.category_id,\n            c.name as category_name,\n            p.created_at,\n            (SELECT lr.output_text \n             FROM llm_responses lr \n             WHERE lr.prompt_id = p.id \n             ORDER BY lr.timestamp DESC \n             LIMIT 1) as answer\n           FROM prompts p\n           LEFT JOIN categories c ON p.category_id = c.id\n           WHERE p.analysis_run_id = ?\n           ORDER BY p.created_at ASC`\n        )\n        .bind(runId)\n        .all<{\n          id: string;\n          question: string;\n          answer: string | null;\n          category_id: string;\n          category_name: string | null;\n          created_at: string;\n        }>();\n\n      // Verarbeite Prompts in kleineren Batches, um Timeouts zu vermeiden\n      const prompts = result.results || [];\n      const batchSize = 10; // Verarbeite 10 Prompts auf einmal\n      const processedPrompts: Array<{\n        id: string;\n        question: string;\n        answer: string | null;\n        categoryId: string;\n        categoryName: string | null;\n        createdAt: string;\n        citations?: number;\n        mentions?: number;\n        otherLinks?: number;\n        citationUrls?: string[];\n        otherLinkUrls?: string[];\n      }> = [];\n\n      for (let i = 0; i < prompts.length; i += batchSize) {\n        const batch = prompts.slice(i, i + batchSize);\n        \n        const batchResults = batch.map(r => {\n          try {\n            // Extrahiere das Fazit\n            const conclusion = extractConclusion(r.answer);\n            \n            // Berechne Statistiken aus dem ORIGINALEN Text (vor Fazit-Extraktion)\n            // Nur wenn answer vorhanden ist, um Performance zu verbessern\n            const stats = r.answer && r.answer.trim().length > 0 \n              ? extractTextStats(r.answer, brandName) \n              : null;\n            \n            return {\n              id: r.id,\n              question: r.question,\n              answer: conclusion, // Das extrahierte Fazit\n              categoryId: r.category_id,\n              categoryName: r.category_name,\n              createdAt: r.created_at,\n              // Statistiken aus dem originalen Text\n              citations: stats?.citations ?? 0,\n              mentions: stats?.mentions ?? 0,\n              otherLinks: stats?.otherLinks ?? 0,\n              citationUrls: stats?.citationUrls ?? [],\n              otherLinkUrls: stats?.otherLinkUrls ?? [],\n            };\n          } catch (error) {\n            // Fallback bei Fehler: gib zumindest die Basis-Daten zur\u00FCck\n            console.error(`Error processing prompt ${r.id}:`, error);\n            return {\n              id: r.id,\n              question: r.question,\n              answer: extractConclusion(r.answer),\n              categoryId: r.category_id,\n              categoryName: r.category_name,\n              createdAt: r.created_at,\n              citations: 0,\n              mentions: 0,\n              otherLinks: 0,\n              citationUrls: [],\n              otherLinkUrls: [],\n            };\n          }\n        });\n        \n        processedPrompts.push(...batchResults);\n        \n        // Kleine Pause zwischen Batches, um D1 nicht zu \u00FCberlasten\n        if (i + batchSize < prompts.length) {\n          await new Promise(resolve => setTimeout(resolve, 10)); // 10ms delay\n        }\n      }\n\n      return processedPrompts;\n    }, 3, 200, `getPromptsForAnalysis (${runId})`);\n  }\n\n  async getAnalysisRun(runId: string): Promise<AnalysisResult | null> {\n    return this.retryD1Operation(async () => {\n      const run = await this.db\n        .prepare(\"SELECT * FROM analysis_runs WHERE id = ?\")\n        .bind(runId)\n        .first<{\n          id: string;\n          website_url: string;\n          country: string;\n          region: string | null;\n          language: string;\n          created_at: string;\n          updated_at: string;\n        }>();\n\n      if (!run) return null;\n\n      // Fetch categories\n      const categoriesResult = await this.db\n        .prepare(\"SELECT * FROM categories WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .all<{\n          id: string;\n          name: string;\n          description: string;\n          confidence: number;\n          source_pages: string;\n        }>();\n      \n      const categories: Category[] = (categoriesResult.results || []).map(c => ({\n        id: c.id,\n        name: c.name,\n        description: c.description,\n        confidence: c.confidence,\n        sourcePages: JSON.parse(c.source_pages || '[]'),\n      }));\n\n      // Fetch prompts\n      const promptsResult = await this.db\n        .prepare(\"SELECT * FROM prompts WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .all<{\n          id: string;\n          category_id: string;\n          question: string;\n          language: string;\n          country: string | null;\n          region: string | null;\n          intent: string;\n          created_at: string;\n        }>();\n      \n      const prompts: Prompt[] = (promptsResult.results || []).map(p => ({\n        id: p.id,\n        categoryId: p.category_id,\n        question: p.question,\n        language: p.language,\n        country: p.country || undefined,\n        region: p.region || undefined,\n        intent: p.intent,\n        createdAt: p.created_at,\n      }));\n\n      // Fetch prompt analyses\n      // Optimized: Use JOIN instead of nested subquery to avoid timeout\n      const analysesResult = await this.db\n        .prepare(`\n          SELECT pa.*, \n                 GROUP_CONCAT(cm.competitor_name || '|' || cm.mention_count, '|||') as competitors_data\n          FROM prompt_analyses pa\n          INNER JOIN prompts p ON pa.prompt_id = p.id\n          LEFT JOIN competitor_mentions cm ON cm.prompt_analysis_id = pa.id\n          WHERE p.analysis_run_id = ?\n          GROUP BY pa.id\n        `)\n        .bind(runId)\n        .all<{\n          id: string;\n          prompt_id: string;\n          brand_mentions_exact: number;\n          brand_mentions_fuzzy: number;\n          brand_mentions_contexts: string;\n          citation_count: number;\n          citation_urls: string;\n          sentiment_tone: string;\n          sentiment_confidence: number;\n          sentiment_keywords: string;\n          timestamp: string;\n          competitors_data: string | null;\n        }>();\n      \n      const analyses: PromptAnalysis[] = (analysesResult.results || []).map(a => {\n        const competitors: any[] = a.competitors_data\n          ? a.competitors_data.split('|||').map(c => {\n              const [name, count] = c.split('|');\n              return { name, count: parseInt(count || '0', 10), contexts: [], citations: [] };\n            })\n          : [];\n        \n        return {\n          promptId: a.prompt_id,\n          brandMentions: {\n            exact: a.brand_mentions_exact,\n            fuzzy: a.brand_mentions_fuzzy,\n            contexts: JSON.parse(a.brand_mentions_contexts || '[]'),\n          },\n          citationCount: a.citation_count,\n          citationUrls: JSON.parse(a.citation_urls || '[]'),\n          brandCitations: [],\n          competitors,\n          sentiment: {\n            tone: a.sentiment_tone,\n            confidence: a.sentiment_confidence,\n            keywords: JSON.parse(a.sentiment_keywords || '[]'),\n          },\n          timestamp: a.timestamp,\n          isMentioned: (a.brand_mentions_exact + a.brand_mentions_fuzzy) > 0,\n          mentionCount: a.brand_mentions_exact + a.brand_mentions_fuzzy,\n          isCited: a.citation_count > 0,\n          citationDetails: JSON.parse(a.citation_urls || '[]').map((url: string) => ({ url })),\n          competitorDetails: competitors.map(c => ({ name: c.name, count: c.count, locations: [] })),\n        };\n      });\n\n      // Fetch category metrics\n      const metricsResult = await this.db\n        .prepare(\"SELECT * FROM category_metrics WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .all<{\n          id: string;\n          category_id: string;\n          visibility_score: number;\n          citation_rate: number;\n          brand_mention_rate: number;\n          competitor_mention_rate: number;\n          timestamp: string;\n        }>();\n      \n      const categoryMetrics: CategoryMetrics[] = (metricsResult.results || []).map(m => ({\n        categoryId: m.category_id,\n        visibilityScore: m.visibility_score,\n        citationRate: m.citation_rate,\n        brandMentionRate: m.brand_mention_rate,\n        competitorMentionRate: m.competitor_mention_rate,\n        timestamp: m.timestamp,\n      }));\n\n      // Fetch competitive analysis\n      const competitiveResult = await this.db\n        .prepare(\"SELECT * FROM competitive_analyses WHERE analysis_run_id = ? ORDER BY timestamp DESC LIMIT 1\")\n        .bind(runId)\n        .first<{\n          brand_share: number;\n          competitor_shares: string;\n          white_space_topics: string;\n          dominated_prompts: string;\n          missing_brand_prompts: string;\n          timestamp: string;\n        }>();\n      \n      const competitiveAnalysis: CompetitiveAnalysis = competitiveResult ? {\n        brandShare: competitiveResult.brand_share,\n        competitorShares: JSON.parse(competitiveResult.competitor_shares || '{}'),\n        whiteSpaceTopics: JSON.parse(competitiveResult.white_space_topics || '[]'),\n        dominatedPrompts: JSON.parse(competitiveResult.dominated_prompts || '[]'),\n        missingBrandPrompts: JSON.parse(competitiveResult.missing_brand_prompts || '[]'),\n        timestamp: competitiveResult.timestamp,\n      } : {\n        brandShare: 0,\n        competitorShares: {},\n        whiteSpaceTopics: [],\n        dominatedPrompts: [],\n        missingBrandPrompts: [],\n        timestamp: run.updated_at,\n      };\n\n      // Fetch time series\n      const timeSeriesResult = await this.db\n        .prepare(\"SELECT * FROM time_series WHERE analysis_run_id = ? ORDER BY timestamp ASC\")\n        .bind(runId)\n        .all<{\n          timestamp: string;\n          visibility_score: number;\n          citation_count: number;\n          brand_mention_count: number;\n          competitor_mention_count: number;\n        }>();\n      \n      const timeSeries: TimeSeriesData[] = (timeSeriesResult.results || []).map(ts => ({\n        timestamp: ts.timestamp,\n        visibilityScore: ts.visibility_score,\n        citationCount: ts.citation_count,\n        brandMentionCount: ts.brand_mention_count,\n        competitorMentionCount: ts.competitor_mention_count,\n      }));\n\n      return {\n        websiteUrl: run.website_url,\n        country: run.country,\n        language: run.language,\n        categories,\n        prompts,\n        analyses,\n        categoryMetrics,\n        competitiveAnalysis,\n        timeSeries,\n        createdAt: run.created_at,\n        updatedAt: run.updated_at,\n      };\n    });\n  }\n\n  async getLatestAnalysisRun(\n    websiteUrl: string\n  ): Promise<string | null> {\n    const run = await this.db\n      .prepare(\n        \"SELECT id FROM analysis_runs WHERE website_url = ? ORDER BY created_at DESC LIMIT 1\"\n      )\n      .bind(websiteUrl)\n      .first<{ id: string }>();\n\n    return run?.id || null;\n  }\n\n  async deleteAnalysis(runId: string): Promise<void> {\n    // Delete in order: child records first, then parent\n    // Use retry logic and optimize queries to avoid timeouts\n    await this.retryD1Operation(async () => {\n      // Get all prompt IDs for this run\n      const prompts = await this.db\n        .prepare(\"SELECT id FROM prompts WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .all<{ id: string }>();\n\n      const promptIds = (prompts.results || []).map(p => p.id);\n\n      if (promptIds.length > 0) {\n        // Delete in chunks if there are many prompts\n        const chunkSize = 50;\n        for (let i = 0; i < promptIds.length; i += chunkSize) {\n          const chunk = promptIds.slice(i, i + chunkSize);\n          \n          // Get all LLM response IDs for these prompts using JOIN (more efficient)\n          const responses = await this.db\n            .prepare(`\n              SELECT lr.id \n              FROM llm_responses lr\n              INNER JOIN prompts p ON lr.prompt_id = p.id\n              WHERE p.analysis_run_id = ? AND lr.prompt_id IN (${chunk.map(() => '?').join(',')})\n            `)\n            .bind(runId, ...chunk)\n            .all<{ id: string }>();\n\n          const responseIds = (responses.results || []).map(r => r.id);\n\n          if (responseIds.length > 0) {\n            // Delete citations in chunks\n            for (let j = 0; j < responseIds.length; j += chunkSize) {\n              const responseChunk = responseIds.slice(j, j + chunkSize);\n              await this.db\n                .prepare(`DELETE FROM citations WHERE llm_response_id IN (${responseChunk.map(() => '?').join(',')})`)\n                .bind(...responseChunk)\n                .run();\n            }\n\n            // Delete LLM responses in chunks\n            for (let j = 0; j < responseIds.length; j += chunkSize) {\n              const responseChunk = responseIds.slice(j, j + chunkSize);\n              await this.db\n                .prepare(`DELETE FROM llm_responses WHERE id IN (${responseChunk.map(() => '?').join(',')})`)\n                .bind(...responseChunk)\n                .run();\n            }\n          }\n\n          // Get all prompt analysis IDs using JOIN\n          const analyses = await this.db\n            .prepare(`\n              SELECT pa.id \n              FROM prompt_analyses pa\n              INNER JOIN prompts p ON pa.prompt_id = p.id\n              WHERE p.analysis_run_id = ? AND pa.prompt_id IN (${chunk.map(() => '?').join(',')})\n            `)\n            .bind(runId, ...chunk)\n            .all<{ id: string }>();\n\n          const analysisIds = (analyses.results || []).map(a => a.id);\n\n          if (analysisIds.length > 0) {\n            // Delete competitor mentions in chunks\n            for (let j = 0; j < analysisIds.length; j += chunkSize) {\n              const analysisChunk = analysisIds.slice(j, j + chunkSize);\n              await this.db\n                .prepare(`DELETE FROM competitor_mentions WHERE prompt_analysis_id IN (${analysisChunk.map(() => '?').join(',')})`)\n                .bind(...analysisChunk)\n                .run();\n            }\n\n            // Delete prompt analyses in chunks\n            for (let j = 0; j < analysisIds.length; j += chunkSize) {\n              const analysisChunk = analysisIds.slice(j, j + chunkSize);\n              await this.db\n                .prepare(`DELETE FROM prompt_analyses WHERE id IN (${analysisChunk.map(() => '?').join(',')})`)\n                .bind(...analysisChunk)\n                .run();\n            }\n          }\n\n          // Delete prompts in chunks\n          await this.db\n            .prepare(`DELETE FROM prompts WHERE id IN (${chunk.map(() => '?').join(',')})`)\n            .bind(...chunk)\n            .run();\n        }\n      }\n\n      // Delete category metrics\n      await this.db\n        .prepare(\"DELETE FROM category_metrics WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .run();\n\n      // Delete competitive analyses\n      await this.db\n        .prepare(\"DELETE FROM competitive_analyses WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .run();\n\n      // Delete time series\n      await this.db\n        .prepare(\"DELETE FROM time_series WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .run();\n\n      // Delete categories\n      await this.db\n        .prepare(\"DELETE FROM categories WHERE analysis_run_id = ?\")\n        .bind(runId)\n        .run();\n\n      // Finally, delete the analysis run\n      await this.db\n        .prepare(\"DELETE FROM analysis_runs WHERE id = ?\")\n        .bind(runId)\n        .run();\n    });\n  }\n\n  // Company Management\n  async createCompany(company: Omit<Company, \"id\" | \"createdAt\" | \"updatedAt\">): Promise<string> {\n    const id = `company_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;\n    const now = new Date().toISOString();\n    await this.db\n      .prepare(\n        `INSERT INTO companies (id, name, website_url, country, language, region, description, is_active, created_at, updated_at)\n         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`\n      )\n      .bind(\n        id,\n        company.name,\n        company.websiteUrl,\n        company.country,\n        company.language,\n        company.region || null,\n        company.description || null,\n        company.isActive ? 1 : 0,\n        now,\n        now\n      )\n      .run();\n    return id;\n  }\n\n  async getCompany(companyId: string): Promise<Company | null> {\n    const company = await this.db\n      .prepare(\"SELECT * FROM companies WHERE id = ?\")\n      .bind(companyId)\n      .first<{\n        id: string;\n        name: string;\n        website_url: string;\n        country: string;\n        language: string;\n        region: string | null;\n        description: string | null;\n        is_active: number;\n        created_at: string;\n        updated_at: string;\n      }>();\n    \n    if (!company) return null;\n    \n    return {\n      id: company.id,\n      name: company.name,\n      websiteUrl: company.website_url,\n      country: company.country,\n      language: company.language,\n      region: company.region || undefined,\n      description: company.description || undefined,\n      isActive: company.is_active === 1,\n      createdAt: company.created_at,\n      updatedAt: company.updated_at,\n    };\n  }\n\n  async getAllCompanies(): Promise<Company[]> {\n    // Get companies from analysis_runs grouped by website_url\n    // This shows all firms that have been analyzed\n    const companies = await this.db\n      .prepare(\n        `SELECT \n          website_url,\n          MAX(country) as country,\n          MAX(language) as language,\n          MAX(region) as region,\n          COUNT(*) as analysis_count,\n          MAX(created_at) as last_analysis_date\n         FROM analysis_runs\n         GROUP BY website_url\n         ORDER BY last_analysis_date DESC`\n      )\n      .all<{\n        website_url: string;\n        country: string;\n        language: string;\n        region: string | null;\n        analysis_count: number;\n        last_analysis_date: string;\n      }>();\n    \n    return (companies.results || []).map((c) => {\n      // Extract domain name as company name\n      let companyName = c.website_url;\n      try {\n        const url = new URL(c.website_url.startsWith('http') ? c.website_url : `https://${c.website_url}`);\n        companyName = url.hostname.replace('www.', '');\n      } catch (e) {\n        // Keep original if URL parsing fails\n      }\n      \n      // Use URL-encoded website_url as ID for easy retrieval\n      return {\n        id: encodeURIComponent(c.website_url),\n        name: companyName,\n        websiteUrl: c.website_url,\n        country: c.country,\n        language: c.language,\n        region: c.region || undefined,\n        description: undefined,\n        isActive: true,\n        createdAt: c.last_analysis_date,\n        updatedAt: c.last_analysis_date,\n      };\n    });\n  }\n\n  async updateCompany(companyId: string, updates: Partial<Company>): Promise<void> {\n    const fields: string[] = [];\n    const values: any[] = [];\n    \n    if (updates.name !== undefined) {\n      fields.push(\"name = ?\");\n      values.push(updates.name);\n    }\n    if (updates.websiteUrl !== undefined) {\n      fields.push(\"website_url = ?\");\n      values.push(updates.websiteUrl);\n    }\n    if (updates.country !== undefined) {\n      fields.push(\"country = ?\");\n      values.push(updates.country);\n    }\n    if (updates.language !== undefined) {\n      fields.push(\"language = ?\");\n      values.push(updates.language);\n    }\n    if (updates.region !== undefined) {\n      fields.push(\"region = ?\");\n      values.push(updates.region || null);\n    }\n    if (updates.description !== undefined) {\n      fields.push(\"description = ?\");\n      values.push(updates.description || null);\n    }\n    if (updates.isActive !== undefined) {\n      fields.push(\"is_active = ?\");\n      values.push(updates.isActive ? 1 : 0);\n    }\n    \n    fields.push(\"updated_at = ?\");\n    values.push(new Date().toISOString());\n    values.push(companyId);\n    \n    await this.db\n      .prepare(`UPDATE companies SET ${fields.join(\", \")} WHERE id = ?`)\n      .bind(...values)\n      .run();\n  }\n\n  // Company Prompts (saved questions for re-use)\n  async saveCompanyPrompt(prompt: Omit<CompanyPrompt, \"id\" | \"createdAt\" | \"updatedAt\">): Promise<string> {\n    const id = `prompt_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;\n    const now = new Date().toISOString();\n    await this.db\n      .prepare(\n        `INSERT INTO company_prompts (id, company_id, question, category_id, category_name, language, country, region, is_active, created_at, updated_at)\n         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`\n      )\n      .bind(\n        id,\n        prompt.companyId,\n        prompt.question,\n        prompt.categoryId || null,\n        prompt.categoryName || null,\n        prompt.language,\n        prompt.country || null,\n        prompt.region || null,\n        prompt.isActive ? 1 : 0,\n        now,\n        now\n      )\n      .run();\n    return id;\n  }\n\n  async getCompanyPrompts(companyId: string, activeOnly: boolean = true): Promise<CompanyPrompt[]> {\n    const query = activeOnly\n      ? \"SELECT * FROM company_prompts WHERE company_id = ? AND is_active = 1 ORDER BY created_at DESC\"\n      : \"SELECT * FROM company_prompts WHERE company_id = ? ORDER BY created_at DESC\";\n    \n    const prompts = await this.db\n      .prepare(query)\n      .bind(companyId)\n      .all<{\n        id: string;\n        company_id: string;\n        question: string;\n        category_id: string | null;\n        category_name: string | null;\n        language: string;\n        country: string | null;\n        region: string | null;\n        is_active: number;\n        created_at: string;\n        updated_at: string;\n      }>();\n    \n    return (prompts.results || []).map(p => ({\n      id: p.id,\n      companyId: p.company_id,\n      question: p.question,\n      categoryId: p.category_id || undefined,\n      categoryName: p.category_name || undefined,\n      language: p.language,\n      country: p.country || undefined,\n      region: p.region || undefined,\n      isActive: p.is_active === 1,\n      createdAt: p.created_at,\n      updatedAt: p.updated_at,\n    }));\n  }\n\n  async getCompanyAnalysisRuns(companyId: string, limit: number = 50): Promise<any[]> {\n    // companyId is URL-encoded website_url\n    const websiteUrl = decodeURIComponent(companyId);\n    \n    const runs = await this.db\n      .prepare(\n        `SELECT id, website_url, country, language, region, status, created_at, updated_at \n         FROM analysis_runs \n         WHERE website_url = ? \n         ORDER BY created_at DESC \n         LIMIT ?`\n      )\n      .bind(websiteUrl, limit)\n      .all<{\n        id: string;\n        website_url: string;\n        country: string;\n        language: string;\n        region: string | null;\n        status: string;\n        created_at: string;\n        updated_at: string;\n      }>();\n    \n    return (runs.results || []).map(r => ({\n      id: r.id,\n      websiteUrl: r.website_url,\n      country: r.country,\n      language: r.language,\n      region: r.region || undefined,\n      status: r.status || 'pending',\n      createdAt: r.created_at,\n      updatedAt: r.updated_at,\n    }));\n  }\n\n  async getAllAnalysisRuns(limit: number = 100): Promise<any[]> {\n    try {\n    const runs = await this.db\n      .prepare(\n        `SELECT id, website_url, country, language, region, status, created_at, updated_at, company_id\n         FROM analysis_runs \n         ORDER BY created_at DESC \n         LIMIT ?`\n      )\n      .bind(limit)\n      .all<{\n        id: string;\n        website_url: string;\n        country: string;\n        language: string;\n        region: string | null;\n        status: string;\n        created_at: string;\n        updated_at: string;\n        company_id: string | null;\n      }>();\n    \n      // Ensure we always return an array\n      if (!runs || !runs.results) {\n        return [];\n      }\n      \n      return runs.results.map(r => ({\n      id: r.id,\n      websiteUrl: r.website_url,\n      country: r.country,\n      language: r.language,\n      region: r.region || undefined,\n        status: r.status || \"pending\",\n      createdAt: r.created_at,\n      updatedAt: r.updated_at,\n      companyId: r.company_id || undefined,\n    }));\n    } catch (error) {\n      console.error(\"Error in getAllAnalysisRuns:\", error);\n      return []; // Always return an array, even on error\n    }\n  }\n\n  // Global view methods\n  async getAllGlobalCategories(): Promise<Array<{ name: string; description: string; count: number }>> {\n    // Only show categories that have prompts with web search (citations)\n    // Optimized query using JOINs instead of EXISTS for better performance\n    // This avoids D1 timeout issues with complex EXISTS subqueries\n    // Uses retry logic to handle transient D1 startup errors\n    \n    return this.retryD1Operation(async () => {\n      try {\n        const result = await this.db\n          .prepare(\n            `SELECT \n              c.name,\n              MAX(c.description) as description,\n              COUNT(DISTINCT p.id) as count\n             FROM categories c\n             INNER JOIN prompts p ON p.category_id = c.id\n             INNER JOIN llm_responses lr ON lr.prompt_id = p.id\n             INNER JOIN citations cit ON cit.llm_response_id = lr.id\n             GROUP BY c.name\n             HAVING count > 0\n             ORDER BY count DESC, c.name ASC\n             LIMIT 100`\n          )\n          .all<{\n            name: string;\n            description: string;\n            count: number;\n          }>();\n        \n        return (result.results || []).map(r => ({\n          name: r.name,\n          description: r.description || \"\",\n          count: r.count,\n        }));\n      } catch (error) {\n        console.error(\"Error in getAllGlobalCategories, trying fallback query:\", error);\n        // Fallback: simpler query without citations check if the main query times out\n        const fallbackResult = await this.db\n          .prepare(\n            `SELECT \n              c.name,\n              MAX(c.description) as description,\n              COUNT(DISTINCT p.id) as count\n             FROM categories c\n             INNER JOIN prompts p ON p.category_id = c.id\n             GROUP BY c.name\n             HAVING count > 0\n             ORDER BY count DESC, c.name ASC\n             LIMIT 100`\n          )\n          .all<{\n            name: string;\n            description: string;\n            count: number;\n          }>();\n        \n        return (fallbackResult.results || []).map(r => ({\n          name: r.name,\n          description: r.description || \"\",\n          count: r.count,\n        }));\n      }\n    }).catch((error) => {\n      console.error(\"All retry attempts failed for getAllGlobalCategories:\", error);\n      // Return empty array if all attempts fail\n      return [];\n    });\n  }\n\n  async getGlobalPromptsByCategory(categoryName: string): Promise<{\n    prompts: Array<{\n      id: string;\n      question: string;\n      answer: string;\n      language: string;\n      country: string | null;\n      region: string | null;\n      intent: string;\n      createdAt: string;\n      analysisRunId: string;\n      websiteUrl: string;\n    }>;\n    sourceStats: Array<{\n      domain: string;\n      count: number;\n    }>;\n  }> {\n    // Optimized query: Use JOINs instead of EXISTS and correlated subqueries\n    // This avoids D1 timeout issues with complex nested queries\n    return this.retryD1Operation(async () => {\n      try {\n        // First, get prompts with citations using JOIN (more efficient than EXISTS)\n        const result = await this.db\n          .prepare(\n            `SELECT DISTINCT\n              p.id,\n              p.question,\n              p.language,\n              p.country,\n              p.region,\n              p.intent,\n              p.created_at,\n              p.analysis_run_id,\n              ar.website_url\n             FROM prompts p\n             INNER JOIN categories c ON p.category_id = c.id\n             INNER JOIN analysis_runs ar ON p.analysis_run_id = ar.id\n             INNER JOIN llm_responses lr ON lr.prompt_id = p.id\n             INNER JOIN citations cit ON cit.llm_response_id = lr.id\n             WHERE c.name = ?\n             ORDER BY p.created_at DESC\n             LIMIT 500`\n          )\n          .bind(categoryName)\n          .all<{\n            id: string;\n            question: string;\n            language: string;\n            country: string | null;\n            region: string | null;\n            intent: string;\n            created_at: string;\n            analysis_run_id: string;\n            website_url: string;\n          }>();\n\n        // Then fetch answers separately for better performance\n        const prompts = result.results || [];\n        const promptIds = prompts.map(p => p.id);\n        \n        if (promptIds.length === 0) {\n          return { prompts: [], sourceStats: [] };\n        }\n\n        // Get latest answer for each prompt in a single query\n        const answersResult = await this.db\n          .prepare(\n            `SELECT \n              prompt_id,\n              output_text,\n              ROW_NUMBER() OVER (PARTITION BY prompt_id ORDER BY timestamp DESC) as rn\n             FROM llm_responses\n             WHERE prompt_id IN (${promptIds.map(() => '?').join(',')})`\n          )\n          .bind(...promptIds)\n          .all<{\n            prompt_id: string;\n            output_text: string;\n            rn: number;\n          }>();\n\n        // Create a map of prompt_id -> latest answer\n        const answerMap = new Map<string, string>();\n        (answersResult.results || []).forEach(a => {\n          if (a.rn === 1 && a.output_text && a.output_text.trim()) {\n            answerMap.set(a.prompt_id, a.output_text);\n          }\n        });\n\n        // Get all citations for these prompts to calculate source statistics\n        const citationsResult = await this.db\n          .prepare(\n            `SELECT \n              cit.url\n             FROM citations cit\n             INNER JOIN llm_responses lr ON cit.llm_response_id = lr.id\n             WHERE lr.prompt_id IN (${promptIds.map(() => '?').join(',')})`\n          )\n          .bind(...promptIds)\n          .all<{\n            url: string;\n          }>();\n\n        // Calculate source statistics (count by domain)\n        const domainCountMap = new Map<string, number>();\n        (citationsResult.results || []).forEach(citation => {\n          try {\n            const urlObj = new URL(citation.url);\n            // Normalize domain: remove www., convert to lowercase\n            const domain = urlObj.hostname.replace(/^www\\./, '').toLowerCase();\n            domainCountMap.set(domain, (domainCountMap.get(domain) || 0) + 1);\n          } catch {\n            // If URL parsing fails, skip this citation\n          }\n        });\n\n        // Convert to array and sort by count (descending)\n        const sourceStats = Array.from(domainCountMap.entries())\n          .map(([domain, count]) => ({ domain, count }))\n          .sort((a, b) => b.count - a.count);\n\n        // Map prompts with answers, filter out those without answers\n        const promptsWithAnswers = prompts\n          .map(r => {\n            const answer = answerMap.get(r.id);\n            if (!answer) return null;\n            return {\n              id: r.id,\n              question: r.question,\n              answer: answer,\n              language: r.language,\n              country: r.country || null,\n              region: r.region || null,\n              intent: r.intent,\n              createdAt: r.created_at,\n              analysisRunId: r.analysis_run_id,\n              websiteUrl: r.website_url,\n            };\n          })\n          .filter((p): p is NonNullable<typeof p> => p !== null);\n\n        // Deduplicate: keep only the newest question when duplicates exist\n        const questionMap = new Map<string, typeof promptsWithAnswers[0]>();\n        promptsWithAnswers.forEach(prompt => {\n          const existing = questionMap.get(prompt.question);\n          if (!existing || new Date(prompt.createdAt) > new Date(existing.createdAt)) {\n            questionMap.set(prompt.question, prompt);\n          }\n        });\n\n        // Convert back to array and sort by creation date (newest first)\n        const deduplicatedPrompts = Array.from(questionMap.values())\n          .sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());\n\n        return {\n          prompts: deduplicatedPrompts,\n          sourceStats,\n        };\n      } catch (error) {\n        console.error(\"Error in getGlobalPromptsByCategory, trying simpler query:\", error);\n        // Fallback: simpler query without citations check\n        const fallbackResult = await this.db\n          .prepare(\n            `SELECT \n              p.id,\n              p.question,\n              p.language,\n              p.country,\n              p.region,\n              p.intent,\n              p.created_at,\n              p.analysis_run_id,\n              ar.website_url\n             FROM prompts p\n             INNER JOIN categories c ON p.category_id = c.id\n             INNER JOIN analysis_runs ar ON p.analysis_run_id = ar.id\n             WHERE c.name = ?\n             ORDER BY p.created_at DESC\n             LIMIT 500`\n          )\n          .bind(categoryName)\n          .all<{\n            id: string;\n            question: string;\n            language: string;\n            country: string | null;\n            region: string | null;\n            intent: string;\n            created_at: string;\n            analysis_run_id: string;\n            website_url: string;\n          }>();\n\n        // For fallback, get answers\n        const fallbackPromptIds = (fallbackResult.results || []).map(p => p.id);\n        if (fallbackPromptIds.length === 0) {\n          return { prompts: [], sourceStats: [] };\n        }\n\n        const fallbackAnswersResult = await this.db\n          .prepare(\n            `SELECT \n              prompt_id,\n              output_text,\n              ROW_NUMBER() OVER (PARTITION BY prompt_id ORDER BY timestamp DESC) as rn\n             FROM llm_responses\n             WHERE prompt_id IN (${fallbackPromptIds.map(() => '?').join(',')})`\n          )\n          .bind(...fallbackPromptIds)\n          .all<{\n            prompt_id: string;\n            output_text: string;\n            rn: number;\n          }>();\n\n        const fallbackAnswerMap = new Map<string, string>();\n        (fallbackAnswersResult.results || []).forEach(a => {\n          if (a.rn === 1 && a.output_text && a.output_text.trim()) {\n            fallbackAnswerMap.set(a.prompt_id, a.output_text);\n          }\n        });\n\n        // Filter and deduplicate fallback results\n        const fallbackPromptsWithAnswers = (fallbackResult.results || [])\n          .map(r => {\n            const answer = fallbackAnswerMap.get(r.id);\n            if (!answer) return null;\n            return {\n              id: r.id,\n              question: r.question,\n              answer: answer,\n              language: r.language,\n              country: r.country || null,\n              region: r.region || null,\n              intent: r.intent,\n              createdAt: r.created_at,\n              analysisRunId: r.analysis_run_id,\n              websiteUrl: r.website_url,\n            };\n          })\n          .filter((p): p is NonNullable<typeof p> => p !== null);\n\n        // Deduplicate fallback results\n        const fallbackQuestionMap = new Map<string, typeof fallbackPromptsWithAnswers[0]>();\n        fallbackPromptsWithAnswers.forEach(prompt => {\n          const existing = fallbackQuestionMap.get(prompt.question);\n          if (!existing || new Date(prompt.createdAt) > new Date(existing.createdAt)) {\n            fallbackQuestionMap.set(prompt.question, prompt);\n          }\n        });\n\n        const deduplicatedFallbackPrompts = Array.from(fallbackQuestionMap.values())\n          .sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());\n\n        return {\n          prompts: deduplicatedFallbackPrompts,\n          sourceStats: [],\n        };\n      }\n    });\n  }\n\n  async getCompanyTimeSeries(companyId: string, days: number = 30): Promise<TimeSeriesData[]> {\n    const cutoffDate = new Date();\n    cutoffDate.setDate(cutoffDate.getDate() - days);\n    \n    const timeSeries = await this.db\n      .prepare(\n        `SELECT ts.timestamp, ts.visibility_score, ts.citation_count, \n                ts.brand_mention_count, ts.competitor_mention_count\n         FROM time_series ts\n         JOIN analysis_runs ar ON ts.analysis_run_id = ar.id\n         WHERE ar.company_id = ? AND ts.timestamp >= ?\n         ORDER BY ts.timestamp ASC`\n      )\n      .bind(companyId, cutoffDate.toISOString())\n      .all<{\n        timestamp: string;\n        visibility_score: number;\n        citation_count: number;\n        brand_mention_count: number;\n        competitor_mention_count: number;\n      }>();\n    \n    return (timeSeries.results || []).map(ts => ({\n      timestamp: ts.timestamp,\n      visibilityScore: ts.visibility_score,\n      citationCount: ts.citation_count,\n      brandMentionCount: ts.brand_mention_count,\n      competitorMentionCount: ts.competitor_mention_count,\n    }));\n  }\n\n  // Scheduled Runs\n  async createScheduledRun(schedule: Omit<ScheduledRun, \"id\" | \"createdAt\" | \"updatedAt\">): Promise<string> {\n    const id = `schedule_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;\n    const now = new Date().toISOString();\n    await this.db\n      .prepare(\n        `INSERT INTO scheduled_runs (id, company_id, schedule_type, next_run_at, last_run_at, is_active, created_at, updated_at)\n         VALUES (?, ?, ?, ?, ?, ?, ?, ?)`\n      )\n      .bind(\n        id,\n        schedule.companyId,\n        schedule.scheduleType,\n        schedule.nextRunAt,\n        schedule.lastRunAt || null,\n        schedule.isActive ? 1 : 0,\n        now,\n        now\n      )\n      .run();\n    return id;\n  }\n\n  async getScheduledRuns(companyId?: string, activeOnly: boolean = true): Promise<ScheduledRun[]> {\n    let query = \"SELECT * FROM scheduled_runs\";\n    const conditions: string[] = [];\n    const values: any[] = [];\n    \n    if (companyId) {\n      conditions.push(\"company_id = ?\");\n      values.push(companyId);\n    }\n    if (activeOnly) {\n      conditions.push(\"is_active = 1\");\n    }\n    \n    if (conditions.length > 0) {\n      query += \" WHERE \" + conditions.join(\" AND \");\n    }\n    \n    query += \" ORDER BY next_run_at ASC\";\n    \n    const schedules = await this.db\n      .prepare(query)\n      .bind(...values)\n      .all<{\n        id: string;\n        company_id: string;\n        schedule_type: string;\n        next_run_at: string;\n        last_run_at: string | null;\n        is_active: number;\n        created_at: string;\n        updated_at: string;\n      }>();\n    \n    return (schedules.results || []).map(s => ({\n      id: s.id,\n      companyId: s.company_id,\n      scheduleType: s.schedule_type as \"daily\" | \"weekly\" | \"monthly\",\n      nextRunAt: s.next_run_at,\n      lastRunAt: s.last_run_at || undefined,\n      isActive: s.is_active === 1,\n      createdAt: s.created_at,\n      updatedAt: s.updated_at,\n    }));\n  }\n\n  async updateScheduledRun(scheduleId: string, updates: Partial<ScheduledRun>): Promise<void> {\n    const fields: string[] = [];\n    const values: any[] = [];\n    \n    if (updates.scheduleType !== undefined) {\n      fields.push(\"schedule_type = ?\");\n      values.push(updates.scheduleType);\n    }\n    if (updates.nextRunAt !== undefined) {\n      fields.push(\"next_run_at = ?\");\n      values.push(updates.nextRunAt);\n    }\n    if (updates.lastRunAt !== undefined) {\n      fields.push(\"last_run_at = ?\");\n      values.push(updates.lastRunAt || null);\n    }\n    if (updates.isActive !== undefined) {\n      fields.push(\"is_active = ?\");\n      values.push(updates.isActive ? 1 : 0);\n    }\n    \n    fields.push(\"updated_at = ?\");\n    values.push(new Date().toISOString());\n    values.push(scheduleId);\n    \n    await this.db\n      .prepare(`UPDATE scheduled_runs SET ${fields.join(\", \")} WHERE id = ?`)\n      .bind(...values)\n      .run();\n  }\n\n  async getScheduledRunsDue(): Promise<ScheduledRun[]> {\n    const now = new Date().toISOString();\n    const schedules = await this.db\n      .prepare(\n        `SELECT * FROM scheduled_runs \n         WHERE is_active = 1 AND next_run_at <= ? \n         ORDER BY next_run_at ASC`\n      )\n      .bind(now)\n      .all<{\n        id: string;\n        company_id: string;\n        schedule_type: string;\n        next_run_at: string;\n        last_run_at: string | null;\n        is_active: number;\n        created_at: string;\n        updated_at: string;\n      }>();\n    \n    return (schedules.results || []).map(s => ({\n      id: s.id,\n      companyId: s.company_id,\n      scheduleType: s.schedule_type as \"daily\" | \"weekly\" | \"monthly\",\n      nextRunAt: s.next_run_at,\n      lastRunAt: s.last_run_at || undefined,\n      isActive: s.is_active === 1,\n      createdAt: s.created_at,\n      updatedAt: s.updated_at,\n    }));\n  }\n}\n\n", "/**\n * Persistence module entry point\n */\n\nexport { Database } from \"./db.js\";\nexport type {\n  D1Database,\n  D1PreparedStatement,\n  D1Result,\n  D1ExecResult,\n} from \"./db.js\";\n\n\n\n\n\n\n\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/maurofrehner/GitHub/GEO_dashboard/backend/.wrangler/tmp/bundle-Ad2mz9/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/Users/maurofrehner/GitHub/GEO_dashboard/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/maurofrehner/GitHub/GEO_dashboard/backend/.wrangler/tmp/bundle-Ad2mz9/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/maurofrehner/GitHub/GEO_dashboard/backend/.wrangler/tmp/bundle-Ad2mz9/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/maurofrehner/GitHub/GEO_dashboard/backend/src/index.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/Users/maurofrehner/GitHub/GEO_dashboard/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\n\n\t\t\t\texport * from \"/Users/maurofrehner/GitHub/GEO_dashboard/backend/src/index.ts\";\n\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "/**\n * Backend Entry Point - Cloudflare Workers\n * \n * Architecture:\n * - Routes: Request routing\n * - Handlers: Request/Response handling\n * - Services: Business logic\n * - Repositories: Data access\n * - Domain: Domain models and business rules\n */\n\nimport { Router } from \"./api/router.js\";\nimport type { Env } from \"./api/types.js\";\n\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    const router = new Router(env);\n    \n    return await router.route(request, ctx);\n  },\n};\n", "/**\n * Router - Handles request routing and delegation to handlers\n * Clean separation: Router -> Handlers -> Services -> Repositories\n */\n\nimport type { Env } from \"./types.js\";\nimport { matchRoute } from \"./routes/route-definitions.js\";\nimport { handleCors, getCorsHeaders, handleError, handleNotFound } from \"./middleware/index.js\";\nimport { WorkflowHandlers } from \"./handlers/workflow.js\";\nimport { AnalysisHandlers } from \"./handlers/analysis.js\";\nimport { WorkflowEngine } from \"../../../shared/engine_workflow.js\";\n\nexport class Router {\n  private workflowHandlers: WorkflowHandlers;\n  private analysisHandlers: AnalysisHandlers;\n\n  constructor(\n    private env: Env\n  ) {\n    const workflowEngine = new WorkflowEngine(env);\n    this.workflowHandlers = new WorkflowHandlers(workflowEngine);\n    this.analysisHandlers = new AnalysisHandlers();\n  }\n\n  async route(request: Request, ctx?: ExecutionContext): Promise<Response> {\n    const corsHeaders = getCorsHeaders();\n    \n    // Handle CORS preflight\n    const corsResponse = handleCors(request);\n    if (corsResponse) return corsResponse;\n\n    const url = new URL(request.url);\n    const path = url.pathname;\n    const method = request.method;\n\n    try {\n      const match = matchRoute(path, method);\n      \n      if (!match) {\n        return handleNotFound(corsHeaders);\n      }\n\n      const { route, params } = match;\n      const [handlerName, methodName] = route.handler.split(\".\");\n\n      // Route to appropriate handler\n      switch (handlerName) {\n        case \"workflow\":\n          return await this.routeWorkflow(methodName, request, params, corsHeaders);\n        case \"analysis\":\n          return await this.routeAnalysis(methodName, request, params, corsHeaders);\n        case \"health\":\n          return new Response(\n            JSON.stringify({ status: \"ok\", timestamp: new Date().toISOString() }),\n            {\n              headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n            }\n          );\n        default:\n          return handleNotFound(corsHeaders);\n      }\n    } catch (error) {\n      return handleError(error, corsHeaders);\n    }\n  }\n\n  private async routeWorkflow(\n    method: string,\n    request: Request,\n    params: Record<string, string>,\n    corsHeaders: ReturnType<typeof getCorsHeaders>\n  ): Promise<Response> {\n    switch (method) {\n      case \"step1\":\n        return await this.workflowHandlers.handleStep1(request, this.env, corsHeaders);\n      case \"step3\":\n        return await this.workflowHandlers.handleStep3(request, this.env, corsHeaders);\n      case \"saveCategories\":\n        return await this.workflowHandlers.handleSaveCategories(\n          params.param0 || \"\",\n          request,\n          this.env,\n          corsHeaders\n        );\n      case \"step4\":\n        return await this.workflowHandlers.handleStep4(request, this.env, corsHeaders);\n      case \"step5\":\n        return await this.workflowHandlers.handleStep5(request, this.env, corsHeaders);\n      case \"fetchUrl\":\n        return await this.workflowHandlers.handleFetchUrl(request, this.env, corsHeaders);\n      case \"generateSummary\":\n        return await this.workflowHandlers.handleGenerateSummary(request, this.env, corsHeaders);\n      case \"aiReadiness\":\n        return await this.workflowHandlers.handleAIReadiness(request, this.env, corsHeaders);\n      default:\n        return handleNotFound(corsHeaders);\n    }\n  }\n\n  private async routeAnalysis(\n    method: string,\n    request: Request,\n    params: Record<string, string>,\n    corsHeaders: ReturnType<typeof getCorsHeaders>\n  ): Promise<Response> {\n    const runId = params.param0 || \"\";\n    const companyId = params.param0 || \"\";\n    const categoryName = params.param0 || \"\";\n    \n    switch (method) {\n      case \"getAll\":\n        return await this.analysisHandlers.handleGetAllAnalyses(request, this.env, corsHeaders);\n      case \"getPromptsAndSummary\":\n        return await this.analysisHandlers.handleGetAnalysisPromptsAndSummary(runId, this.env, corsHeaders);\n      case \"delete\":\n        return await this.analysisHandlers.handleDeleteAnalysis(runId, this.env, corsHeaders);\n      case \"getAllCompanies\":\n        return await this.analysisHandlers.handleGetAllCompanies(request, this.env, corsHeaders);\n      case \"getCompanyAnalyses\":\n        return await this.analysisHandlers.handleGetCompanyAnalyses(companyId, this.env, corsHeaders);\n      case \"getGlobalCategories\":\n        return await this.analysisHandlers.handleGetGlobalCategories(request, this.env, corsHeaders);\n      case \"getGlobalPromptsByCategory\":\n        return await this.analysisHandlers.handleGetGlobalPromptsByCategory(categoryName, this.env, corsHeaders);\n      default:\n        return handleNotFound(corsHeaders);\n    }\n  }\n}\n", "/**\n * Route Definitions - Only routes used by the frontend\n */\n\nexport interface RouteDefinition {\n  method: string;\n  path: string | RegExp;\n  handler: string; // Format: \"handlerName.methodName\"\n}\n\nexport const ROUTES: RouteDefinition[] = [\n  // Workflow routes (used by frontend)\n  { method: \"POST\", path: \"/api/workflow/step1\", handler: \"workflow.step1\" },\n  { method: \"POST\", path: \"/api/workflow/step3\", handler: \"workflow.step3\" },\n  { method: \"PUT\", path: /^\\/api\\/workflow\\/([^\\/]+)\\/categories$/, handler: \"workflow.saveCategories\" },\n  { method: \"POST\", path: \"/api/workflow/step4\", handler: \"workflow.step4\" },\n  { method: \"POST\", path: \"/api/workflow/step5\", handler: \"workflow.step5\" },\n  { method: \"POST\", path: \"/api/workflow/fetchUrl\", handler: \"workflow.fetchUrl\" },\n  { method: \"POST\", path: \"/api/workflow/generateSummary\", handler: \"workflow.generateSummary\" },\n  { method: \"POST\", path: \"/api/workflow/aiReadiness\", handler: \"workflow.aiReadiness\" },\n  \n  // Analysis routes (used by frontend)\n  { method: \"GET\", path: \"/api/analyses\", handler: \"analysis.getAll\" },\n  { method: \"GET\", path: /^\\/api\\/analysis\\/([^\\/]+)\\/prompts-summary$/, handler: \"analysis.getPromptsAndSummary\" },\n  { method: \"DELETE\", path: /^\\/api\\/analysis\\/([^\\/]+)$/, handler: \"analysis.delete\" },\n  \n  // Dashboard routes\n  { method: \"GET\", path: \"/api/companies\", handler: \"analysis.getAllCompanies\" },\n  { method: \"GET\", path: /^\\/api\\/companies\\/([^\\/]+)\\/analyses$/, handler: \"analysis.getCompanyAnalyses\" },\n  { method: \"GET\", path: \"/api/global/categories\", handler: \"analysis.getGlobalCategories\" },\n  { method: \"GET\", path: /^\\/api\\/global\\/categories\\/([^\\/]+)\\/prompts$/, handler: \"analysis.getGlobalPromptsByCategory\" },\n  \n  // Health check (for monitoring)\n  { method: \"GET\", path: \"/api/health\", handler: \"health.check\" },\n];\n\nexport function matchRoute(\n  path: string,\n  method: string\n): { route: RouteDefinition; params: Record<string, string> } | null {\n  for (const route of ROUTES) {\n    if (route.method !== method) continue;\n\n    if (typeof route.path === \"string\") {\n      if (route.path === path) {\n        return { route, params: {} };\n      }\n    } else {\n      const match = path.match(route.path);\n      if (match) {\n        const params: Record<string, string> = {};\n        // Extract named groups or use indices\n        if (match.groups) {\n          Object.assign(params, match.groups);\n        } else {\n          // Use indices for unnamed groups\n          match.slice(1).forEach((value, index) => {\n            params[`param${index}`] = value;\n          });\n        }\n        return { route, params };\n      }\n    }\n  }\n  return null;\n}\n", "/**\n * Middleware exports\n */\n\nexport * from \"./cors.js\";\nexport * from \"./error-handler.js\";\n", "/**\n * CORS Middleware\n */\n\nexport interface CorsHeaders {\n  \"Access-Control-Allow-Origin\": string;\n  \"Access-Control-Allow-Methods\": string;\n  \"Access-Control-Allow-Headers\": string;\n}\n\nexport function getCorsHeaders(): CorsHeaders {\n  return {\n    \"Access-Control-Allow-Origin\": \"*\",\n    \"Access-Control-Allow-Methods\": \"GET, POST, PUT, DELETE, OPTIONS\",\n    \"Access-Control-Allow-Headers\": \"Content-Type\",\n  };\n}\n\nexport function handleCors(request: Request): Response | null {\n  if (request.method === \"OPTIONS\") {\n    return new Response(null, { headers: getCorsHeaders() });\n  }\n  return null;\n}\n", "/**\n * Error Handling Middleware\n */\n\nimport { getCorsHeaders } from \"./cors.js\";\n\nexport function handleError(error: unknown, corsHeaders: ReturnType<typeof getCorsHeaders>): Response {\n  console.error(\"API error:\", error);\n  return new Response(\n    JSON.stringify({\n      error: \"Internal Server Error\",\n      message: error instanceof Error ? error.message : \"Unknown error\",\n    }),\n    {\n      status: 500,\n      headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n    }\n  );\n}\n\nexport function handleNotFound(corsHeaders: ReturnType<typeof getCorsHeaders>): Response {\n  return new Response(\n    JSON.stringify({\n      error: \"Not Found\",\n      message: \"The requested endpoint does not exist\",\n    }),\n    {\n      status: 404,\n      headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n    }\n  );\n}\n", "/**\n * Workflow API Handlers\n */\n\nimport type { UserInput, Prompt } from \"../../../shared/types.js\";\nimport type { Env, CorsHeaders } from \"../types.js\";\nimport { WorkflowEngine } from \"../../../shared/engine_workflow.js\";\nimport { LLMExecutor } from \"../../../shared/llm_execution/index.js\";\nimport { getConfig } from \"../../../shared/config.js\";\nimport { Database } from \"../../../shared/persistence/index.js\";\nimport { AnalysisEngine } from \"../../../shared/analysis/index.js\";\nimport { extractBrandName } from \"../utils.js\";\nimport { fetchSitemap, parseSitemap, extractLinksFromHtml, extractTextContent, shouldFetchUrl, deduplicateUrls } from \"../utils/sitemap.js\";\n\nexport class WorkflowHandlers {\n  constructor(private workflowEngine: WorkflowEngine) {}\n\n  async handleStep1(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const body = await request.json() as {\n        websiteUrl?: string;\n        country?: string;\n        region?: string;\n        language?: string;\n      };\n      let websiteUrl = body.websiteUrl?.trim();\n      // Auto-add https:// if missing\n      if (websiteUrl) {\n        const urlPattern = new RegExp('^https?:\\\\/\\\\/', 'i');\n        if (!urlPattern.test(websiteUrl)) {\n          websiteUrl = 'https://' + websiteUrl;\n        }\n      }\n      const userInput: UserInput = {\n        websiteUrl: websiteUrl || '',\n        country: body.country || '',\n        region: body.region,\n        language: body.language || '',\n      };\n\n      const result = await this.workflowEngine.step1FindSitemap(userInput, env);\n\n      return new Response(JSON.stringify({\n        runId: result.runId,\n        urls: result.urls,\n        foundSitemap: result.foundSitemap,\n        message: result.foundSitemap \n          ? `Sitemap found: ${result.urls.length} URLs`\n          : `No sitemap found. ${result.urls.length} URLs extracted from homepage`\n      }), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error in handleStep1:\", error);\n      return new Response(\n        JSON.stringify({\n          error: \"Failed to start analysis\",\n          message: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleStep3(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    const body = await request.json() as {\n      runId: string;\n      content: string;\n      language?: string;\n    };\n    const { runId, content, language } = body;\n\n    const categories = await this.workflowEngine.step3GenerateCategories(\n      runId,\n      content,\n      language || 'de',\n      env\n    );\n\n    return new Response(JSON.stringify({ categories }), {\n      headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n    });\n  }\n\n  async handleSaveCategories(\n    runId: string,\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    const body = await request.json() as {\n      selectedCategoryIds?: string[];\n      customCategories?: any[];\n    };\n    const { selectedCategoryIds, customCategories } = body;\n\n    await this.workflowEngine.saveSelectedCategories(\n      runId,\n      selectedCategoryIds || [],\n      customCategories || [],\n      env\n    );\n\n    return new Response(JSON.stringify({ success: true }), {\n      headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n    });\n  }\n\n  async handleStep4(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const body = await request.json() as {\n        runId: string;\n        categories: any[];\n        userInput?: UserInput;\n        questionsPerCategory?: number;\n        companyId?: string;\n        content?: string;\n      };\n      const { runId, categories, userInput, questionsPerCategory, companyId } = body;\n\n      if (!runId) {\n        return new Response(\n          JSON.stringify({ error: \"runId is required\" }),\n          {\n            status: 400,\n            headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n          }\n        );\n      }\n\n      if (!categories || categories.length === 0) {\n        return new Response(\n          JSON.stringify({ error: \"categories are required\" }),\n          {\n            status: 400,\n            headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n          }\n        );\n      }\n\n      const prompts = await this.workflowEngine.step4GeneratePrompts(\n        runId,\n        categories,\n        userInput || { websiteUrl: '', country: '', language: 'de' },\n        body.content || \"\",\n        env,\n        questionsPerCategory || 3,\n        companyId\n      );\n\n      return new Response(JSON.stringify({ prompts }), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error: any) {\n      console.error(\"Error in handleStep4:\", error);\n      return new Response(\n        JSON.stringify({\n          error: \"Failed to generate prompts\",\n          message: error instanceof Error ? error.message : \"Unknown error\",\n          stack: error instanceof Error ? error.stack : undefined,\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleStep5(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    const body = await request.json() as {\n      runId: string;\n      prompts?: any[];\n    };\n    const { runId, prompts: promptsFromBody } = body;\n\n    try {\n      const result = await this.workflowEngine.step5ExecutePrompts(\n        runId,\n        promptsFromBody || [],\n        env\n      );\n\n      // Step 2: Perform full analysis after all prompts are executed\n      const config = getConfig(env);\n      const db = new Database(env.geo_db as any);\n\n      // Get run info to extract brand name\n      const runInfo = await db.retryD1Operation(async () => {\n        return await db.db\n          .prepare(\"SELECT website_url FROM analysis_runs WHERE id = ?\")\n          .bind(runId)\n          .first<{ website_url: string }>();\n      }, 3, 200, \"getRunInfoForStep5\");\n\n      if (!runInfo) {\n        throw new Error(\"Analysis run not found\");\n      }\n\n      const brandName = extractBrandName(runInfo.website_url);\n      const analysisEngine = new AnalysisEngine(brandName, config.analysis.brandFuzzyThreshold);\n\n      // Load all prompts for this run\n      console.log(`[D1 DEBUG] Loading prompts for runId: ${runId}`);\n      const startPrompts = Date.now();\n      const savedPrompts = await db.retryD1Operation(async () => {\n        return await db.db\n          .prepare(\"SELECT * FROM prompts WHERE analysis_run_id = ?\")\n          .bind(runId)\n          .all<any>();\n      }, 3, 200, \"loadPromptsForStep5\");\n      console.log(`[D1 DEBUG] Loaded ${savedPrompts.results?.length || 0} prompts in ${Date.now() - startPrompts}ms`);\n\n      // Load all responses for this run\n      // Optimized: Use JOIN instead of nested subquery to avoid timeout\n      // Note: GROUP_CONCAT can be slow with many citations, so we add LIMIT and retry logic\n      console.log(`[D1 DEBUG] Loading responses with citations for runId: ${runId}`);\n      const startResponses = Date.now();\n      let savedResponses;\n      try {\n        savedResponses = await db.retryD1Operation(async () => {\n          return await db.db\n            .prepare(`\n              SELECT lr.*, \n                     GROUP_CONCAT(c.url || '|' || COALESCE(c.title, '') || '|' || COALESCE(c.snippet, ''), '|||') as citations_data\n              FROM llm_responses lr\n              INNER JOIN prompts p ON lr.prompt_id = p.id\n              LEFT JOIN citations c ON c.llm_response_id = lr.id\n              WHERE p.analysis_run_id = ?\n              GROUP BY lr.id\n            `)\n            .bind(runId)\n            .all<any>();\n        }, 3, 200, \"loadResponsesWithCitations\");\n        console.log(`[D1 DEBUG] Loaded ${savedResponses.results?.length || 0} responses in ${Date.now() - startResponses}ms`);\n      } catch (error: any) {\n        console.error(`[D1 ERROR] Failed to load responses with GROUP_CONCAT, trying alternative approach:`, error.message);\n        // Fallback: Load responses and citations separately if GROUP_CONCAT times out\n        const responsesOnly = await db.retryD1Operation(async () => {\n          return await db.db\n            .prepare(`\n              SELECT lr.*\n              FROM llm_responses lr\n              INNER JOIN prompts p ON lr.prompt_id = p.id\n              WHERE p.analysis_run_id = ?\n            `)\n            .bind(runId)\n            .all<any>();\n        }, 3, 200, \"loadResponsesOnly\");\n        \n        const responseIds = (responsesOnly.results || []).map((r: any) => r.id);\n        const citationsMap = new Map<string, any[]>();\n        \n        if (responseIds.length > 0) {\n          // Load citations in chunks to avoid timeout\n          const chunkSize = 50;\n          for (let i = 0; i < responseIds.length; i += chunkSize) {\n            const chunk = responseIds.slice(i, i + chunkSize);\n            const citations = await db.retryD1Operation(async () => {\n              return await db.db\n                .prepare(`SELECT * FROM citations WHERE llm_response_id IN (${chunk.map(() => '?').join(',')})`)\n                .bind(...chunk)\n                .all<any>();\n            }, 3, 200, `loadCitationsChunk_${i}`);\n            \n            (citations.results || []).forEach((cite: any) => {\n              if (!citationsMap.has(cite.llm_response_id)) {\n                citationsMap.set(cite.llm_response_id, []);\n              }\n              citationsMap.get(cite.llm_response_id)!.push(cite);\n            });\n          }\n        }\n        \n        // Combine responses with citations\n        savedResponses = {\n          results: (responsesOnly.results || []).map((r: any) => ({\n            ...r,\n            citations_data: (citationsMap.get(r.id) || []).map(c => \n              `${c.url}|${c.title || ''}|${c.snippet || ''}`\n            ).join('|||')\n          }))\n        };\n        console.log(`[D1 DEBUG] Loaded ${savedResponses.results?.length || 0} responses (fallback method) in ${Date.now() - startResponses}ms`);\n      }\n\n      // Parse citations from concatenated string\n      const responsesWithCitations = (savedResponses.results || []).map((r: any) => {\n        const citations = r.citations_data\n          ? r.citations_data.split('|||').map((c: string) => {\n              const [url, title, snippet] = c.split('|');\n              return { url, title: title || '', snippet: snippet || '' };\n            })\n          : [];\n        return {\n          ...r,\n          citations\n        };\n      });\n\n      // Perform analysis\n      const promptsArray = (savedPrompts.results || []) as any[];\n      const analyses = analysisEngine.analyzeResponses(\n        promptsArray, \n        responsesWithCitations\n      );\n\n      // Save analyses\n      await db.savePromptAnalyses(analyses);\n\n      // Calculate metrics - using direct database queries since methods don't exist\n      // Optimized: Use JOINs instead of nested subqueries to avoid timeout\n      console.log(`[D1 DEBUG] Calculating category metrics for runId: ${runId}`);\n      const startMetrics = Date.now();\n      let categoryMetrics;\n      try {\n        categoryMetrics = await db.retryD1Operation(async () => {\n          return await db.db\n            .prepare(`\n              SELECT p.category_id, \n                     COUNT(*) as prompt_count,\n                     SUM(CASE WHEN pa.brand_mentions_exact + pa.brand_mentions_fuzzy > 0 THEN 1 ELSE 0 END) as mentions_count\n              FROM prompt_analyses pa\n              INNER JOIN prompts p ON pa.prompt_id = p.id\n              WHERE p.analysis_run_id = ?\n              GROUP BY p.category_id\n            `)\n            .bind(runId)\n            .all<any>();\n        }, 3, 200, \"calculateCategoryMetrics\");\n        console.log(`[D1 DEBUG] Category metrics calculated in ${Date.now() - startMetrics}ms`);\n      } catch (error: any) {\n        console.error(`[D1 ERROR] Failed to calculate category metrics:`, error.message);\n        categoryMetrics = { results: [] };\n      }\n\n      // Competitive analysis (no competitors tracked anymore)\n      const competitiveAnalysis = { results: [] };\n\n      console.log(`[D1 DEBUG] Calculating time series for runId: ${runId}`);\n      const startTS = Date.now();\n      let timeSeries;\n      try {\n        timeSeries = await db.retryD1Operation(async () => {\n          return await db.db\n            .prepare(`\n              SELECT DATE(lr.timestamp) as date, COUNT(*) as count\n              FROM llm_responses lr\n              INNER JOIN prompts p ON lr.prompt_id = p.id\n              WHERE p.analysis_run_id = ?\n              GROUP BY DATE(lr.timestamp)\n              ORDER BY date\n            `)\n            .bind(runId)\n            .all<any>();\n        }, 3, 200, \"calculateTimeSeries\");\n        console.log(`[D1 DEBUG] Time series calculated in ${Date.now() - startTS}ms`);\n      } catch (error: any) {\n        console.error(`[D1 ERROR] Failed to calculate time series:`, error.message);\n        timeSeries = { results: [] };\n      }\n\n      // Update run status\n      await db.updateAnalysisStatus(runId, \"completed\", {\n        step: \"completed\",\n        progress: 100,\n        message: \"Analysis completed\",\n      });\n\n      // Automatically generate summary after analysis is complete\n      console.log(`[D1 DEBUG] Generating summary for runId: ${runId}`);\n      try {\n        // Call the summary generation logic inline\n        const summaryRunInfo = await db.db\n          .prepare(\"SELECT website_url FROM analysis_runs WHERE id = ?\")\n          .bind(runId)\n          .first<{ website_url: string }>();\n\n        if (summaryRunInfo) {\n          const summaryBrandName = extractBrandName(summaryRunInfo.website_url);\n          const summaryBrandLower = summaryBrandName.toLowerCase();\n          const brandInUrl = summaryBrandLower.replace(/\\s+/g, '');\n\n          // Get prompts with mentions and citations from getPromptsForAnalysis\n          // This ensures consistency with the data shown in the UI\n          const prompts = await db.getPromptsForAnalysis(runId);\n          const totalMentions = prompts.reduce((sum, prompt) => sum + (prompt.mentions || 0), 0);\n          const totalCitations = prompts.reduce((sum, prompt) => sum + (prompt.citations || 0), 0);\n\n          const bestPrompts = prompts\n            .map((prompt) => ({\n              question: prompt.question,\n              mentions: prompt.mentions || 0,\n              citations: prompt.citations || 0,\n            }))\n            .sort((a, b) => (b.mentions + b.citations) - (a.mentions + a.citations))\n            .slice(0, 10);\n\n          // Get other sources\n          let ownCompanyDomain = '';\n          try {\n            const websiteUrlObj = new URL(summaryRunInfo.website_url);\n            ownCompanyDomain = websiteUrlObj.hostname.replace('www.', '').toLowerCase();\n          } catch {\n            ownCompanyDomain = brandInUrl;\n          }\n\n          const isOwnCompany = (domain: string) => {\n            const domainLower = domain.toLowerCase();\n            return domainLower.includes(ownCompanyDomain) || domainLower.includes(summaryBrandLower);\n          };\n\n          const allCitationsResult = await db.retryD1Operation(async () => {\n            return await db.db\n              .prepare(`\n                SELECT DISTINCT c.url, c.title, c.snippet\n                FROM citations c\n                INNER JOIN llm_responses lr ON c.llm_response_id = lr.id\n                INNER JOIN prompts p ON lr.prompt_id = p.id\n                WHERE p.analysis_run_id = ?\n              `)\n              .bind(runId)\n              .all<any>();\n          }, 3, 200, \"getAllCitationsForSummary\");\n\n          const otherSources: Record<string, number> = {};\n          (allCitationsResult.results || []).forEach((citation) => {\n            try {\n              const urlObj = new URL(citation.url);\n              const domain = urlObj.hostname.replace('www.', '').toLowerCase();\n              if (!isOwnCompany(domain)) {\n                otherSources[domain] = (otherSources[domain] || 0) + 1;\n              }\n            } catch {\n              const urlLower = citation.url.toLowerCase();\n              if (!isOwnCompany(urlLower)) {\n                otherSources[citation.url] = (otherSources[citation.url] || 0) + 1;\n              }\n            }\n          });\n\n          const summary = {\n            totalMentions,\n            totalCitations,\n            bestPrompts,\n            otherSources,\n          };\n\n          await db.saveSummary(runId, summary);\n          console.log(`[D1 DEBUG] Summary generated and saved for runId: ${runId}`);\n        }\n      } catch (error) {\n        console.error(`[D1 ERROR] Failed to generate summary automatically:`, error);\n        // Don't fail the whole request if summary generation fails\n      }\n\n      return new Response(JSON.stringify({\n        success: true,\n        runId,\n        result: {\n          categoryMetrics: categoryMetrics.results || [],\n          competitiveAnalysis: competitiveAnalysis.results || [],\n          timeSeries: timeSeries.results || [],\n        }\n      }), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error in handleStep5:\", error);\n      return new Response(\n        JSON.stringify({\n          error: \"Failed to execute prompts\",\n          message: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleFetchUrl(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    const body = await request.json() as { url?: string };\n    const { url } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ error: \"URL is required\" }),\n        {\n          status: 400,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n\n    try {\n      const response = await fetch(url, {\n        headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n        signal: AbortSignal.timeout(10000),\n      });\n\n      if (response.ok) {\n        const html = await response.text();\n        // Extract text content\n        let text = html.replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\");\n        text = text.replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\");\n        text = text.replace(/<[^>]+>/g, \" \");\n        text = text.replace(/\\s+/g, \" \").trim();\n\n        return new Response(JSON.stringify({ content: text, text: text }), {\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        });\n      } else {\n        return new Response(JSON.stringify({ content: null, error: \"Failed to fetch\" }), {\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        });\n      }\n    } catch (error) {\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleGenerateSummary(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const body = await request.json() as {\n        runId: string;\n        questionsAndAnswers?: any[];\n        userInput?: any;\n      };\n      const { runId } = body;\n\n      const db = new Database(env.geo_db as any);\n\n      // Get run info to extract brand name\n      const runInfo = await db.retryD1Operation(async () => {\n        return await db.db\n          .prepare(\"SELECT website_url FROM analysis_runs WHERE id = ?\")\n          .bind(runId)\n          .first<{ website_url: string }>();\n      }, 3, 200, \"getRunInfoForSummary\");\n\n      if (!runInfo) {\n        throw new Error(\"Analysis run not found\");\n      }\n\n      const brandName = extractBrandName(runInfo.website_url);\n      const brandLower = brandName.toLowerCase();\n      const brandInUrl = brandLower.replace(/\\s+/g, \"\"); // Remove spaces for URL matching\n\n      // Calculate total mentions from prompts using extractTextStats\n      // This uses the same logic as getPromptsForAnalysis to ensure consistency\n      const prompts = await db.getPromptsForAnalysis(runId);\n      const totalMentions = prompts.reduce((sum, prompt) => sum + (prompt.mentions || 0), 0);\n\n      // Get all citations for this run\n      const allCitationsResult = await db.retryD1Operation(async () => {\n        return await db.db\n          .prepare(`\n            SELECT \n              c.url,\n              c.title,\n              c.snippet\n            FROM citations c\n            WHERE c.llm_response_id IN (\n              SELECT id FROM llm_responses \n              WHERE prompt_id IN (SELECT id FROM prompts WHERE analysis_run_id = ?)\n            )\n          `)\n          .bind(runId)\n          .all<{ url: string; title: string | null; snippet: string | null }>();\n      }, 3, 200, \"getCitationsForSummary\");\n\n      // Filter citations where brand is mentioned (same logic as AnalysisEngine.findBrandCitations)\n      const brandCitations = (allCitationsResult.results || []).filter((citation) => {\n        const citationText = `${citation.title || \"\"} ${citation.snippet || \"\"}`.toLowerCase();\n        const urlLower = citation.url.toLowerCase();\n        \n        // Check if brand is mentioned in citation title, snippet, or URL\n        const mentionedInText = citationText.includes(brandLower);\n        const mentionedInUrl = urlLower.includes(brandInUrl);\n        \n        return mentionedInText || mentionedInUrl;\n      });\n\n      const totalCitations = brandCitations.length;\n\n      // Get best prompts using mentions and citations from getPromptsForAnalysis\n      // This ensures consistency with the data shown in the UI\n      const bestPrompts = prompts\n        .map((prompt) => ({\n          question: prompt.question,\n          mentions: prompt.mentions || 0,\n          citations: prompt.citations || 0,\n        }))\n        .sort((a, b) => (b.mentions + b.citations) - (a.mentions + a.citations))\n        .slice(0, 10);\n\n      // Get other sources (all citation URLs grouped by domain, excluding own company)\n      // Extract own company domain from website URL\n      let ownCompanyDomain = '';\n      let ownCompanyBrandName = brandLower.replace(/\\s+/g, ''); // Brand name without spaces for matching\n      try {\n        const websiteUrlObj = new URL(runInfo.website_url);\n        ownCompanyDomain = websiteUrlObj.hostname.replace('www.', '').toLowerCase();\n        // Also extract the base domain name (without TLD) for better matching\n        const domainParts = ownCompanyDomain.split('.');\n        if (domainParts.length > 0) {\n          ownCompanyBrandName = domainParts[0]; // e.g., \"frehnertec\" from \"frehnertec.ch\"\n        }\n      } catch {\n        // If URL parsing fails, use brand name\n        ownCompanyDomain = ownCompanyBrandName;\n      }\n\n      // Helper function to check if a domain should be excluded\n      const isOwnCompany = (domain: string): boolean => {\n        const domainLower = domain.toLowerCase();\n        // Exact match\n        if (domainLower === ownCompanyDomain) return true;\n        // Check if domain starts with brand name (e.g., \"frehnertec.ch\" contains \"frehnertec\")\n        if (domainLower.startsWith(ownCompanyBrandName + '.') || domainLower === ownCompanyBrandName) {\n          return true;\n        }\n        // Check if domain contains brand name as a significant part\n        const domainWithoutTld = domainLower.split('.')[0];\n        if (domainWithoutTld === ownCompanyBrandName) return true;\n        return false;\n      };\n\n      const otherSources: Record<string, number> = {};\n      // IMPORTANT: otherSources counts ONLY citations (sources), NOT mentions\n      // This ensures that competitors/other sources are only counted when they appear as citations,\n      // not when they are just mentioned in the text\n      // Use a Set to track unique citation URLs per domain to avoid double counting\n      // This ensures that [acotec.ch](https://www.acotec.ch/?utm_source=openai) counts as ONE source\n      const domainUrlMap = new Map<string, Set<string>>();\n      \n      // Use ALL citations (aggregated across all questions), not just brand citations\n      // This counts other sources (competitors) that appear as citations across all questions\n      (allCitationsResult.results || []).forEach((citation) => {\n        try {\n          const urlObj = new URL(citation.url);\n          // Normalize domain: remove www., convert to lowercase, remove trailing dots\n          let domain = urlObj.hostname.replace(/^www\\./, '').toLowerCase().replace(/\\.$/, '');\n          \n          // Exclude own company domain\n          if (!isOwnCompany(domain)) {\n            // Track unique URLs per domain to avoid counting the same URL multiple times\n            if (!domainUrlMap.has(domain)) {\n              domainUrlMap.set(domain, new Set<string>());\n            }\n            // Normalize URL by removing query parameters and fragments for comparison\n            // This ensures https://www.acotec.ch/?utm_source=openai and https://www.acotec.ch/ count as the same\n            const normalizedUrl = urlObj.origin + urlObj.pathname;\n            domainUrlMap.get(domain)!.add(normalizedUrl);\n          }\n        } catch {\n          // If URL parsing fails, try to extract domain from the URL string\n          try {\n            // Try to extract domain using regex as fallback\n            const domainMatch = citation.url.match(/https?:\\/\\/(?:www\\.)?([^\\/\\?]+)/i);\n            if (domainMatch && domainMatch[1]) {\n              let domain = domainMatch[1].replace(/^www\\./, '').toLowerCase().replace(/\\.$/, '');\n              if (!isOwnCompany(domain)) {\n                if (!domainUrlMap.has(domain)) {\n                  domainUrlMap.set(domain, new Set<string>());\n                }\n                // Use the original URL as fallback\n                domainUrlMap.get(domain)!.add(citation.url);\n              }\n            }\n          } catch {\n            // If all parsing fails, skip this citation\n          }\n        }\n      });\n      \n      // Count unique URLs per domain (each unique URL counts as 1, not multiple times)\n      domainUrlMap.forEach((urlSet, domain) => {\n        otherSources[domain] = urlSet.size;\n      });\n\n      // Create summary object\n      const summary = {\n        totalMentions,\n        totalCitations,\n        bestPrompts,\n        otherSources,\n      };\n\n      // Save summary to database\n      await db.saveSummary(runId, summary);\n\n      return new Response(\n        JSON.stringify(summary),\n        {\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    } catch (error) {\n      console.error(\"Error in handleGenerateSummary:\", error);\n      return new Response(\n        JSON.stringify({\n          error: \"Failed to generate summary\",\n          message: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleAIReadiness(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const body = await request.json() as { url: string };\n      const baseUrl = body.url?.trim();\n      \n      if (!baseUrl) {\n        return new Response(\n          JSON.stringify({ error: \"URL is required\" }),\n          {\n            status: 400,\n            headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n          }\n        );\n      }\n\n      // Normalize URL\n      let normalizedUrl = baseUrl;\n      if (!normalizedUrl.match(/^https?:\\/\\//i)) {\n        normalizedUrl = 'https://' + normalizedUrl;\n      }\n\n      const protocol: {\n        timestamp: string;\n        baseUrl: string;\n        robotsTxt: {\n          found: boolean;\n          content?: string;\n        };\n        sitemap: {\n          found: boolean;\n          content?: string;\n          urls: string[];\n        };\n        pages: Array<{\n          url: string;\n          fetchTime: number;\n          content: string;\n          success: boolean;\n          error?: string;\n        }>;\n        analysis?: {\n          summary: string;\n          recommendations: string[];\n          score?: number;\n        };\n      } = {\n        timestamp: new Date().toISOString(),\n        baseUrl: normalizedUrl,\n        robotsTxt: {\n          found: false,\n        },\n        sitemap: {\n          found: false,\n          urls: [],\n        },\n        pages: [],\n      };\n\n      // Step 1: Try to fetch robots.txt\n      try {\n        const robotsUrl = new URL('/robots.txt', normalizedUrl).toString();\n        const robotsResponse = await fetch(robotsUrl, {\n          headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n          signal: AbortSignal.timeout(10000),\n        });\n        if (robotsResponse.ok) {\n          const robotsContent = await robotsResponse.text();\n          protocol.robotsTxt = {\n            found: true,\n            content: robotsContent,\n          };\n        } else {\n          protocol.robotsTxt = { found: false };\n        }\n      } catch (error) {\n        protocol.robotsTxt = { found: false };\n      }\n\n      // Step 2: Try to fetch sitemap\n      const sitemapResult = await fetchSitemap(normalizedUrl);\n      protocol.sitemap = {\n        found: sitemapResult.found,\n        content: sitemapResult.content,\n        urls: sitemapResult.urls,\n      };\n\n      let urlsToFetch: string[] = [];\n\n      if (sitemapResult.found && sitemapResult.urls.length > 0) {\n        // If sitemap index, fetch individual sitemaps\n        if (sitemapResult.urls.some(url => url.includes('sitemap'))) {\n          const allUrls: string[] = [];\n          for (const sitemapUrl of sitemapResult.urls.slice(0, 10)) { // Limit to 10 sitemaps\n            try {\n              const response = await fetch(sitemapUrl, {\n                headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n                signal: AbortSignal.timeout(10000),\n              });\n              if (response.ok) {\n                const content = await response.text();\n                const parsedUrls = parseSitemap(content);\n                allUrls.push(...parsedUrls);\n              }\n            } catch (error) {\n              // Skip failed sitemaps\n              continue;\n            }\n          }\n          urlsToFetch = allUrls;\n        } else {\n          urlsToFetch = sitemapResult.urls;\n        }\n      } else {\n        // No sitemap found - extract links from landing page\n        try {\n          const response = await fetch(normalizedUrl, {\n            headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n            signal: AbortSignal.timeout(10000),\n          });\n          if (response.ok) {\n            const html = await response.text();\n            const links = extractLinksFromHtml(html, normalizedUrl);\n            urlsToFetch = links.slice(0, 50); // Limit to 50 pages\n          }\n        } catch (error) {\n          // Continue with just the base URL\n        }\n      }\n\n      // Always include the base URL\n      if (!urlsToFetch.includes(normalizedUrl)) {\n        urlsToFetch.unshift(normalizedUrl);\n      }\n\n      // Filter out PDFs, images, and other non-HTML files\n      urlsToFetch = urlsToFetch.filter(url => shouldFetchUrl(url));\n\n      // Deduplicate URLs to avoid fetching the same page twice\n      urlsToFetch = deduplicateUrls(urlsToFetch);\n\n      // Limit total pages to fetch\n      urlsToFetch = urlsToFetch.slice(0, 50);\n\n      // Step 3: Fetch all pages with timing\n      for (const url of urlsToFetch) {\n        const startTime = Date.now();\n        try {\n          const response = await fetch(url, {\n            headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n            signal: AbortSignal.timeout(15000),\n          });\n\n          const fetchTime = Date.now() - startTime;\n\n          // Check content type - only process HTML\n          const contentType = response.headers.get('content-type') || '';\n          if (!contentType.includes('text/html') && !contentType.includes('application/xhtml')) {\n            protocol.pages.push({\n              url,\n              fetchTime,\n              content: \"\",\n              success: false,\n              error: `Nicht-HTML Content-Type: ${contentType}`,\n            });\n            continue;\n          }\n\n          if (response.ok) {\n            const html = await response.text();\n            const textContent = extractTextContent(html);\n            \n            protocol.pages.push({\n              url,\n              fetchTime,\n              content: textContent,\n              success: true,\n            });\n          } else {\n            protocol.pages.push({\n              url,\n              fetchTime,\n              content: \"\",\n              success: false,\n              error: `HTTP ${response.status}: ${response.statusText}`,\n            });\n          }\n        } catch (error) {\n          const fetchTime = Date.now() - startTime;\n          protocol.pages.push({\n            url,\n            fetchTime,\n            content: \"\",\n            success: false,\n            error: error instanceof Error ? error.message : \"Unknown error\",\n          });\n        }\n      }\n\n      // Step 4: Generate initial protocol text (without GPT analysis)\n      let protocolText = this.formatProtocol(protocol);\n\n      // Step 5: Send to GPT API for analysis\n      const config = getConfig(env);\n      if (config.openai.apiKey) {\n        try {\n          const llmExecutor = new LLMExecutor(config);\n          const analysisPromptText = `Analyze the following website analysis protocol. Focus: How well can an AI read and understand the content? What is missing?\n\n${protocolText}\n\nPlease provide a structured analysis with:\n1. Summary - How well can an AI read the content?\n2. AI Readiness Score (0-100) - How well is the website optimized for AI readability?\n3. Concrete Recommendations (as a list) - What is missing for better AI readability?\n4. Identified Issues - What prevents AI from reading the content well?\n5. Website Strengths - What is already good for AI readability?\n\nFormat: JSON with fields: summary, score, recommendations (Array), issues (Array), strengths (Array)`;\n\n          // Use the LLM executor to get analysis\n          const prompt: Prompt = {\n            id: 'ai-readiness-analysis',\n            categoryId: 'ai-readiness',\n            question: analysisPromptText,\n            language: 'en',\n            intent: 'high',\n            createdAt: new Date().toISOString(),\n          };\n          const analysisResult = await llmExecutor.executePrompt(prompt);\n          \n          try {\n            // Try to parse JSON from the response\n            const jsonMatch = analysisResult.outputText.match(/\\{[\\s\\S]*\\}/);\n            if (jsonMatch) {\n              protocol.analysis = JSON.parse(jsonMatch[0]);\n            } else {\n              // Fallback: create structured response from text\n              protocol.analysis = {\n                summary: analysisResult.outputText,\n                recommendations: analysisResult.outputText.split('\\n').filter(line => line.trim().startsWith('-') || line.trim().startsWith('\u2022')),\n              };\n            }\n          } catch (parseError) {\n            protocol.analysis = {\n              summary: analysisResult.outputText,\n              recommendations: [],\n            };\n          }\n          \n          // Regenerate protocol text with GPT analysis included\n          protocolText = this.formatProtocol(protocol);\n        } catch (error) {\n          console.error(\"Error calling GPT API:\", error);\n          // Continue without analysis - protocolText already generated\n        }\n      }\n\n      return new Response(\n        JSON.stringify({\n          success: true,\n          protocol,\n          protocolText,\n        }),\n        {\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    } catch (error) {\n      console.error(\"Error in handleAIReadiness:\", error);\n      return new Response(\n        JSON.stringify({\n          error: \"Failed to analyze AI readiness\",\n          message: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  private formatProtocol(protocol: any): string {\n    let text = `\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nPROTOCOL\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTimestamp: ${protocol.timestamp}\nWebsite: ${protocol.baseUrl}\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nROBOTS.TXT ANALYSIS\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n`;\n\n    if (protocol.robotsTxt.found) {\n      text += `\u2713 robots.txt found\\n`;\n      text += `\\nContent:\\n${protocol.robotsTxt.content}\\n`;\n    } else {\n      text += `\u2717 No robots.txt found\\n`;\n    }\n\n    text += `\\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSITEMAP ANALYSIS\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n`;\n\n    if (protocol.sitemap.found) {\n      text += `\u2713 Sitemap found\\n`;\n      text += `Number of URLs in Sitemap: ${protocol.sitemap.urls.length}\\n`;\n      if (protocol.sitemap.content) {\n        text += `\\nSitemap Content (first 1000 characters):\\n${protocol.sitemap.content.substring(0, 1000)}\\n`;\n      }\n    } else {\n      text += `\u2717 No sitemap found\\n`;\n      text += `Links were extracted from the landing page\\n`;\n    }\n\n    text += `\\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPAGES ANALYSIS\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nNumber of Pages: ${protocol.pages.length}\nSuccessful: ${protocol.pages.filter((p: any) => p.success).length}\nFailed: ${protocol.pages.filter((p: any) => !p.success).length}\n\nAverage Load Time: ${Math.round(\n      protocol.pages.reduce((sum: number, p: any) => sum + p.fetchTime, 0) / protocol.pages.length\n    )}ms\n\n`;\n\n    protocol.pages.forEach((page: any, index: number) => {\n      text += `\\n[${index + 1}] ${page.url}\\n`;\n      text += `   Status: ${page.success ? '\u2713 Successful' : '\u2717 Error'}\\n`;\n      text += `   Load Time: ${page.fetchTime}ms\\n`;\n      if (page.error) {\n        text += `   Error: ${page.error}\\n`;\n      }\n      text += `   Content (first 3000 characters):\\n   ${page.content.substring(0, 3000).replace(/\\n/g, ' ')}${page.content.length > 3000 ? '...' : ''}\\n`;\n    });\n\n    text += `\\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n`;\n\n    return text;\n  }\n\n}\n", "/**\n * LLM execution module\n * Executes prompts against GPT-5 with Web Search enabled\n */\n\nimport type { Prompt, LLMResponse, WebSearchCitation } from \"../types.js\";\nimport type { Config } from \"../config.js\";\n\nexport class LLMExecutor {\n  constructor(private config: Config) {}\n\n  async executePrompt(prompt: Prompt): Promise<LLMResponse> {\n    const response = await this.callResponsesAPI(prompt.question);\n\n    return {\n      promptId: prompt.id,\n      outputText: response.outputText,\n      citations: response.citations,\n      timestamp: new Date().toISOString(),\n      model: this.config.openai.model,\n    };\n  }\n\n  async executePrompts(prompts: Prompt[]): Promise<LLMResponse[]> {\n    const responses: LLMResponse[] = [];\n\n    // Execute prompts sequentially to avoid rate limits\n    for (const prompt of prompts) {\n      try {\n        const response = await this.executePrompt(prompt);\n        // Only include responses that have valid output text\n        if (response && response.outputText && response.outputText.trim().length > 0) {\n          responses.push(response);\n        } else {\n          console.warn(`Prompt ${prompt.id} executed but has no valid output text`);\n        }\n      } catch (error) {\n        console.error(`Failed to execute prompt ${prompt.id}:`, error);\n        // Continue with other prompts even if one fails - failed prompts are not saved\n      }\n    }\n\n    return responses;\n  }\n\n  private async callResponsesAPI(question: string): Promise<{\n    outputText: string;\n    citations: WebSearchCitation[];\n  }> {\n    // Debug mode: Return dummy values without making API calls\n    if (this.config.debug?.enabled) {\n      console.log('\uD83D\uDC1B DEBUG MODE: Returning dummy LLM response (no API call)');\n      return this.getDummyResponse(question);\n    }\n\n    // According to OpenAI Responses API documentation:\n    // https://platform.openai.com/docs/guides/tools-web-search\n    // The endpoint is: POST https://api.openai.com/v1/responses\n    // Format: { model, tools: [{ type: \"web_search\" }], input }\n    const url = \"https://api.openai.com/v1/responses\";\n    \n    if (!this.config.openai.apiKey) {\n      throw new Error(\"OpenAI API key is not configured\");\n    }\n\n    const requestBody = {\n      model: this.config.openai.model,\n      tools: [\n        {\n          type: \"web_search\",\n        },\n      ],\n      input: question,\n    };\n\n    console.log('\uD83D\uDCE4 Sending request to OpenAI Responses API:');\n    console.log('  URL:', url);\n    console.log('  Model:', this.config.openai.model);\n    console.log('  API Key present:', !!this.config.openai.apiKey);\n    console.log('  API Key length:', this.config.openai.apiKey?.length || 0);\n    console.log('  Request body:', JSON.stringify(requestBody, null, 2));\n\n    let response: Response;\n    try {\n      response = await fetch(url, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          Authorization: `Bearer ${this.config.openai.apiKey}`,\n        },\n        body: JSON.stringify(requestBody),\n      });\n    } catch (fetchError) {\n      console.error('\u274C Fetch error:', fetchError);\n      throw new Error(`Failed to connect to OpenAI API: ${fetchError instanceof Error ? fetchError.message : String(fetchError)}`);\n    }\n\n    console.log('\uD83D\uDCE5 Response status:', response.status, response.statusText);\n    console.log('\uD83D\uDCE5 Response headers:', Object.fromEntries(response.headers.entries()));\n\n    if (!response.ok) {\n      let errorText = '';\n      try {\n        errorText = await response.text();\n        console.error('\u274C API Error Response Text:', errorText);\n      } catch (e) {\n        errorText = 'Could not read error response';\n        console.error('\u274C Could not read error response:', e);\n      }\n      console.error('\u274C API Error Response Status:', response.status);\n      console.error('\u274C API Error Response Status Text:', response.statusText);\n      \n      // Try to parse error as JSON\n      let errorJson: any = null;\n      try {\n        errorJson = JSON.parse(errorText);\n        console.error('\u274C API Error JSON:', JSON.stringify(errorJson, null, 2));\n      } catch (e) {\n        // Not JSON, that's okay\n      }\n      \n      const errorMessage = errorJson?.error?.message || errorJson?.error || errorText || response.statusText;\n      throw new Error(\n        `OpenAI API error: ${response.status} ${response.statusText} - ${errorMessage.substring(0, 500)}`\n      );\n    }\n\n    let data;\n    try {\n      data = await response.json();\n      console.log('\uD83D\uDD0D Raw API response type:', Array.isArray(data) ? 'array' : typeof data);\n      try {\n        console.log('\uD83D\uDD0D Raw API response:', JSON.stringify(data, null, 2));\n      } catch (e) {\n        console.error('\u274C Failed to stringify response:', e);\n      }\n    } catch (jsonError) {\n      const responseText = await response.text();\n      console.error('\u274C Failed to parse JSON response:', jsonError);\n      console.error('\u274C Response text:', responseText);\n      throw new Error(`Failed to parse API response: ${jsonError instanceof Error ? jsonError.message : String(jsonError)}. Response: ${responseText.substring(0, 500)}`);\n    }\n\n    // According to OpenAI docs, response is an array:\n    // [\n    //   { type: \"web_search_call\", id: \"...\", status: \"completed\" },\n    //   { id: \"...\", type: \"message\", status: \"completed\", role: \"assistant\", content: [...] }\n    // ]\n    // The response object also has output_text directly available\n    let outputText: string;\n    let citations: WebSearchCitation[];\n    try {\n      outputText = this.extractOutputText(data);\n      citations = this.extractCitations(data);\n    } catch (extractError) {\n      throw extractError;\n    }\n\n    console.log('\uD83D\uDCDD Extracted outputText length:', outputText.length);\n    console.log('\uD83D\uDCDD Extracted outputText preview:', outputText.substring(0, 200));\n    console.log('\uD83D\uDCDA Extracted citations count:', citations.length);\n    if (citations.length > 0) {\n      console.log('\uD83D\uDCDA Extracted citations:', JSON.stringify(citations, null, 2));\n    } else {\n      console.warn('\u26A0\uFE0F No citations extracted! Raw data structure:', JSON.stringify(data, null, 2).substring(0, 1000));\n    }\n\n    if (!outputText || outputText.trim().length === 0) {\n      console.error('\u274C ERROR: Empty outputText extracted!');\n      console.error('\u274C Full raw data:', JSON.stringify(data, null, 2));\n      throw new Error('Keine Antwort von GPT-5 erhalten. Die API hat eine leere Antwort zur\u00FCckgegeben.');\n    }\n\n    return {\n      outputText,\n      citations,\n    };\n  }\n\n  private extractOutputText(data: any): string {\n    console.log('\uD83D\uDD0D extractOutputText - Input data type:', Array.isArray(data) ? 'array' : typeof data);\n    \n    // According to OpenAI docs, the response can be:\n    // 1. An array: [{ type: \"web_search_call\" }, { type: \"message\", content: [...] }]\n    // 2. An object with 'output' field: { output: [{ type: \"message\", content: [...] }] }\n    // The text is in: output[0].content[0].text where content[0].type === \"output_text\"\n    \n    // Check if data has an 'output' field that is an array (actual API response format)\n    if (data && typeof data === 'object' && Array.isArray((data as any).output)) {\n      const outputArray = (data as any).output;\n      // Find the message object with type \"message\" and status \"completed\"\n      const messageObj = outputArray.find(\n        (item: any) => item.type === \"message\" && item.status === \"completed\"\n      );\n      \n      if (messageObj?.content && Array.isArray(messageObj.content)) {\n        // Find the output_text item in content array\n        const outputTextItem = messageObj.content.find(\n          (item: any) => item.type === \"output_text\"\n        );\n        \n        if (outputTextItem?.text) {\n          return outputTextItem.text;\n        }\n      }\n    }\n    \n    // Check if data has a 'data' field that is an array (wrapped response)\n    if (data && typeof data === 'object' && Array.isArray((data as any).data)) {\n      // Recursively call with the unwrapped array\n      return this.extractOutputText((data as any).data);\n    }\n    \n    // First, try direct output_text (if using SDK, response.output_text is available)\n    if (data && typeof data === 'object' && 'output_text' in data) {\n      console.log('\u2705 Found output_text directly on response object');\n      return (data as any).output_text;\n    }\n    \n    // If data is an array (raw API response - old format)\n    if (Array.isArray(data)) {\n      console.log('\uD83D\uDD0D Data is array, length:', data.length);\n      \n      // Find the message object with type \"message\" and status \"completed\"\n      // According to docs: second element is usually the message\n      const messageObj = data.find(\n        (item: any) => item.type === \"message\" && item.status === \"completed\"\n      );\n      \n      console.log('\uD83D\uDD0D Found messageObj:', messageObj ? 'yes' : 'no');\n      \n      if (messageObj?.content && Array.isArray(messageObj.content)) {\n        console.log('\uD83D\uDD0D messageObj.content is array, length:', messageObj.content.length);\n        \n        // Find the output_text item in content array\n        // According to docs: content: [{ type: \"output_text\", text: \"...\", annotations: [...] }]\n        const outputTextItem = messageObj.content.find(\n          (item: any) => item.type === \"output_text\"\n        );\n        \n        console.log('\uD83D\uDD0D Found outputTextItem:', outputTextItem ? 'yes' : 'no');\n        \n        if (outputTextItem?.text) {\n          console.log('\u2705 Extracted text from outputTextItem.text, length:', outputTextItem.text.length);\n          return outputTextItem.text;\n        } else if (outputTextItem) {\n          console.warn('\u26A0\uFE0F outputTextItem found but no text property. Keys:', Object.keys(outputTextItem));\n        }\n      }\n    }\n\n    // Fallback: try nested paths\n    if (data?.message?.output_text) {\n      console.log('\u2705 Using fallback: data.message.output_text');\n      return data.message.output_text;\n    }\n\n    if (data?.outputText) {\n      console.log('\u2705 Using fallback: data.outputText');\n      return data.outputText;\n    }\n\n    console.error('\u274C No output text found in data structure');\n    console.error('\u274C Data structure:', JSON.stringify(data, null, 2));\n    return \"\";\n  }\n\n  private extractCitations(data: any): WebSearchCitation[] {\n    const citations: WebSearchCitation[] = [];\n\n    // According to OpenAI docs, citations are in:\n    // 1. data.output[0].content[0].annotations[] (actual API format)\n    // 2. data[1].content[0].annotations[] (old array format)\n    \n    // Check if data has an 'output' field that is an array (actual API response format)\n    if (data && typeof data === 'object' && Array.isArray((data as any).output)) {\n      const outputArray = (data as any).output;\n      // Find the message object with type \"message\" and status \"completed\"\n      const messageObj = outputArray.find(\n        (item: any) => item.type === \"message\" && item.status === \"completed\"\n      );\n      \n      if (messageObj?.content && Array.isArray(messageObj.content)) {\n        // Find the output_text item in content array\n        const outputTextItem = messageObj.content.find(\n          (item: any) => item.type === \"output_text\"\n        );\n        \n        // Extract citations from annotations array\n        // According to docs: annotations: [{ type: \"url_citation\", url: \"...\", title: \"...\", ... }]\n        if (outputTextItem?.annotations && Array.isArray(outputTextItem.annotations)) {\n          for (const annotation of outputTextItem.annotations) {\n            if (annotation.type === \"url_citation\" && annotation.url) {\n              citations.push({\n                url: annotation.url,\n                title: annotation.title || annotation.url,\n                snippet: annotation.snippet || \"\",\n              });\n            }\n          }\n        }\n      }\n    }\n    \n    // If data is an array (raw API response - old format)\n    if (Array.isArray(data)) {\n      // Find the message object with type \"message\" and status \"completed\"\n      const messageObj = data.find(\n        (item: any) => item.type === \"message\" && item.status === \"completed\"\n      );\n      \n      if (messageObj?.content && Array.isArray(messageObj.content)) {\n        // Find the output_text item in content array\n        const outputTextItem = messageObj.content.find(\n          (item: any) => item.type === \"output_text\"\n        );\n        \n        // Extract citations from annotations array\n        // According to docs: annotations: [{ type: \"url_citation\", url: \"...\", title: \"...\", ... }]\n        if (outputTextItem?.annotations && Array.isArray(outputTextItem.annotations)) {\n          for (const annotation of outputTextItem.annotations) {\n            if (annotation.type === \"url_citation\" && annotation.url) {\n              citations.push({\n                url: annotation.url,\n                title: annotation.title || annotation.url,\n                snippet: annotation.snippet || \"\",\n              });\n            }\n          }\n        }\n      }\n    }\n\n    // Fallback: try nested paths (for backward compatibility)\n    if (data?.message?.content && Array.isArray(data.message.content)) {\n      for (const item of data.message.content) {\n        if (item.annotations && Array.isArray(item.annotations)) {\n          for (const annotation of item.annotations) {\n            if (annotation.type === \"url_citation\" && annotation.url) {\n              citations.push({\n                url: annotation.url,\n                title: annotation.title || annotation.url,\n                snippet: annotation.snippet || \"\",\n              });\n            }\n          }\n        }\n      }\n    }\n\n    // Deduplicate by URL\n    const uniqueCitations = new Map<string, WebSearchCitation>();\n    for (const citation of citations) {\n      if (citation.url && !uniqueCitations.has(citation.url)) {\n        uniqueCitations.set(citation.url, citation);\n      }\n    }\n\n    return Array.from(uniqueCitations.values());\n  }\n\n  private getDummyResponse(question: string): {\n    outputText: string;\n    citations: WebSearchCitation[];\n  } {\n    // Generate realistic dummy response based on question\n    const dummyOutputText = `[DEBUG MODE] Dies ist eine Dummy-Antwort f\u00FCr die Frage: \"${question}\"\n\nIn einem echten Szenario w\u00FCrde hier eine detaillierte Antwort von GPT-5 mit Web-Suche stehen. Diese Antwort enth\u00E4lt relevante Informationen, Zitate und Verweise auf externe Quellen.\n\nDie Antwort behandelt verschiedene Aspekte des Themas und bietet umfassende Informationen f\u00FCr den Benutzer.`;\n\n    const dummyCitations: WebSearchCitation[] = [\n      {\n        url: \"https://example.com/article1\",\n        title: \"Beispiel-Artikel 1 - Relevante Informationen\",\n        snippet: \"Dies ist ein Beispiel-Zitat aus einer externen Quelle, die relevante Informationen zum Thema enth\u00E4lt.\",\n      },\n      {\n        url: \"https://example.com/article2\",\n        title: \"Beispiel-Artikel 2 - Weitere Details\",\n        snippet: \"Ein weiteres Beispiel-Zitat mit zus\u00E4tzlichen Informationen und Kontext zum Thema.\",\n      },\n      {\n        url: \"https://example.com/article3\",\n        title: \"Beispiel-Artikel 3 - Zus\u00E4tzliche Ressourcen\",\n        snippet: \"Ein drittes Beispiel-Zitat, das weitere Perspektiven und Ressourcen zum Thema bietet.\",\n      },\n    ];\n\n    return {\n      outputText: dummyOutputText,\n      citations: dummyCitations,\n    };\n  }\n}\n\n", "/**\n * Configuration management for the GEO platform\n */\n\nexport interface Config {\n  debug: {\n    enabled: boolean;\n  };\n  openai: {\n    apiKey: string;\n    model: string;\n    responsesApiUrl: string;\n  };\n  crawling: {\n    maxPages: number;\n    maxDepth: number;\n    timeout: number;\n    userAgent: string;\n  };\n  analysis: {\n    reRunSchedule: \"daily\" | \"weekly\";\n    brandFuzzyThreshold: number;\n    sentimentConfidenceThreshold: number;\n  };\n  categories: {\n    minConfidence: number;\n    maxCategories: number;\n  };\n  prompts: {\n    questionsPerCategory: number;\n    minIntentScore: number;\n  };\n}\n\nexport function getConfig(env: Record<string, any>): Config {\n  const debugModeValue = env.DEBUG_MODE;\n  const debugEnabled = debugModeValue === \"true\" || debugModeValue === \"1\" || debugModeValue === true;\n  \n  console.log('\uD83D\uDD27 Config loaded - DEBUG_MODE:', debugModeValue, '\u2192 enabled:', debugEnabled);\n  \n  if (debugEnabled) {\n    console.log('\uD83D\uDC1B DEBUG MODE ENABLED - Using dummy values, no API calls will be made');\n  }\n  \n  return {\n    debug: {\n      enabled: debugEnabled,\n    },\n    openai: {\n      apiKey: env.OPENAI_API_KEY || \"\",\n      model: env.OPENAI_MODEL || \"gpt-4o\", // Use gpt-4o by default, set OPENAI_MODEL=gpt-5 in .dev.vars if available\n      responsesApiUrl: \"https://api.openai.com/v1/responses\",\n    },\n    crawling: {\n      maxPages: parseInt(env.MAX_PAGES || \"50\"),\n      maxDepth: parseInt(env.MAX_DEPTH || \"3\"),\n      timeout: parseInt(env.CRAWL_TIMEOUT || \"30000\"),\n      userAgent: env.USER_AGENT || \"GEO-Platform/1.0\",\n    },\n    analysis: {\n      reRunSchedule: (env.RE_RUN_SCHEDULE as \"daily\" | \"weekly\") || \"weekly\",\n      brandFuzzyThreshold: parseFloat(env.BRAND_FUZZY_THRESHOLD || \"0.7\"),\n      sentimentConfidenceThreshold: parseFloat(\n        env.SENTIMENT_CONFIDENCE_THRESHOLD || \"0.6\"\n      ),\n    },\n    categories: {\n      minConfidence: parseFloat(env.MIN_CATEGORY_CONFIDENCE || \"0.5\"),\n      maxCategories: parseInt(env.MAX_CATEGORIES || \"10\"),\n    },\n    prompts: {\n      questionsPerCategory: parseInt(env.QUESTIONS_PER_CATEGORY || \"5\"),\n      minIntentScore: parseFloat(env.MIN_INTENT_SCORE || \"0.7\"),\n    },\n  };\n}\n\n", "/**\n * Analysis module entry point\n */\n\nimport type {\n  Prompt,\n  LLMResponse,\n  PromptAnalysis,\n  CategoryMetrics,\n  CompetitiveAnalysis,\n  BrandCitation,\n} from \"../types.js\";\nimport { BrandMentionDetector } from \"./brand_mention.js\";\nimport { SentimentAnalyzer } from \"./sentiment.js\";\n\nexport class AnalysisEngine {\n  private brandMentionDetector: BrandMentionDetector;\n  private sentimentAnalyzer: SentimentAnalyzer;\n  private brandName: string;\n\n  constructor(\n    brandName: string,\n    fuzzyThreshold: number = 0.7\n  ) {\n    this.brandName = brandName;\n    this.brandMentionDetector = new BrandMentionDetector(\n      brandName,\n      fuzzyThreshold\n    );\n    this.sentimentAnalyzer = new SentimentAnalyzer();\n  }\n\n  analyzeResponses(\n    prompts: Prompt[],\n    responses: LLMResponse[]\n  ): PromptAnalysis[] {\n    const analyses: PromptAnalysis[] = [];\n\n    for (const prompt of prompts) {\n      const response = responses.find((r) => r.promptId === prompt.id);\n      if (!response) continue;\n\n      const analysis = this.analyzeSingleResponse(prompt, response);\n      analyses.push(analysis);\n    }\n\n    return analyses;\n  }\n\n  private analyzeSingleResponse(\n    prompt: Prompt,\n    response: LLMResponse\n  ): PromptAnalysis {\n    const brandMentions = this.brandMentionDetector.detectMentions(response);\n    const sentiment = this.sentimentAnalyzer.analyzeSentiment(response);\n    \n    // Find citations where the brand is mentioned\n    const brandCitations = this.findBrandCitations(response);\n    \n    // Calculate structured answers\n    const isMentioned = brandMentions.exact > 0 || brandMentions.fuzzy > 0;\n    const mentionCount = brandMentions.exact + brandMentions.fuzzy;\n    const isCited = brandCitations.length > 0;\n    \n    // Citation details (where and what)\n    const citationDetails = brandCitations.map(c => ({\n      url: c.url,\n      title: c.title,\n      snippet: c.snippet,\n    }));\n\n    return {\n      promptId: prompt.id,\n      brandMentions,\n      citationCount: response.citations.length,\n      citationUrls: response.citations.map((c) => c.url),\n      brandCitations,\n      sentiment,\n      timestamp: response.timestamp,\n      // Structured answers\n      isMentioned,\n      mentionCount,\n      isCited,\n      citationDetails,\n    };\n  }\n  \n  private findBrandCitations(response: LLMResponse): BrandCitation[] {\n    const brandLower = this.brandName.toLowerCase();\n    const brandInUrl = brandLower.replace(/\\s+/g, \"\"); // Remove spaces for URL matching\n    const brandCitations: BrandCitation[] = [];\n    \n    for (const citation of response.citations) {\n      const citationText = `${citation.title || \"\"} ${citation.snippet || \"\"}`.toLowerCase();\n      const urlLower = citation.url.toLowerCase();\n      \n      // Check if brand is mentioned in citation title, snippet, or URL\n      const mentionedInText = citationText.includes(brandLower);\n      const mentionedInUrl = urlLower.includes(brandInUrl);\n      \n      if (mentionedInText || mentionedInUrl) {\n        // Extract context where brand is mentioned\n        let context = \"\";\n        if (mentionedInText) {\n          context = this.extractBrandContextFromCitation(citation, brandLower);\n        } else if (mentionedInUrl) {\n          // Find context in the main text where this URL is referenced\n          context = this.findUrlContextInText(response.outputText, citation.url);\n        }\n        \n        brandCitations.push({\n          url: citation.url,\n          title: citation.title,\n          snippet: citation.snippet,\n          context,\n        });\n      }\n    }\n    \n    return brandCitations;\n  }\n  \n  private findUrlContextInText(text: string, url: string): string {\n    // Find markdown links or plain URLs in text\n    // Pattern: [text](url) or just url\n    const urlPattern = url.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n    const markdownPattern = new RegExp(`\\\\[([^\\\\]]+)\\\\]\\\\(${urlPattern}\\\\)`, \"i\");\n    const match = text.match(markdownPattern);\n    \n    if (match && match[1]) {\n      return match[1]; // Return the link text\n    }\n    \n    // Try to find sentence containing the URL\n    const sentences = text.split(/[.!?]+/);\n    for (const sentence of sentences) {\n      if (sentence.includes(url)) {\n        return sentence.trim();\n      }\n    }\n    \n    return \"\";\n  }\n  \n  private extractBrandContextFromCitation(\n    citation: { title?: string; snippet?: string },\n    brandLower: string\n  ): string | undefined {\n    const text = `${citation.title || \"\"} ${citation.snippet || \"\"}`;\n    const sentences = text.split(/[.!?]+/);\n    \n    for (const sentence of sentences) {\n      if (sentence.toLowerCase().includes(brandLower)) {\n        return sentence.trim();\n      }\n    }\n    \n    return undefined;\n  }\n\n  calculateCategoryMetrics(\n    categoryId: string,\n    prompts: Prompt[],\n    analyses: PromptAnalysis[]\n  ): CategoryMetrics {\n    const categoryPrompts = prompts.filter((p) => p.categoryId === categoryId);\n    const categoryAnalyses = analyses.filter((a) =>\n      categoryPrompts.some((p) => p.id === a.promptId)\n    );\n\n    if (categoryAnalyses.length === 0) {\n      return {\n        categoryId,\n        visibilityScore: 0,\n        citationRate: 0,\n        brandMentionRate: 0,\n        timestamp: new Date().toISOString(),\n      };\n    }\n\n    const totalPrompts = categoryPrompts.length;\n    const promptsWithBrandMentions = categoryAnalyses.filter(\n      (a) => a.brandMentions.exact > 0 || a.brandMentions.fuzzy > 0\n    ).length;\n    const totalCitations = categoryAnalyses.reduce(\n      (sum, a) => sum + a.citationCount,\n      0\n    );\n\n    const visibilityScore = this.calculateVisibilityScore(categoryAnalyses);\n    const citationRate = totalCitations / totalPrompts;\n    const brandMentionRate = promptsWithBrandMentions / totalPrompts;\n\n    return {\n      categoryId,\n      visibilityScore,\n      citationRate,\n      brandMentionRate,\n      timestamp: new Date().toISOString(),\n    };\n  }\n\n  private calculateVisibilityScore(analyses: PromptAnalysis[]): number {\n    // Visibility score based on:\n    // - Brand mentions (weighted)\n    // - Citation count\n    // - Sentiment (positive boosts score)\n\n    let score = 0;\n\n    for (const analysis of analyses) {\n      // Brand mentions contribute to score\n      score += analysis.brandMentions.exact * 10;\n      score += analysis.brandMentions.fuzzy * 5;\n\n      // Citations contribute\n      score += analysis.citationCount * 2;\n\n      // Positive sentiment boosts\n      if (analysis.sentiment.tone === \"positive\") {\n        score += 5;\n      } else if (analysis.sentiment.tone === \"negative\") {\n        score -= 5;\n      }\n    }\n\n    // Normalize to 0-100\n    const maxPossibleScore = analyses.length * 50; // Rough estimate\n    return Math.min(Math.max((score / maxPossibleScore) * 100, 0), 100);\n  }\n\n  performCompetitiveAnalysis(\n    analyses: PromptAnalysis[],\n    prompts: Prompt[]\n  ): CompetitiveAnalysis {\n    const totalMentions = analyses.reduce(\n      (sum, a) => sum + a.brandMentions.exact + a.brandMentions.fuzzy,\n      0\n    );\n\n    // Calculate brand share (100% since no competitors)\n    const brandShare = 100;\n\n    // Identify white space topics (prompts with no brand mentions)\n    const whiteSpaceTopics = prompts\n      .filter((p) => {\n        const analysis = analyses.find((a) => a.promptId === p.id);\n        if (!analysis) return true;\n        return (\n          analysis.brandMentions.exact === 0 &&\n          analysis.brandMentions.fuzzy === 0\n        );\n      })\n      .map((p) => p.question);\n\n    // Identify missing brand prompts\n    const missingBrandPrompts = prompts\n      .filter((p) => {\n        const analysis = analyses.find((a) => a.promptId === p.id);\n        if (!analysis) return true;\n        return (\n          analysis.brandMentions.exact === 0 &&\n          analysis.brandMentions.fuzzy === 0\n        );\n      })\n      .map((p) => p.id);\n\n    return {\n      brandShare,\n      competitorShares: {},\n      whiteSpaceTopics,\n      dominatedPrompts: [],\n      missingBrandPrompts,\n      timestamp: new Date().toISOString(),\n    };\n  }\n}\n\nexport { BrandMentionDetector } from \"./brand_mention.js\";\nexport { SentimentAnalyzer } from \"./sentiment.js\";\n\n\n", "/**\n * Brand mention & citation detection module\n * Ziel:\n * - exact   = echte Text-Erw\u00E4hnungen der Brand\n * - fuzzy   = bewusst 0 (LLM-Texte sind deterministisch)\n * - contexts = S\u00E4tze mit Erw\u00E4hnung ODER Citation\n */\n\nimport type { LLMResponse, BrandMention } from \"../types.js\";\n\nexport class BrandMentionDetector {\n  private brandName: string;\n  private fuzzyThreshold: number;\n  private debug: boolean;\n\n  constructor(brandName: string, fuzzyThreshold: number = 0.7, debug: boolean = false) {\n    this.brandName = brandName;\n    this.fuzzyThreshold = fuzzyThreshold;\n    this.debug = debug;\n  }\n\n  /**\n   * Enable or disable debug logging\n   */\n  setDebug(enabled: boolean): void {\n    this.debug = enabled;\n  }\n\n  detectMentions(response: LLMResponse): BrandMention {\n    const rawText = response.outputText;\n    const lowerText = rawText.toLowerCase();\n\n    const brandLower = this.brandName.toLowerCase();\n    const brandDomain = brandLower.replace(/\\s+/g, \"\");\n\n    if (this.debug) {\n      console.log(\"[BrandMentionDetector] Starting detection\");\n      console.log(\"[BrandMentionDetector] Brand name:\", this.brandName);\n      console.log(\"[BrandMentionDetector] Brand lower:\", brandLower);\n      console.log(\"[BrandMentionDetector] Brand domain:\", brandDomain);\n      console.log(\"[BrandMentionDetector] Text length:\", rawText.length);\n      console.log(\"[BrandMentionDetector] Text preview:\", rawText.substring(0, 200));\n    }\n\n    // Zuerst Citations finden, um deren Positionen zu kennen\n    // Use lowerText for citation ranges to ensure case-insensitive matching\n    const citationRanges = this.findCitationRanges(lowerText, brandDomain);\n    const citations = citationRanges.length;\n\n    // Exakte Erw\u00E4hnungen z\u00E4hlen, aber die in Citations ausschlie\u00DFen\n    // Case-insensitive: uses lowerText and brandLower for matching\n    const exact = this.countExactMentionsExcludingCitations(\n      rawText,\n      lowerText,\n      brandLower,\n      citationRanges\n    );\n\n    const contexts = this.extractContexts(rawText, brandLower, brandDomain);\n\n    if (this.debug) {\n      console.log(\"[BrandMentionDetector] Exact mentions (excluding citations):\", exact);\n      console.log(\"[BrandMentionDetector] Citations found:\", citations);\n      console.log(\"[BrandMentionDetector] Citation ranges:\", citationRanges);\n      console.log(\"[BrandMentionDetector] Contexts found:\", contexts.length);\n      console.log(\"[BrandMentionDetector] Contexts:\", contexts);\n    }\n\n    return {\n      exact,\n      fuzzy: 0, // absichtlich: alles andere w\u00E4re unseri\u00F6s\n      contexts,\n      citations // Anzahl der Markdown-Citations mit Brand-Domain\n    };\n  }\n\n  // --------------------------------------------------\n  // Exakte Text-Erw\u00E4hnungen (kein Fuzzy, kein Ratespiel)\n  // Ausschlie\u00DFt Erw\u00E4hnungen, die bereits in Citations sind\n  // Case-insensitive: brand is already lowercased, lowerText is used for matching\n  // --------------------------------------------------\n  private countExactMentionsExcludingCitations(\n    rawText: string,\n    lowerText: string,\n    brand: string,\n    citationRanges: Array<{ start: number; end: number }>\n  ): number {\n    const escapedBrand = this.escapeRegex(brand);\n    // Use case-insensitive flag 'i' (though we're already using lowerText)\n    // This ensures robustness even if called with mixed case\n    const regex = new RegExp(`\\\\b${escapedBrand}\\\\b`, \"gi\");\n    \n    if (this.debug) {\n      console.log(\"[countExactMentionsExcludingCitations] Regex pattern:\", regex.source);\n      console.log(\"[countExactMentionsExcludingCitations] Escaped brand:\", escapedBrand);\n    }\n    \n    let count = 0;\n    let match;\n    \n    // Alle Matches durchgehen\n    while ((match = regex.exec(lowerText)) !== null) {\n      const matchStart = match.index;\n      const matchEnd = matchStart + match[0].length;\n      \n      // Pr\u00FCfen, ob diese Erw\u00E4hnung innerhalb eines Citations liegt\n      const isInCitation = citationRanges.some(range => \n        matchStart >= range.start && matchEnd <= range.end\n      );\n      \n      if (!isInCitation) {\n        count++;\n        if (this.debug) {\n          console.log(`[countExactMentionsExcludingCitations] Found mention at ${matchStart}-${matchEnd}: \"${match[0]}\"`);\n        }\n      } else {\n        if (this.debug) {\n          console.log(`[countExactMentionsExcludingCitations] Skipped mention at ${matchStart}-${matchEnd} (in citation)`);\n        }\n      }\n    }\n    \n    if (this.debug) {\n      console.log(\"[countExactMentionsExcludingCitations] Total count (excluding citations):\", count);\n    }\n    \n    return count;\n  }\n\n  // --------------------------------------------------\n  // Markdown-Citations wie:\n  // [frehnertec.ch](https://www.frehnertec.ch/...)\n  // Oder auch: [text](https://www.frehnertec.ch/...)\n  // Gibt die Positionen (start, end) der Citations zur\u00FCck\n  // --------------------------------------------------\n  private findCitationRanges(\n    text: string,\n    brandDomain: string\n  ): Array<{ start: number; end: number }> {\n    // Pattern f\u00FCr Markdown-Links: [text](url)\n    // Wir suchen nach Links, die die Brand-Domain enthalten\n    const escapedDomain = this.escapeRegex(brandDomain);\n    \n    // Pattern: [irgendwas](url_mit_brand_domain)\n    const citationRegex = new RegExp(\n      `\\\\[([^\\\\]]*)\\\\]\\\\([^)]*${escapedDomain}[^)]*\\\\)`,\n      \"gi\"\n    );\n\n    if (this.debug) {\n      console.log(\"[findCitationRanges] Regex pattern:\", citationRegex.source);\n      console.log(\"[findCitationRanges] Escaped domain:\", escapedDomain);\n    }\n\n    const ranges: Array<{ start: number; end: number }> = [];\n    let match;\n    \n    while ((match = citationRegex.exec(text)) !== null) {\n      ranges.push({\n        start: match.index,\n        end: match.index + match[0].length\n      });\n    }\n    \n    if (this.debug) {\n      console.log(\"[findCitationRanges] Found citations:\", ranges.length);\n      console.log(\"[findCitationRanges] Citation ranges:\", ranges);\n    }\n\n    return ranges;\n  }\n\n  // --------------------------------------------------\n  // Kontext = ganze S\u00E4tze, die entweder\n  // - Brand-Namen ODER\n  // - Brand-Domain enthalten\n  // --------------------------------------------------\n  private extractContexts(\n    text: string,\n    brand: string,\n    brandDomain: string\n  ): string[] {\n    const sentences = text\n      .split(/(?<=[.!?])\\s+/)\n      .map(s => s.trim())\n      .filter(Boolean);\n\n    if (this.debug) {\n      console.log(\"[extractContexts] Total sentences:\", sentences.length);\n    }\n\n    const contexts: string[] = [];\n\n    for (const sentence of sentences) {\n      const lower = sentence.toLowerCase();\n\n      if (lower.includes(brand) || lower.includes(brandDomain)) {\n        if (!contexts.includes(sentence)) {\n          contexts.push(sentence);\n        }\n      }\n    }\n\n    if (this.debug) {\n      console.log(\"[extractContexts] Found contexts:\", contexts.length);\n    }\n\n    return contexts.slice(0, 5);\n  }\n\n  // --------------------------------------------------\n  // Regex-Sicherheit\n  // --------------------------------------------------\n  private escapeRegex(str: string): string {\n    return str.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n  }\n}", "/**\n * Sentiment analysis module\n */\n\nimport type { LLMResponse, SentimentAnalysis } from \"../types.js\";\n\nexport class SentimentAnalyzer {\n  private readonly positiveKeywords = [\n    \"excellent\",\n    \"great\",\n    \"best\",\n    \"top\",\n    \"leading\",\n    \"outstanding\",\n    \"superior\",\n    \"recommended\",\n    \"popular\",\n    \"trusted\",\n    \"reliable\",\n    \"innovative\",\n    \"effective\",\n    \"efficient\",\n    \"powerful\",\n    \"comprehensive\",\n    \"advanced\",\n    \"professional\",\n    \"quality\",\n    \"expert\",\n  ];\n\n  private readonly negativeKeywords = [\n    \"poor\",\n    \"bad\",\n    \"worst\",\n    \"limited\",\n    \"lacks\",\n    \"missing\",\n    \"inadequate\",\n    \"insufficient\",\n    \"problematic\",\n    \"difficult\",\n    \"complex\",\n    \"expensive\",\n    \"overpriced\",\n    \"slow\",\n    \"unreliable\",\n    \"outdated\",\n    \"inferior\",\n    \"weak\",\n    \"flawed\",\n    \"disappointing\",\n  ];\n\n  analyzeSentiment(response: LLMResponse): SentimentAnalysis {\n    const text = response.outputText.toLowerCase();\n    const words = text.split(/\\s+/);\n\n    let positiveScore = 0;\n    let negativeScore = 0;\n    const foundKeywords: string[] = [];\n\n    for (const word of words) {\n      const cleanWord = word.replace(/[.,!?;:]/g, \"\");\n\n      if (this.positiveKeywords.includes(cleanWord)) {\n        positiveScore++;\n        if (!foundKeywords.includes(cleanWord)) {\n          foundKeywords.push(cleanWord);\n        }\n      }\n\n      if (this.negativeKeywords.includes(cleanWord)) {\n        negativeScore++;\n        if (!foundKeywords.includes(cleanWord)) {\n          foundKeywords.push(cleanWord);\n        }\n      }\n    }\n\n    // Determine tone\n    let tone: SentimentAnalysis[\"tone\"];\n    const totalScore = positiveScore + negativeScore;\n\n    if (totalScore === 0) {\n      tone = \"neutral\";\n    } else if (positiveScore > negativeScore * 2) {\n      tone = \"positive\";\n    } else if (negativeScore > positiveScore * 2) {\n      tone = \"negative\";\n    } else {\n      tone = \"mixed\";\n    }\n\n    // Calculate confidence based on keyword density\n    const confidence = Math.min(\n      totalScore / Math.max(words.length / 100, 1),\n      1.0\n    );\n\n    return {\n      tone,\n      confidence: Math.max(confidence, 0.1), // Minimum confidence\n      keywords: foundKeywords.slice(0, 10),\n    };\n  }\n}\n\n\n\n\n\n\n\n", "/**\n * Utility functions for API handlers\n */\n\nexport function extractBrandName(websiteUrl: string): string {\n  try {\n    const url = new URL(websiteUrl);\n    const hostname = url.hostname;\n    // Remove www. prefix\n    const domain = hostname.replace(/^www\\./, '');\n    // Extract brand name (first part before first dot)\n    const brandName = domain.split('.')[0];\n    // Capitalize first letter\n    return brandName.charAt(0).toUpperCase() + brandName.slice(1);\n  } catch (e) {\n    // Fallback: use the URL itself\n    return websiteUrl.replace(/^https?:\\/\\//, '').replace(/^www\\./, '').split('/')[0].split('.')[0];\n  }\n}\n", "/**\n * Sitemap and Link Extraction Utilities\n */\n\n/**\n * Try to fetch sitemap from common locations\n */\nexport async function fetchSitemap(baseUrl: string): Promise<{ found: boolean; urls: string[]; content?: string }> {\n  const sitemapUrls = [\n    `${baseUrl}/sitemap.xml`,\n    `${baseUrl}/sitemap_index.xml`,\n    `${baseUrl}/sitemap/sitemap.xml`,\n  ];\n\n  for (const sitemapUrl of sitemapUrls) {\n    try {\n      const response = await fetch(sitemapUrl, {\n        headers: { \"User-Agent\": \"GEO-Platform/1.0\" },\n        signal: AbortSignal.timeout(10000),\n      });\n\n      if (response.ok) {\n        const content = await response.text();\n        const urls = parseSitemap(content);\n        if (urls.length > 0) {\n          return { found: true, urls, content };\n        }\n      }\n    } catch (error) {\n      // Continue to next sitemap URL\n      continue;\n    }\n  }\n\n  return { found: false, urls: [] };\n}\n\n/**\n * Parse sitemap XML and extract URLs\n */\nexport function parseSitemap(xml: string): string[] {\n  const urls: string[] = [];\n\n  // Handle sitemap index (contains links to other sitemaps)\n  const sitemapIndexMatch = xml.match(/<sitemapindex[^>]*>([\\s\\S]*?)<\\/sitemapindex>/i);\n  if (sitemapIndexMatch) {\n    const sitemapLinks = xml.matchAll(/<sitemap[^>]*>[\\s\\S]*?<loc[^>]*>([^<]+)<\\/loc>[\\s\\S]*?<\\/sitemap>/gi);\n    for (const match of sitemapLinks) {\n      urls.push(match[1].trim());\n    }\n    return urls; // Return sitemap URLs, not page URLs\n  }\n\n  // Handle regular sitemap\n  const urlMatches = xml.matchAll(/<url[^>]*>[\\s\\S]*?<loc[^>]*>([^<]+)<\\/loc>[\\s\\S]*?<\\/url>/gi);\n  for (const match of urlMatches) {\n    urls.push(match[1].trim());\n  }\n\n  return urls;\n}\n\n/**\n * Extract links from HTML content\n */\nexport function extractLinksFromHtml(html: string, baseUrl: string): string[] {\n  const links: string[] = [];\n  const baseUrlObj = new URL(baseUrl);\n  \n  // Find all <a> tags with href attributes\n  const linkMatches = html.matchAll(/<a[^>]+href=[\"']([^\"']+)[\"'][^>]*>/gi);\n  \n  for (const match of linkMatches) {\n    let href = match[1].trim();\n    \n    // Skip anchors, javascript, mailto, etc.\n    if (href.startsWith('#') || href.startsWith('javascript:') || href.startsWith('mailto:') || href.startsWith('tel:')) {\n      continue;\n    }\n    \n    try {\n      // Convert relative URLs to absolute\n      if (href.startsWith('/')) {\n        href = `${baseUrlObj.protocol}//${baseUrlObj.host}${href}`;\n      } else if (!href.startsWith('http')) {\n        href = new URL(href, baseUrl).toString();\n      }\n      \n      // Only include URLs from the same domain\n      const hrefUrl = new URL(href);\n      if (hrefUrl.hostname === baseUrlObj.hostname || hrefUrl.hostname.endsWith('.' + baseUrlObj.hostname)) {\n        links.push(href);\n      }\n    } catch (error) {\n      // Skip invalid URLs\n      continue;\n    }\n  }\n  \n  // Remove duplicates\n  return [...new Set(links)];\n}\n\n/**\n * Extract text content from HTML\n */\nexport function extractTextContent(html: string): string {\n  // Remove script and style tags\n  let text = html.replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\");\n  text = text.replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\");\n  text = text.replace(/<noscript[^>]*>[\\s\\S]*?<\\/noscript>/gi, \"\");\n  \n  // Remove HTML tags\n  text = text.replace(/<[^>]+>/g, \" \");\n  \n  // Clean up whitespace\n  text = text.replace(/\\s+/g, \" \").trim();\n  \n  return text;\n}\n\n/**\n * Check if URL should be fetched (exclude PDFs, images, etc.)\n */\nexport function shouldFetchUrl(url: string): boolean {\n  const urlLower = url.toLowerCase();\n  const excludedExtensions = [\n    '.pdf', '.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.bmp', '.ico',\n    '.mp4', '.mp3', '.avi', '.mov', '.wmv', '.flv',\n    '.zip', '.rar', '.tar', '.gz',\n    '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',\n    '.css', '.js', '.json', '.xml', '.txt'\n  ];\n  \n  // Check if URL ends with excluded extension\n  for (const ext of excludedExtensions) {\n    if (urlLower.endsWith(ext)) {\n      return false;\n    }\n  }\n  \n  // Check if URL contains image paths\n  if (urlLower.includes('/images/') || urlLower.includes('/img/') || \n      urlLower.includes('/assets/') && (urlLower.includes('.jpg') || urlLower.includes('.png') || urlLower.includes('.gif'))) {\n    return false;\n  }\n  \n  return true;\n}\n\n/**\n * Normalize URL to remove duplicates (remove trailing slash, normalize query params, etc.)\n */\nexport function normalizeUrl(url: string): string {\n  try {\n    const urlObj = new URL(url);\n    \n    // Remove trailing slash from pathname (except for root)\n    if (urlObj.pathname.length > 1 && urlObj.pathname.endsWith('/')) {\n      urlObj.pathname = urlObj.pathname.slice(0, -1);\n    }\n    \n    // Normalize to lowercase hostname\n    urlObj.hostname = urlObj.hostname.toLowerCase();\n    \n    // Remove default ports\n    if ((urlObj.protocol === 'https:' && urlObj.port === '443') ||\n        (urlObj.protocol === 'http:' && urlObj.port === '80')) {\n      urlObj.port = '';\n    }\n    \n    // Sort query parameters for consistent comparison\n    if (urlObj.search) {\n      const params = new URLSearchParams(urlObj.search);\n      const sortedParams = new URLSearchParams();\n      Array.from(params.keys()).sort().forEach(key => {\n        sortedParams.append(key, params.get(key) || '');\n      });\n      urlObj.search = sortedParams.toString();\n    }\n    \n    // Remove fragment\n    urlObj.hash = '';\n    \n    return urlObj.toString();\n  } catch (error) {\n    // If URL parsing fails, return original\n    return url;\n  }\n}\n\n/**\n * Deduplicate URLs by normalizing them\n */\nexport function deduplicateUrls(urls: string[]): string[] {\n  const seen = new Set<string>();\n  const unique: string[] = [];\n  \n  for (const url of urls) {\n    const normalized = normalizeUrl(url);\n    if (!seen.has(normalized)) {\n      seen.add(normalized);\n      unique.push(url); // Keep original URL, not normalized one\n    }\n  }\n  \n  return unique;\n}\n", "/**\n * Analysis API Handlers\n */\n\nimport type { Env, CorsHeaders } from \"../types.js\";\n\nexport class AnalysisHandlers {\n  constructor() {}\n\n  async handleGetAllAnalyses(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      const analyses = await db.getAllAnalysisRuns(100);\n      \n      // Ensure we always return an array, even if empty or if there's an error\n      const analysesArray = Array.isArray(analyses) ? analyses : [];\n      \n      return new Response(JSON.stringify(analysesArray), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting all analyses:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleGetAllCompanies(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      const companies = await db.getAllCompanies();\n      \n      return new Response(JSON.stringify(companies), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting all companies:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleGetCompanyAnalyses(\n    companyId: string,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      const analyses = await db.getCompanyAnalysisRuns(companyId, 100);\n      \n      return new Response(JSON.stringify(analyses), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting company analyses:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleGetGlobalCategories(\n    request: Request,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      const categories = await db.getAllGlobalCategories();\n      \n      // Always return an array, even if empty (retry logic handles errors internally)\n      return new Response(JSON.stringify(categories || []), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting global categories:\", error);\n      // Return empty array instead of 500 error to prevent frontend crashes\n      // The retry logic in Database class should handle most transient errors\n      return new Response(JSON.stringify([]), {\n        status: 200,\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    }\n  }\n\n  async handleGetGlobalPromptsByCategory(\n    categoryName: string,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      const prompts = await db.getGlobalPromptsByCategory(categoryName);\n      \n      return new Response(JSON.stringify(prompts), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting global prompts by category:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleDeleteAnalysis(\n    runId: string,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      await db.deleteAnalysis(runId);\n      \n      return new Response(\n        JSON.stringify({ success: true, message: \"Analysis deleted\" }),\n        {\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    } catch (error) {\n      console.error(\"Error deleting analysis:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n\n  async handleGetAnalysisPromptsAndSummary(\n    runId: string,\n    env: Env,\n    corsHeaders: CorsHeaders\n  ): Promise<Response> {\n    try {\n      const { Database } = await import(\"../../../shared/persistence/index.js\");\n      const db = new Database(env.geo_db as any);\n      \n      // Get prompts with answers\n      const prompts = await db.getPromptsForAnalysis(runId);\n      \n      // Get summary\n      const summary = await db.getSummary(runId);\n      \n      return new Response(JSON.stringify({\n        prompts,\n        summary,\n      }), {\n        headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      });\n    } catch (error) {\n      console.error(\"Error getting analysis prompts and summary:\", error);\n      return new Response(\n        JSON.stringify({\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        }),\n        {\n          status: 500,\n          headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n        }\n      );\n    }\n  }\n}\n\n", "/**\n * Interactive workflow engine for step-by-step analysis\n */\n\nimport type { UserInput, Category, Prompt } from \"./types.js\";\nimport type { Config } from \"./config.js\";\nimport { getConfig } from \"./config.js\";\nimport { SitemapParser } from \"./ingestion/sitemap.js\";\nimport { ContentScraper } from \"./ingestion/index.js\";\nimport { CategoryGenerator } from \"./categorization/index.js\";\nimport { PromptGenerator } from \"./prompt_generation/index.js\";\nimport { LLMExecutor } from \"./llm_execution/index.js\";\nimport { AnalysisEngine } from \"./analysis/index.js\";\nimport { Database } from \"./persistence/index.js\";\nimport type { D1Database } from \"./persistence/index.js\";\n// Note: OpenAI SDK might not be available in Workers, using fetch instead\n\nexport class WorkflowEngine {\n  private config: Config;\n  private contentScraper: ContentScraper;\n  private categoryGenerator: CategoryGenerator;\n  private promptGenerator: PromptGenerator;\n  private llmExecutor: LLMExecutor;\n  private sitemapParser: SitemapParser;\n  constructor(env: Record<string, any>) {\n    this.config = getConfig(env);\n    this.contentScraper = new ContentScraper(this.config.crawling);\n    this.categoryGenerator = new CategoryGenerator();\n    this.promptGenerator = new PromptGenerator();\n    this.llmExecutor = new LLMExecutor(this.config);\n    this.sitemapParser = new SitemapParser();\n  }\n\n  // Step 1: Find and parse sitemap\n  async step1FindSitemap(\n    userInput: UserInput,\n    env: Record<string, any>\n  ): Promise<{ runId: string; urls: string[]; foundSitemap: boolean }> {\n    try {\n      const runId = `run_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n      const db = new Database(env.geo_db as D1Database);\n\n      await db.saveAnalysisRun(runId, userInput, \"running\");\n\n      const result = await this.sitemapParser.findAndParseSitemap(\n        userInput.websiteUrl\n      );\n\n      await db.db\n        .prepare(\n          \"UPDATE analysis_runs SET sitemap_urls = ?, step = ?, updated_at = ? WHERE id = ?\"\n        )\n        .bind(JSON.stringify(result.urls), \"content\", new Date().toISOString(), runId)\n        .run();\n\n      return { runId, urls: result.urls, foundSitemap: result.foundSitemap };\n    } catch (error) {\n      console.error(\"Error in step1FindSitemap:\", error);\n      throw error;\n    }\n  }\n\n  private extractTextContent(html: string): string {\n    // Remove script and style tags\n    let text = html.replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\");\n    text = text.replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\");\n    // Remove HTML tags\n    text = text.replace(/<[^>]+>/g, \" \");\n    // Clean up whitespace\n    return text.replace(/\\s+/g, \" \").trim();\n  }\n\n  // Step 3: Generate categories/keywords with GPT\n  async step3GenerateCategories(\n    runId: string,\n    content: string,\n    language: string,\n    env: Record<string, any>\n  ): Promise<Category[]> {\n    const db = new Database(env.geo_db as D1Database);\n\n    // Use GPT to generate categories from content\n    const prompt = `Analyze the following website content and suggest 15-20 thematic categories/keywords that represent the main topics, products, or services. \nReturn only a JSON object with a \"categories\" array of objects: {\"categories\": [{\"name\": \"Category Name\", \"description\": \"Brief description\", \"keywords\": [\"keyword1\", \"keyword2\"]}]}\nContent (first 8000 chars): ${content.substring(0, 8000)}\nLanguage: ${language}\nReturn only valid JSON object with categories array, no other text.`;\n\n    try {\n      // Use OpenAI API via fetch (compatible with Workers) with timeout\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout\n      \n      let response: Response;\n      try {\n        response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            Authorization: `Bearer ${this.config.openai.apiKey}`,\n          },\n          body: JSON.stringify({\n            model: \"gpt-4o-mini\",\n            messages: [{ role: \"user\", content: prompt }],\n            response_format: { type: \"json_object\" },\n            temperature: 0.7,\n            max_tokens: 2000,\n          }),\n          signal: controller.signal,\n        });\n        clearTimeout(timeoutId);\n      } catch (fetchError: any) {\n        clearTimeout(timeoutId);\n        if (fetchError.name === 'AbortError') {\n          throw new Error(\"OpenAI API request timed out after 30 seconds\");\n        }\n        throw fetchError;\n      }\n\n      if (!response.ok) {\n        const errorText = await response.text();\n        throw new Error(`OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`);\n      }\n\n      const data = await response.json();\n      \n      if (!data.choices || !data.choices[0] || !data.choices[0].message) {\n        throw new Error(\"Invalid response format from OpenAI API\");\n      }\n\n      let gptResponse: any;\n      try {\n        const content = data.choices[0].message.content || \"{}\";\n        gptResponse = JSON.parse(content);\n      } catch (parseError) {\n        console.error(\"Failed to parse GPT response:\", data.choices[0].message.content);\n        throw new Error(\"Failed to parse JSON response from GPT\");\n      }\n\n      const categories: Category[] = [];\n\n      // Parse GPT response - handle both formats\n      let categoryArray = [];\n      if (gptResponse.categories && Array.isArray(gptResponse.categories)) {\n        categoryArray = gptResponse.categories;\n      } else if (Array.isArray(gptResponse)) {\n        categoryArray = gptResponse;\n      }\n\n      for (let i = 0; i < categoryArray.length; i++) {\n        const cat = categoryArray[i];\n        categories.push({\n          id: `cat_${runId}_${i}`,\n          name: cat.name || `Category ${i + 1}`,\n          description: cat.description || \"\",\n          confidence: 0.8,\n          sourcePages: [],\n        });\n      }\n\n      // Also use traditional category generator as fallback\n      // Extract domain from content or use a default\n      let rootDomain = \"\";\n      try {\n        // Try to extract domain from content if it contains URLs\n        const urlMatch = content.match(/https?:\\/\\/([^\\/\\s]+)/i);\n        if (urlMatch) {\n          rootDomain = urlMatch[1];\n        }\n      } catch (e) {\n        // Ignore\n      }\n\n      const traditionalCategories = this.categoryGenerator.generateCategories(\n        {\n          rootDomain: rootDomain,\n          pages: [],\n          normalizedContent: content,\n          language,\n        },\n        0.3,\n        10\n      );\n\n      // Merge and deduplicate\n      const allCategories = [...categories, ...traditionalCategories];\n      const uniqueCategories = Array.from(\n        new Map(allCategories.map((c) => [c.name, c])).values()\n      );\n\n      await db.saveCategories(runId, uniqueCategories);\n\n      return uniqueCategories;\n    } catch (error: any) {\n      console.error(\"GPT category generation error:\", error);\n      console.error(\"Error details:\", error?.message || error, error?.stack);\n      \n      // Fallback to traditional method\n      let rootDomain = \"\";\n      try {\n        const urlMatch = content.match(/https?:\\/\\/([^\\/\\s]+)/i);\n        if (urlMatch) {\n          rootDomain = urlMatch[1];\n        }\n      } catch (e) {\n        // Ignore\n      }\n      \n      const categories = this.categoryGenerator.generateCategories(\n        {\n          rootDomain: rootDomain,\n          pages: [],\n          normalizedContent: content,\n          language,\n        },\n        0.3,\n        15 // Generate more categories as fallback\n      );\n      \n      if (categories.length === 0) {\n        // Ultimate fallback: create some basic categories\n        categories.push(\n          {\n            id: `cat_${runId}_0`,\n            name: \"Products & Services\",\n            description: \"Main products and services offered\",\n            confidence: 0.5,\n            sourcePages: [],\n          },\n          {\n            id: `cat_${runId}_1`,\n            name: \"Features\",\n            description: \"Key features and capabilities\",\n            confidence: 0.5,\n            sourcePages: [],\n          },\n          {\n            id: `cat_${runId}_2`,\n            name: \"Use Cases\",\n            description: \"Use cases and applications\",\n            confidence: 0.5,\n            sourcePages: [],\n          }\n        );\n      }\n      \n      await db.saveCategories(runId, categories);\n      return categories;\n    }\n  }\n\n  // Step 4: Generate prompts (questionsPerCategory per category, no brand name) using GPT\n  // Always generates per category with rate limiting to avoid overwhelming the API\n  async step4GeneratePrompts(\n    runId: string,\n    categories: Category[],\n    userInput: UserInput,\n    content: string,\n    env: Record<string, any>,\n    questionsPerCategory: number = 3,\n    companyId?: string\n  ): Promise<Prompt[]> {\n    const db = new Database(env.geo_db as D1Database);\n\n    const totalQuestions = categories.length * questionsPerCategory;\n    const API_CALL_DELAY_MS = 2000; // 2 seconds delay between API calls to avoid rate limits\n    const MAX_CONCURRENT_CALLS = 3; // Maximum concurrent API calls\n    \n    console.log(`Generating ${questionsPerCategory} questions per category (${categories.length} categories) = ${totalQuestions} total, will keep ${questionsPerCategory} per category (${categories.length * questionsPerCategory} total)`);\n    \n    const allPrompts: Prompt[] = [];\n    let processedCount = 0;\n\n    // Process categories with rate limiting\n    for (let i = 0; i < categories.length; i++) {\n      const category = categories[i];\n      \n      // Add delay between API calls (except for the first one)\n      if (i > 0) {\n        console.log(`Waiting ${API_CALL_DELAY_MS}ms before next API call to avoid rate limits...`);\n        await new Promise(resolve => setTimeout(resolve, API_CALL_DELAY_MS));\n      }\n      \n      try {\n        console.log(`[${i + 1}/${categories.length}] Generating prompts for category: ${category.name} (requesting ${questionsPerCategory} questions)`);\n        const categoryPrompts = await this.generateCategoryPromptsWithGPT(\n          category,\n          userInput,\n          content,\n          questionsPerCategory,\n          runId\n        );\n        // Ensure we only add exactly questionsPerCategory prompts\n        const promptsToAdd = categoryPrompts.slice(0, questionsPerCategory);\n        if (promptsToAdd.length !== questionsPerCategory) {\n          console.warn(`[${i + 1}/${categories.length}] \u26A0\uFE0F Category ${category.name}: Got ${categoryPrompts.length} prompts, but expected ${questionsPerCategory}. Using first ${promptsToAdd.length}.`);\n        }\n        allPrompts.push(...promptsToAdd);\n        processedCount++;\n        console.log(`[${i + 1}/${categories.length}] \u2713 Added ${promptsToAdd.length} prompts for ${category.name} (expected: ${questionsPerCategory})`);\n      } catch (error: any) {\n        console.error(`[${i + 1}/${categories.length}] \u2717 Error generating prompts for category ${category.name}:`, error);\n        // Fallback to template-based generation for this category\n        const fallbackPrompts = this.promptGenerator.generatePrompts(\n          [category],\n          userInput,\n          questionsPerCategory\n        );\n        // Ensure we only add exactly questionsPerCategory prompts\n        const promptsToAdd = fallbackPrompts.slice(0, questionsPerCategory);\n        allPrompts.push(...promptsToAdd);\n        console.log(`[${i + 1}/${categories.length}] \u2713 Used fallback: Added ${promptsToAdd.length} prompts for ${category.name} (expected: ${questionsPerCategory})`);\n      }\n    }\n    \n    console.log(`Completed: Generated ${allPrompts.length} prompts across ${processedCount}/${categories.length} categories`);\n\n    // Filter to keep exactly questionsPerCategory questions per selected category\n    const filteredPrompts: Prompt[] = [];\n    const categoryPromptMap = new Map<string, Prompt[]>();\n    \n    // Group prompts by category\n    for (const prompt of allPrompts) {\n      if (!categoryPromptMap.has(prompt.categoryId)) {\n        categoryPromptMap.set(prompt.categoryId, []);\n      }\n      categoryPromptMap.get(prompt.categoryId)!.push(prompt);\n    }\n    \n    // Debug: Log how many prompts per category before filtering\n    console.log(`[step4GeneratePrompts] Before filtering: ${allPrompts.length} total prompts`);\n    for (const [categoryId, prompts] of categoryPromptMap.entries()) {\n      const category = categories.find(c => c.id === categoryId);\n      console.log(`[step4GeneratePrompts] Category ${category?.name || categoryId}: ${prompts.length} prompts generated`);\n    }\n    \n    // Keep exactly questionsPerCategory questions from each category\n    for (const [categoryId, prompts] of categoryPromptMap.entries()) {\n      // Take exactly questionsPerCategory questions from this category\n      const promptsToKeep = prompts.slice(0, questionsPerCategory);\n      if (promptsToKeep.length !== questionsPerCategory) {\n        console.warn(`[step4GeneratePrompts] \u26A0\uFE0F Category ${categoryId}: Only ${promptsToKeep.length} prompts available, but ${questionsPerCategory} requested`);\n      }\n      filteredPrompts.push(...promptsToKeep);\n      const category = categories.find(c => c.id === categoryId);\n      console.log(`[step4GeneratePrompts] Category ${category?.name || categoryId}: Keeping ${promptsToKeep.length} prompts (requested: ${questionsPerCategory})`);\n    }\n    \n    const expectedTotal = categories.length * questionsPerCategory;\n    if (filteredPrompts.length !== expectedTotal) {\n      console.warn(`[step4GeneratePrompts] \u26A0\uFE0F Expected ${expectedTotal} prompts (${questionsPerCategory} \u00D7 ${categories.length} categories), but got ${filteredPrompts.length}`);\n    } else {\n      console.log(`[step4GeneratePrompts] \u2713 Filtered to ${filteredPrompts.length} prompts (${questionsPerCategory} per category, ${categories.length} categories = ${expectedTotal} total)`);\n    }\n\n    // DO NOT save prompts here - they will only be saved after successful execution with responses\n    // This ensures only questions that were actually asked and have answers are stored\n\n    // Wrap database update in retry logic to handle timeouts\n    await db.retryD1Operation(async () => {\n      await db.db\n        .prepare(\n          \"UPDATE analysis_runs SET prompts_generated = ?, step = ?, updated_at = ? WHERE id = ?\"\n        )\n        .bind(\n          filteredPrompts.length,\n          \"prompts\",\n          new Date().toISOString(),\n          runId\n        )\n        .run();\n    }, 3, 150, \"step4UpdateAnalysisRun\");\n\n    return filteredPrompts;\n  }\n\n  private async generateAllCategoryPromptsWithGPT(\n    categories: Category[],\n    userInput: UserInput,\n    content: string,\n    questionsPerCategory: number,\n    runId: string\n  ): Promise<Prompt[]> {\n    // Debug mode: Return dummy prompts without making API calls\n    if (this.config.debug?.enabled) {\n      console.log('\uD83D\uDC1B DEBUG MODE: Returning dummy prompts (no API call)');\n      const allPrompts: Prompt[] = [];\n      for (const category of categories) {\n        const dummyPrompts = await this.getDummyPrompts(category, userInput, questionsPerCategory, runId);\n        allPrompts.push(...dummyPrompts);\n      }\n      return allPrompts;\n    }\n\n    const regionText = userInput.region || userInput.country;\n    const totalQuestions = categories.length * questionsPerCategory;\n    \n    // Build categories description\n    const categoriesList = categories.map(c => `- ${c.name}: ${c.description}`).join('\\n');\n    \n    const prompt = `Du bist ein Experte f\u00FCr Kundenerfahrung. Generiere f\u00FCr jede der folgenden Kategorien genau ${questionsPerCategory} SEHR REALISTISCHE, DIREKTE Fragen in ${userInput.language}, die echte Kunden wirklich in einer Suchmaschine oder ChatGPT eingeben w\u00FCrden.\n\nKRITISCHE ANFORDERUNGEN:\n- Fragen m\u00FCssen brand-neutral sein (KEINE Firmennamen, KEINE Markennamen)\n- Verwende SEHR DIREKTE, SUCHMASCHINEN-\u00C4HNLICHE Formulierungen\n- BEVORZUGE \"Wer ist...\" Fragen statt \"Wie...\" Fragen\n- Integriere IMMER LOKALE/REGIONALE Bez\u00FCge (z.B. \"${regionText}\", \"in Graub\u00FCnden\", \"in Z\u00FCrich\")\n- Fragen sollten kurz, pr\u00E4gnant und sehr spezifisch sein\n- Verwende Formulierungen wie \"Wer ist...\", \"Wer bietet...\", \"Wer verkauft...\", \"Gibt es...\", \"Was kostet...\"\n- Vermeide \"Wie...\" Fragen - verwende stattdessen direkte Suchanfragen\n- Fragen sollten zeigen, dass der Kunde aktiv nach einem Anbieter/L\u00F6sung sucht\n\nBeispiele f\u00FCr PERFEKTE kundenorientierte Fragen (${userInput.language}):\n${userInput.language === 'de' ? `\n- \"Wer ist in ${regionText} f\u00FCr Kassensystem?\"\n- \"Wer bietet Kassensysteme in ${regionText}?\"\n- \"Gibt es Kassensysteme f\u00FCr Restaurants in ${regionText}?\"\n- \"Was kostet ein Kassensystem in ${regionText}?\"\n` : userInput.language === 'en' ? `\n- \"Who is in ${regionText} for POS system?\"\n- \"Who offers POS systems in ${regionText}?\"\n- \"Are there POS systems for restaurants in ${regionText}?\"\n- \"What does a POS system cost in ${regionText}?\"\n` : `\n- \"Qui est en ${regionText} pour syst\u00E8me de caisse?\"\n- \"Qui offre des syst\u00E8mes de caisse en ${regionText}?\"\n- \"Y a-t-il des syst\u00E8mes de caisse pour restaurants en ${regionText}?\"\n`}\n\nKategorien (f\u00FCr jede Kategorie genau ${questionsPerCategory} Fragen generieren):\n${categoriesList}\n\nKontext:\n- Land: ${userInput.country}\n- Region: ${userInput.region || userInput.country}\n- Sprache: ${userInput.language}\n- Relevanter Inhaltsauszug: ${content.substring(0, 2000)}\n\nWICHTIG: \n- Die Fragen m\u00FCssen so klingen, als ob ein echter Kunde sie direkt in eine Suchmaschine oder ChatGPT eingibt\n- BEVORZUGE \"Wer ist...\" statt \"Wie...\"\n- IMMER lokale/regionale Bez\u00FCge einbauen\n- Sei SEHR DIREKT und PR\u00C4GNANT\n- F\u00FCr jede Kategorie genau ${questionsPerCategory} Fragen generieren\n\nGib nur ein JSON-Objekt zur\u00FCck mit einem \"categories\" Array, wobei jedes Element eine Kategorie mit ihren Fragen enth\u00E4lt:\n{\n  \"categories\": [\n    {\n      \"categoryName\": \"Kategorie 1 Name\",\n      \"questions\": [\"Frage 1\", \"Frage 2\", \"Frage ${questionsPerCategory}\"]\n    },\n    {\n      \"categoryName\": \"Kategorie 2 Name\", \n      \"questions\": [\"Frage 1\", \"Frage 2\", \"Frage ${questionsPerCategory}\"]\n    }\n  ]\n}\nKein anderer Text, nur g\u00FCltiges JSON.`;\n\n    try {\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), 60000); // 60 second timeout for multiple categories\n      \n      let response: Response;\n      try {\n        response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            Authorization: `Bearer ${this.config.openai.apiKey}`,\n          },\n          body: JSON.stringify({\n            model: \"gpt-4o-mini\",\n            messages: [{ role: \"user\", content: prompt }],\n            response_format: { type: \"json_object\" },\n            temperature: 0.8,\n            max_tokens: 2000, // More tokens for multiple categories\n          }),\n          signal: controller.signal,\n        });\n        clearTimeout(timeoutId);\n      } catch (fetchError: any) {\n        clearTimeout(timeoutId);\n        if (fetchError.name === 'AbortError') {\n          throw new Error(\"OpenAI API request timed out after 60 seconds\");\n        }\n        throw fetchError;\n      }\n\n      if (!response.ok) {\n        const errorText = await response.text();\n        throw new Error(`OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`);\n      }\n\n      const data = await response.json();\n      \n      if (!data.choices || !data.choices[0] || !data.choices[0].message) {\n        throw new Error(\"Invalid response format from OpenAI API\");\n      }\n\n      let gptResponse: any;\n      try {\n        const responseContent = data.choices[0].message.content || \"{}\";\n        gptResponse = JSON.parse(responseContent);\n      } catch (parseError) {\n        console.error(\"Failed to parse GPT response:\", data.choices[0].message.content);\n        throw new Error(\"Failed to parse JSON response from GPT\");\n      }\n\n      const categoriesData = gptResponse.categories || [];\n      const allPrompts: Prompt[] = [];\n      const now = new Date().toISOString();\n\n      for (const categoryData of categoriesData) {\n        const categoryName = categoryData.categoryName;\n        const questions = categoryData.questions || [];\n        \n        // Find matching category - try exact match first, then fuzzy match\n        let category = categories.find(c => c.name === categoryName);\n        \n        // If exact match fails, try case-insensitive or partial match\n        if (!category) {\n          category = categories.find(c => \n            c.name.toLowerCase() === categoryName.toLowerCase() ||\n            categoryName.toLowerCase().includes(c.name.toLowerCase()) ||\n            c.name.toLowerCase().includes(categoryName.toLowerCase())\n          );\n        }\n        \n        if (!category) {\n          console.warn(`Category \"${categoryName}\" from GPT not found in original categories. Available: ${categories.map(c => c.name).join(', ')}`);\n          // Try to match by index if count matches\n          const index = categoriesData.indexOf(categoryData);\n          if (index < categories.length) {\n            category = categories[index];\n            console.log(`Using category by index: ${category.name}`);\n          } else {\n            continue;\n          }\n        }\n\n        // Process questions, ensuring we get exactly 'questionsPerCategory' questions per category\n        for (let i = 0; i < questions.length && allPrompts.filter(p => p.categoryId === category.id).length < questionsPerCategory; i++) {\n          const question = questions[i];\n          if (question && typeof question === 'string' && question.trim()) {\n            allPrompts.push({\n              id: `prompt_${runId}_${category.id}_${allPrompts.filter(p => p.categoryId === category.id).length}_${Date.now()}_${Math.random().toString(36).substring(7)}`,\n              categoryId: category.id,\n              question: question.trim(),\n              language: userInput.language,\n              country: userInput.country,\n              region: userInput.region,\n              intent: \"high\",\n              createdAt: now,\n            });\n          }\n        }\n        \n        // If we got fewer questions than requested for this category, fill with fallback\n        const categoryPromptCount = allPrompts.filter(p => p.categoryId === category.id).length;\n        if (categoryPromptCount < questionsPerCategory) {\n          console.warn(`Category ${category.name}: Only got ${categoryPromptCount} questions, using fallback for remaining ${questionsPerCategory - categoryPromptCount}`);\n          const fallbackPrompts = this.promptGenerator.generatePrompts(\n            [category],\n            userInput,\n            questionsPerCategory - categoryPromptCount\n          );\n          allPrompts.push(...fallbackPrompts.slice(0, questionsPerCategory - categoryPromptCount));\n        }\n      }\n\n      // Ensure we have the right number of prompts\n      if (allPrompts.length < totalQuestions) {\n        console.warn(`Generated ${allPrompts.length} prompts, expected ${totalQuestions}. Filling with template-based prompts.`);\n        const existingCount = allPrompts.length;\n        const fallbackPrompts = this.promptGenerator.generatePrompts(\n          categories,\n          userInput,\n          questionsPerCategory\n        );\n        // Only add prompts we're missing\n        const needed = totalQuestions - existingCount;\n        allPrompts.push(...fallbackPrompts.slice(0, needed));\n      }\n\n      return allPrompts.slice(0, totalQuestions); // Ensure we don't exceed expected count\n    } catch (error: any) {\n      console.error(\"Error in generateAllCategoryPromptsWithGPT:\", error);\n      throw error;\n    }\n  }\n\n  private async generateCategoryPromptsWithGPT(\n    category: Category,\n    userInput: UserInput,\n    content: string,\n    count: number,\n    runId: string\n  ): Promise<Prompt[]> {\n    // Debug mode: Return dummy prompts without making API calls\n    if (this.config.debug?.enabled) {\n      console.log('\uD83D\uDC1B DEBUG MODE: Returning dummy prompts (no API call)');\n      return this.getDummyPrompts(category, userInput, count, runId);\n    }\n\n    const regionText = userInput.region || userInput.country;\n    const prompt = `Du bist ein Experte f\u00FCr Kundenerfahrung. Generiere genau ${count} SEHR REALISTISCHE, DIREKTE Fragen in ${userInput.language}, die echte Kunden wirklich in einer Suchmaschine oder ChatGPT eingeben w\u00FCrden.\n\nKRITISCHE ANFORDERUNGEN:\n- Fragen m\u00FCssen brand-neutral sein (KEINE Firmennamen, KEINE Markennamen)\n- Verwende SEHR DIREKTE, SUCHMASCHINEN-\u00C4HNLICHE Formulierungen\n- BEVORZUGE \"Wer ist...\" Fragen statt \"Wie...\" Fragen\n- Integriere IMMER LOKALE/REGIONALE Bez\u00FCge (z.B. \"${regionText}\", \"in Graub\u00FCnden\", \"in Z\u00FCrich\")\n- Fragen sollten kurz, pr\u00E4gnant und sehr spezifisch sein\n- Verwende Formulierungen wie \"Wer ist...\", \"Wer bietet...\", \"Wer verkauft...\", \"Gibt es...\", \"Was kostet...\"\n- Vermeide \"Wie...\" Fragen - verwende stattdessen direkte Suchanfragen\n- Fragen sollten zeigen, dass der Kunde aktiv nach einem Anbieter/L\u00F6sung sucht\n\nBeispiele f\u00FCr PERFEKTE kundenorientierte Fragen (${userInput.language}):\n${userInput.language === 'de' ? `\n- \"Wer ist in ${regionText} f\u00FCr Kassensystem?\"\n- \"Wer bietet Kassensysteme in ${regionText}?\"\n- \"Gibt es Kassensysteme f\u00FCr Restaurants in ${regionText}?\"\n- \"Was kostet ein Kassensystem in ${regionText}?\"\n- \"Wer verkauft Kassensysteme f\u00FCr kleine L\u00E4den in ${regionText}?\"\n- \"Welche Kassensysteme gibt es in ${regionText}?\"\n- \"Wer ist der beste Anbieter f\u00FCr Kassensysteme in ${regionText}?\"\n` : userInput.language === 'en' ? `\n- \"Who is in ${regionText} for POS system?\"\n- \"Who offers POS systems in ${regionText}?\"\n- \"Are there POS systems for restaurants in ${regionText}?\"\n- \"What does a POS system cost in ${regionText}?\"\n- \"Who sells POS systems for small shops in ${regionText}?\"\n- \"What POS systems are available in ${regionText}?\"\n- \"Who is the best provider for POS systems in ${regionText}?\"\n` : `\n- \"Qui est en ${regionText} pour syst\u00E8me de caisse?\"\n- \"Qui offre des syst\u00E8mes de caisse en ${regionText}?\"\n- \"Y a-t-il des syst\u00E8mes de caisse pour restaurants en ${regionText}?\"\n- \"Combien co\u00FBte un syst\u00E8me de caisse en ${regionText}?\"\n- \"Qui vend des syst\u00E8mes de caisse pour petits magasins en ${regionText}?\"\n`}\n\nKontext:\n- Kategorie: ${category.name} - ${category.description}\n- Land: ${userInput.country}\n- Region: ${userInput.region || userInput.country}\n- Sprache: ${userInput.language}\n- Relevanter Inhaltsauszug: ${content.substring(0, 2000)}\n\nWICHTIG: \n- Die Fragen m\u00FCssen so klingen, als ob ein echter Kunde sie direkt in eine Suchmaschine oder ChatGPT eingibt\n- BEVORZUGE \"Wer ist...\" statt \"Wie...\"\n- IMMER lokale/regionale Bez\u00FCge einbauen\n- Sei SEHR DIREKT und PR\u00C4GNANT\n\nGib nur ein JSON-Objekt mit einem \"questions\" Array zur\u00FCck, das genau ${count} Fragen enth\u00E4lt:\n{\"questions\": [\"Frage 1 in ${userInput.language}\", \"Frage 2 in ${userInput.language}\", ...]}\nKein anderer Text, nur g\u00FCltiges JSON.`;\n\n      try {\n        const controller = new AbortController();\n        const timeoutId = setTimeout(() => controller.abort(), 45000); // 45 second timeout per category\n      \n      let response: Response;\n      try {\n        response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            Authorization: `Bearer ${this.config.openai.apiKey}`,\n          },\n          body: JSON.stringify({\n            model: \"gpt-4o-mini\",\n            messages: [{ role: \"user\", content: prompt }],\n            response_format: { type: \"json_object\" },\n            temperature: 0.8,\n            max_tokens: 1000,\n          }),\n          signal: controller.signal,\n        });\n        clearTimeout(timeoutId);\n      } catch (fetchError: any) {\n        clearTimeout(timeoutId);\n        if (fetchError.name === 'AbortError') {\n          throw new Error(\"OpenAI API request timed out after 30 seconds\");\n        }\n        throw fetchError;\n      }\n\n      if (!response.ok) {\n        const errorText = await response.text();\n        throw new Error(`OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`);\n      }\n\n      const data = await response.json();\n      \n      if (!data.choices || !data.choices[0] || !data.choices[0].message) {\n        throw new Error(\"Invalid response format from OpenAI API\");\n      }\n\n      let gptResponse: any;\n      try {\n        const responseContent = data.choices[0].message.content || \"{}\";\n        gptResponse = JSON.parse(responseContent);\n      } catch (parseError) {\n        console.error(\"Failed to parse GPT response:\", data.choices[0].message.content);\n        throw new Error(\"Failed to parse JSON response from GPT\");\n      }\n\n      const questions = gptResponse.questions || [];\n      const prompts: Prompt[] = [];\n\n      // Process questions, ensuring we get exactly 'count' questions\n      for (let i = 0; i < questions.length && prompts.length < count; i++) {\n        const question = questions[i];\n        if (question && typeof question === 'string' && question.trim().length > 0) {\n          prompts.push({\n            id: `prompt_${runId}_${category.id}_${prompts.length}_${Date.now()}_${Math.random().toString(36).substring(7)}`,\n            categoryId: category.id,\n            question: question.trim(),\n            language: userInput.language,\n            country: userInput.country,\n            region: userInput.region,\n            intent: \"high\",\n            createdAt: new Date().toISOString(),\n          });\n        }\n      }\n\n      // If we got fewer questions than requested, fill with fallback to ensure exactly 'count' questions\n      if (prompts.length < count) {\n        console.warn(`Only got ${prompts.length} questions for category ${category.name}, using fallback for remaining ${count - prompts.length}`);\n        const fallbackPrompts = this.promptGenerator.generatePrompts([category], userInput, count - prompts.length);\n        const needed = count - prompts.length;\n        prompts.push(...fallbackPrompts.slice(0, needed));\n      }\n\n      // Ensure we return exactly 'count' questions (trim if GPT returned more)\n      const finalPrompts = prompts.slice(0, count);\n      console.log(`[generateCategoryPromptsWithGPT] Category ${category.name}: Generated ${prompts.length} prompts, returning exactly ${finalPrompts.length} (requested: ${count})`);\n      return finalPrompts;\n    } catch (error: any) {\n      console.error(`Error generating prompts for category ${category.name}:`, error);\n      console.error(\"Error details:\", error?.message || error, error?.stack);\n      // Fallback to template-based generation\n      const fallbackPrompts = this.promptGenerator.generatePrompts([category], userInput, count);\n      return fallbackPrompts;\n    }\n  }\n\n  private getDummyPrompts(\n    category: Category,\n    userInput: UserInput,\n    count: number,\n    runId: string\n  ): Prompt[] {\n    const regionText = userInput.region || userInput.country;\n    const prompts: Prompt[] = [];\n    \n    // Generate dummy questions based on category and language\n    const questionTemplates: Record<string, string[]> = {\n      de: [\n        `Wer ist in ${regionText} f\u00FCr ${category.name}?`,\n        `Wer bietet ${category.name} in ${regionText}?`,\n        `Gibt es ${category.name} f\u00FCr Unternehmen in ${regionText}?`,\n        `Was kostet ${category.name} in ${regionText}?`,\n        `Wer verkauft ${category.name} in ${regionText}?`,\n        `Welche ${category.name} gibt es in ${regionText}?`,\n        `Wer ist der beste Anbieter f\u00FCr ${category.name} in ${regionText}?`,\n        `Wo finde ich ${category.name} in ${regionText}?`,\n      ],\n      en: [\n        `Who is in ${regionText} for ${category.name}?`,\n        `Who offers ${category.name} in ${regionText}?`,\n        `Are there ${category.name} for businesses in ${regionText}?`,\n        `What does ${category.name} cost in ${regionText}?`,\n        `Who sells ${category.name} in ${regionText}?`,\n        `What ${category.name} are available in ${regionText}?`,\n        `Who is the best provider for ${category.name} in ${regionText}?`,\n        `Where can I find ${category.name} in ${regionText}?`,\n      ],\n      fr: [\n        `Qui est en ${regionText} pour ${category.name}?`,\n        `Qui offre ${category.name} en ${regionText}?`,\n        `Y a-t-il ${category.name} pour entreprises en ${regionText}?`,\n        `Combien co\u00FBte ${category.name} en ${regionText}?`,\n        `Qui vend ${category.name} en ${regionText}?`,\n        `Quels ${category.name} sont disponibles en ${regionText}?`,\n        `Qui est le meilleur fournisseur pour ${category.name} en ${regionText}?`,\n        `O\u00F9 puis-je trouver ${category.name} en ${regionText}?`,\n      ],\n    };\n\n    const templates = questionTemplates[userInput.language] || questionTemplates.de;\n    \n    for (let i = 0; i < count; i++) {\n      const template = templates[i % templates.length];\n      prompts.push({\n        id: `prompt_${runId}_${category.id}_${i}`,\n        categoryId: category.id,\n        question: template,\n        language: userInput.language,\n        country: userInput.country,\n        region: userInput.region,\n        intent: \"high\",\n        createdAt: new Date().toISOString(),\n      });\n    }\n\n    return prompts;\n  }\n\n  // Save selected prompts\n  async saveSelectedPrompts(\n    runId: string,\n    selectedPrompts: Prompt[],\n    env: Record<string, any>\n  ): Promise<Prompt[]> {\n    const db = new Database(env.geo_db as D1Database);\n\n    await db.savePrompts(runId, selectedPrompts);\n\n    await db.db\n      .prepare(\n        \"UPDATE analysis_runs SET prompts_generated = ?, step = ?, updated_at = ? WHERE id = ?\"\n      )\n      .bind(\n        selectedPrompts.length,\n        \"prompts\",\n        new Date().toISOString(),\n        runId\n      )\n      .run();\n\n    return selectedPrompts;\n  }\n\n  // Step 5: Execute prompts with GPT-5 Web Search\n  // Only saves prompts that were successfully executed and have responses\n  async step5ExecutePrompts(\n    runId: string,\n    prompts: Prompt[],\n    env: Record<string, any>\n  ): Promise<{ executed: number }> {\n    const db = new Database(env.geo_db as D1Database);\n\n    await db.db\n      .prepare(\"UPDATE analysis_runs SET step = ?, updated_at = ? WHERE id = ?\")\n      .bind(\"execution\", new Date().toISOString(), runId)\n      .run();\n\n    const responses = await this.llmExecutor.executePrompts(prompts);\n    \n    // Only save prompts that have successful responses\n    const promptsWithResponses: Prompt[] = [];\n    const validResponses: any[] = [];\n    \n    for (let i = 0; i < responses.length; i++) {\n      const response = responses[i];\n      // Only include prompts that have a valid response with output text\n      if (response && response.outputText && response.outputText.trim().length > 0) {\n        // Find the corresponding prompt\n        const prompt = prompts.find(p => p.id === response.promptId);\n        if (prompt) {\n          promptsWithResponses.push(prompt);\n          validResponses.push(response);\n        }\n      }\n    }\n    \n    // Save only prompts that have successful responses\n    if (promptsWithResponses.length > 0) {\n      await db.savePrompts(runId, promptsWithResponses);\n      console.log(`Saved ${promptsWithResponses.length} prompts with successful responses (out of ${prompts.length} total)`);\n    } else {\n      console.warn(`No prompts with valid responses to save (${prompts.length} prompts executed, ${responses.length} responses received)`);\n    }\n    \n    // Save all responses (including failed ones for debugging, but only prompts with valid responses are saved)\n    await db.saveLLMResponses(responses);\n\n    await db.db\n      .prepare(\"UPDATE analysis_runs SET step = ?, updated_at = ? WHERE id = ?\")\n      .bind(\"completed\", new Date().toISOString(), runId)\n      .run();\n\n    return { executed: validResponses.length };\n  }\n\n  // Save user-selected categories\n  async saveSelectedCategories(\n    runId: string,\n    categoryIds: string[],\n    customCategories: Category[],\n    env: Record<string, any>\n  ): Promise<void> {\n    const db = new Database(env.geo_db as D1Database);\n\n    // Save custom categories\n    if (customCategories.length > 0) {\n      await db.saveCategories(runId, customCategories);\n    }\n\n    await db.db\n      .prepare(\n        \"UPDATE analysis_runs SET selected_categories = ?, custom_categories = ?, updated_at = ? WHERE id = ?\"\n      )\n      .bind(\n        JSON.stringify(categoryIds),\n        JSON.stringify(customCategories),\n        new Date().toISOString(),\n        runId\n      )\n      .run();\n  }\n\n  // Save user-edited prompts\n}\n\n", "/**\n * Sitemap.xml parser and crawler\n */\n\nexport interface SitemapUrl {\n  loc: string;\n  lastmod?: string;\n  changefreq?: string;\n  priority?: string;\n}\n\nexport class SitemapParser {\n  async findAndParseSitemap(baseUrl: string): Promise<{ urls: string[]; foundSitemap: boolean }> {\n    const sitemapUrls = [\n      `${baseUrl}/sitemap.xml`,\n      `${baseUrl}/sitemap_index.xml`,\n      `${baseUrl}/sitemaps/sitemap.xml`,\n    ];\n\n    for (const sitemapUrl of sitemapUrls) {\n      try {\n        const response = await fetch(sitemapUrl, {\n          headers: {\n            \"User-Agent\": \"GEO-Platform/1.0\",\n          },\n          signal: AbortSignal.timeout(10000) // 10 second timeout\n        });\n\n        if (response.ok) {\n          const xml = await response.text();\n          const urls = this.parseSitemap(xml);\n          if (urls.length > 0) {\n            return { urls, foundSitemap: true };\n          }\n        }\n      } catch (error) {\n        // Try next sitemap URL\n        continue;\n      }\n    }\n\n    // If no sitemap found, crawl homepage and extract internal links\n    console.log(\"\u26A0\uFE0F Keine Sitemap gefunden. Crawle Startseite und extrahiere interne Links...\");\n    const urls = await this.crawlHomepageForLinks(baseUrl);\n    return { urls, foundSitemap: false };\n  }\n\n  private async crawlHomepageForLinks(baseUrl: string): Promise<string[]> {\n    const urls: string[] = [];\n    const baseUrlObj = new URL(baseUrl);\n    const visited = new Set<string>();\n    \n    try {\n      // Fetch homepage\n      const response = await fetch(baseUrl, {\n        headers: {\n          \"User-Agent\": \"GEO-Platform/1.0\",\n        },\n        signal: AbortSignal.timeout(10000) // 10 second timeout\n      });\n\n      if (!response.ok) {\n        console.error(\"Failed to fetch homepage:\", response.status);\n        return [baseUrl]; // Return at least the homepage\n      }\n\n      const html = await response.text();\n      urls.push(baseUrl); // Add homepage\n      visited.add(baseUrl);\n\n      // Extract all links from homepage\n      const linkRegex = /<a\\s+[^>]*href=[\"']([^\"']+)[\"'][^>]*>/gi;\n      let match;\n      const foundLinks = new Set<string>();\n\n      while ((match = linkRegex.exec(html)) !== null) {\n        const href = match[1].trim();\n        if (!href || href.startsWith('#') || href.startsWith('javascript:') || href.startsWith('mailto:')) {\n          continue;\n        }\n\n        try {\n          // Resolve relative URLs\n          const absoluteUrl = new URL(href, baseUrl).href;\n          const urlObj = new URL(absoluteUrl);\n\n          // Only include internal links (same domain)\n          if (urlObj.hostname === baseUrlObj.hostname || urlObj.hostname === `www.${baseUrlObj.hostname}` || baseUrlObj.hostname === `www.${urlObj.hostname}`) {\n            // Normalize URL (remove fragment, trailing slash)\n            const normalizedUrl = urlObj.origin + urlObj.pathname + (urlObj.search || '');\n            if (!visited.has(normalizedUrl) && !normalizedUrl.endsWith('.pdf') && !normalizedUrl.endsWith('.jpg') && !normalizedUrl.endsWith('.png') && !normalizedUrl.endsWith('.gif') && !normalizedUrl.endsWith('.zip')) {\n              foundLinks.add(normalizedUrl);\n            }\n          }\n        } catch (e) {\n          // Invalid URL, skip\n          continue;\n        }\n      }\n\n      // Convert to array and limit to reasonable number\n      const linkArray = Array.from(foundLinks);\n      const maxLinks = 50; // Limit to prevent too many URLs\n      urls.push(...linkArray.slice(0, maxLinks));\n\n      console.log(`\u2705 ${urls.length} URLs von Startseite extrahiert (${foundLinks.size} interne Links gefunden)`);\n      \n      return urls;\n    } catch (error) {\n      console.error(\"Error crawling homepage:\", error);\n      // Return at least the homepage\n      return [baseUrl];\n    }\n  }\n\n  private parseSitemap(xml: string): string[] {\n    const urls: string[] = [];\n\n    // Parse sitemap.xml format\n    const urlRegex = /<loc>(.*?)<\\/loc>/gi;\n    let match;\n    while ((match = urlRegex.exec(xml)) !== null) {\n      const url = match[1].trim();\n      if (url) {\n        urls.push(url);\n      }\n    }\n\n    // Also check for sitemap index\n    const sitemapIndexRegex = /<sitemap><loc>(.*?)<\\/loc><\\/sitemap>/gi;\n    while ((match = sitemapIndexRegex.exec(xml)) !== null) {\n      const sitemapUrl = match[1].trim();\n      // Could recursively fetch, but for now just note it\n      console.log(\"Found sitemap index:\", sitemapUrl);\n    }\n\n    return urls;\n  }\n\n  async parseSitemapFromUrl(sitemapUrl: string): Promise<string[]> {\n    try {\n      const response = await fetch(sitemapUrl, {\n        headers: {\n          \"User-Agent\": \"GEO-Platform/1.0\",\n        },\n        signal: AbortSignal.timeout(10000) // 10 second timeout\n      });\n\n      if (!response.ok) {\n        return [];\n      }\n\n      const xml = await response.text();\n      return this.parseSitemap(xml);\n    } catch (error) {\n      console.error(\"Error parsing sitemap:\", error);\n      return [];\n    }\n  }\n}\n\n", "/**\n * Ingestion module entry point\n */\n\nexport { WebsiteCrawler } from \"./crawler.js\";\nexport { ContentScraper } from \"./scraper.js\";\nexport type { CrawlOptions } from \"./crawler.js\";\n\n\n\n\n\n\n\n", "/**\n * Website crawler for discovering and indexing pages\n */\n\nimport type { CrawledPage } from \"../types.js\";\n\nexport interface CrawlOptions {\n  maxPages: number;\n  maxDepth: number;\n  timeout: number;\n  userAgent: string;\n  language?: string;\n}\n\nexport class WebsiteCrawler {\n  private visitedUrls = new Set<string>();\n  private pages: CrawledPage[] = [];\n  private baseUrl?: URL;\n\n  constructor(private options: CrawlOptions) {}\n\n  async crawl(baseUrl: string): Promise<CrawledPage[]> {\n    this.baseUrl = new URL(baseUrl);\n    this.visitedUrls.clear();\n    this.pages = [];\n\n    await this.crawlPage(baseUrl, 0);\n    return this.pages;\n  }\n\n  private async crawlPage(url: string, depth: number): Promise<void> {\n    if (depth > this.options.maxDepth) return;\n    if (this.pages.length >= this.options.maxPages) return;\n\n    const normalizedUrl = this.normalizeUrl(url);\n    if (this.visitedUrls.has(normalizedUrl)) return;\n\n    this.visitedUrls.add(normalizedUrl);\n\n    try {\n      const response = await fetch(url, {\n        headers: {\n          \"User-Agent\": this.options.userAgent,\n        },\n        signal: AbortSignal.timeout(this.options.timeout),\n      });\n\n      if (!response.ok) return;\n\n      const html = await response.text();\n      const page = await this.parsePage(url, html);\n\n      if (page) {\n        this.pages.push(page);\n\n        // Extract links for further crawling\n        if (depth < this.options.maxDepth) {\n          const links = this.extractLinks(html, url);\n          for (const link of links) {\n            if (this.pages.length >= this.options.maxPages) break;\n            await this.crawlPage(link, depth + 1);\n          }\n        }\n      }\n    } catch (error) {\n      // Silently skip failed pages\n      console.error(`Failed to crawl ${url}:`, error);\n    }\n  }\n\n  private normalizeUrl(url: string): string {\n    try {\n      const urlObj = new URL(url);\n      return `${urlObj.protocol}//${urlObj.host}${urlObj.pathname}`.toLowerCase();\n    } catch {\n      return url.toLowerCase();\n    }\n  }\n\n  private extractLinks(html: string, baseUrl: string): string[] {\n    const links: string[] = [];\n    const base = new URL(baseUrl);\n    const linkRegex = /<a[^>]+href=[\"']([^\"']+)[\"']/gi;\n\n    let match;\n    while ((match = linkRegex.exec(html)) !== null) {\n      try {\n        const href = match[1];\n        const absoluteUrl = new URL(href, base).href;\n\n        // Only include same-domain links\n        if (new URL(absoluteUrl).hostname === base.hostname) {\n          links.push(absoluteUrl);\n        }\n      } catch {\n        // Skip invalid URLs\n      }\n    }\n\n    return [...new Set(links)];\n  }\n\n  private async parsePage(url: string, html: string): Promise<CrawledPage | null> {\n    // Use Cheerio-like parsing (simplified for Cloudflare Workers)\n    const titleMatch = html.match(/<title[^>]*>([^<]+)<\\/title>/i);\n    const title = titleMatch ? this.cleanText(titleMatch[1]) : \"\";\n\n    const headings: string[] = [];\n    const headingRegex = /<h([1-6])[^>]*>([^<]+)<\\/h[1-6]>/gi;\n    let headingMatch;\n    while ((headingMatch = headingRegex.exec(html)) !== null) {\n      headings.push(this.cleanText(headingMatch[2]));\n    }\n\n    // Extract main content (simplified - remove scripts, styles, etc.)\n    const bodyMatch = html.match(/<body[^>]*>([\\s\\S]*?)<\\/body>/i);\n    const bodyContent = bodyMatch ? bodyMatch[1] : html;\n    const textContent = this.extractTextContent(bodyContent);\n\n    // Extract topics (simplified keyword extraction)\n    const topics = this.extractTopics(textContent);\n\n    // Extract entities (simplified - look for capitalized phrases)\n    const entities = this.extractEntities(textContent);\n\n    return {\n      url,\n      title,\n      headings,\n      content: textContent,\n      topics,\n      entities,\n      language: this.options.language || \"en\",\n    };\n  }\n\n  private cleanText(text: string): string {\n    return text\n      .replace(/\\s+/g, \" \")\n      .replace(/&nbsp;/g, \" \")\n      .replace(/&amp;/g, \"&\")\n      .replace(/&lt;/g, \"<\")\n      .replace(/&gt;/g, \">\")\n      .replace(/&quot;/g, '\"')\n      .trim();\n  }\n\n  private extractTextContent(html: string): string {\n    // Remove script and style tags\n    let text = html.replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, \"\");\n    text = text.replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, \"\");\n    // Remove HTML tags\n    text = text.replace(/<[^>]+>/g, \" \");\n    // Clean up whitespace\n    return this.cleanText(text);\n  }\n\n  private extractTopics(text: string): string[] {\n    // Simplified topic extraction - look for repeated important words\n    const words = text\n      .toLowerCase()\n      .split(/\\s+/)\n      .filter((w) => w.length > 4);\n\n    const wordFreq = new Map<string, number>();\n    for (const word of words) {\n      wordFreq.set(word, (wordFreq.get(word) || 0) + 1);\n    }\n\n    return Array.from(wordFreq.entries())\n      .sort((a, b) => b[1] - a[1])\n      .slice(0, 10)\n      .map(([word]) => word);\n  }\n\n  private extractEntities(text: string): string[] {\n    // Simplified entity extraction - look for capitalized phrases\n    const entityRegex = /\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\b/g;\n    const entities = new Set<string>();\n    let match;\n\n    while ((match = entityRegex.exec(text)) !== null) {\n      const entity = match[1];\n      if (entity.length > 3 && entity.length < 50) {\n        entities.add(entity);\n      }\n    }\n\n    return Array.from(entities).slice(0, 20);\n  }\n}\n\n", "/**\n * Content scraper and normalizer for website content\n */\n\nimport type { WebsiteContent, CrawledPage } from \"../types.js\";\nimport { WebsiteCrawler, type CrawlOptions } from \"./crawler.js\";\n\nexport class ContentScraper {\n  constructor(private config: CrawlOptions) {}\n\n  async scrapeWebsite(\n    websiteUrl: string,\n    language: string\n  ): Promise<WebsiteContent> {\n    const crawler = new WebsiteCrawler({\n      ...this.config,\n      language,\n    });\n\n    const pages = await crawler.crawl(websiteUrl);\n    const normalizedContent = this.normalizeContent(pages, language);\n\n    return {\n      rootDomain: new URL(websiteUrl).hostname,\n      pages,\n      normalizedContent,\n      language,\n    };\n  }\n\n  private normalizeContent(pages: CrawledPage[], language: string): string {\n    // Combine all content with language-aware normalization\n    const allText = pages\n      .map((page) => {\n        const parts = [\n          page.title,\n          ...page.headings,\n          page.content,\n          ...page.topics,\n        ];\n        return parts.join(\" \");\n      })\n      .join(\"\\n\\n\");\n\n    // Language-aware normalization\n    return this.normalizeText(allText, language);\n  }\n\n  private normalizeText(text: string, language: string): string {\n    // Basic normalization - remove extra whitespace, normalize line breaks\n    let normalized = text\n      .replace(/\\s+/g, \" \")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n\n    // Language-specific normalization could be added here\n    // For now, we do basic cleanup\n    if (language === \"de\") {\n      // German-specific normalization\n      normalized = normalized.replace(/\u00DF/g, \"ss\");\n    }\n\n    return normalized;\n  }\n}\n\n", "/**\n * Category generation module\n * Derives thematic categories from website content\n */\n\nimport type { WebsiteContent, Category } from \"../types.js\";\n\nexport class CategoryGenerator {\n  private readonly categoryTemplates = [\n    {\n      name: \"Product\",\n      keywords: [\"product\", \"feature\", \"solution\", \"offering\", \"service\"],\n      description: \"Product features and capabilities\",\n    },\n    {\n      name: \"Pricing\",\n      keywords: [\"price\", \"cost\", \"pricing\", \"plan\", \"subscription\", \"fee\"],\n      description: \"Pricing information and plans\",\n    },\n    {\n      name: \"Comparison\",\n      keywords: [\"compare\", \"vs\", \"versus\", \"alternative\", \"competitor\"],\n      description: \"Comparisons with alternatives\",\n    },\n    {\n      name: \"Use Cases\",\n      keywords: [\"use case\", \"example\", \"scenario\", \"application\", \"how to\"],\n      description: \"Use cases and applications\",\n    },\n    {\n      name: \"Industry\",\n      keywords: [\"industry\", \"sector\", \"vertical\", \"market\", \"domain\"],\n      description: \"Industry-specific information\",\n    },\n    {\n      name: \"Problems / Solutions\",\n      keywords: [\"problem\", \"solution\", \"challenge\", \"issue\", \"solve\"],\n      description: \"Problems addressed and solutions provided\",\n    },\n    {\n      name: \"Integration\",\n      keywords: [\"integrate\", \"api\", \"connection\", \"compatible\", \"works with\"],\n      description: \"Integration capabilities\",\n    },\n    {\n      name: \"Support\",\n      keywords: [\"support\", \"help\", \"documentation\", \"guide\", \"tutorial\"],\n      description: \"Support and documentation\",\n    },\n  ];\n\n  generateCategories(\n    content: WebsiteContent,\n    minConfidence: number = 0.5,\n    maxCategories: number = 10\n  ): Category[] {\n    const categories: Category[] = [];\n    const contentText = content.normalizedContent.toLowerCase();\n    const allPages = content.pages.map((p) => p.url);\n\n    for (const template of this.categoryTemplates) {\n      const confidence = this.calculateCategoryConfidence(\n        template,\n        contentText,\n        content.pages\n      );\n\n      if (confidence >= minConfidence) {\n        const sourcePages = this.findRelevantPages(template, content.pages);\n\n        categories.push({\n          id: this.generateCategoryId(template.name),\n          name: template.name,\n          description: template.description,\n          confidence,\n          sourcePages: sourcePages.map((p) => p.url),\n        });\n      }\n    }\n\n    // Sort by confidence and limit\n    return categories\n      .sort((a, b) => b.confidence - a.confidence)\n      .slice(0, maxCategories);\n  }\n\n  private calculateCategoryConfidence(\n    template: { keywords: string[] },\n    contentText: string,\n    pages: WebsiteContent[\"pages\"]\n  ): number {\n    let keywordMatches = 0;\n    let totalKeywords = template.keywords.length;\n\n    for (const keyword of template.keywords) {\n      if (contentText.includes(keyword.toLowerCase())) {\n        keywordMatches++;\n      }\n    }\n\n    // Base confidence from keyword matches\n    let confidence = keywordMatches / totalKeywords;\n\n    // Boost confidence if found in multiple pages\n    const pagesWithKeywords = pages.filter((page) => {\n      const pageText = page.content.toLowerCase();\n      return template.keywords.some((kw) => pageText.includes(kw.toLowerCase()));\n    }).length;\n\n    if (pages.length > 0) {\n      confidence += (pagesWithKeywords / pages.length) * 0.3;\n    }\n\n    return Math.min(confidence, 1.0);\n  }\n\n  private findRelevantPages(\n    template: { keywords: string[] },\n    pages: WebsiteContent[\"pages\"]\n  ): WebsiteContent[\"pages\"] {\n    return pages.filter((page) => {\n      const pageText = (\n        page.title +\n        \" \" +\n        page.headings.join(\" \") +\n        \" \" +\n        page.content\n      ).toLowerCase();\n\n      return template.keywords.some((kw) =>\n        pageText.includes(kw.toLowerCase())\n      );\n    });\n  }\n\n  private generateCategoryId(name: string): string {\n    return `cat_${name.toLowerCase().replace(/\\s+/g, \"_\")}_${Date.now()}`;\n  }\n}\n\n\n\n\n\n\n\n", "/**\n * Prompt generation module\n * Generates high-intent questions for each category\n */\n\nimport type { Category, Prompt, UserInput } from \"../types.js\";\n\nexport class PromptGenerator {\n  generatePrompts(\n    categories: Category[],\n    userInput: UserInput,\n    questionsPerCategory: number = 5\n  ): Prompt[] {\n    const prompts: Prompt[] = [];\n\n    for (const category of categories) {\n      const categoryPrompts = this.generateCategoryPrompts(\n        category,\n        userInput,\n        questionsPerCategory\n      );\n      prompts.push(...categoryPrompts);\n    }\n\n    return prompts;\n  }\n\n  private generateCategoryPrompts(\n    category: Category,\n    userInput: UserInput,\n    count: number\n  ): Prompt[] {\n    const prompts: Prompt[] = [];\n    const templates = this.getPromptTemplates(category.name, userInput.language);\n\n    for (let i = 0; i < count && i < templates.length; i++) {\n      const template = templates[i];\n      const question = this.fillTemplate(template, userInput, category);\n\n      prompts.push({\n        id: this.generatePromptId(category.id, i),\n        categoryId: category.id,\n        question,\n        language: userInput.language,\n        country: userInput.country,\n        region: userInput.region,\n        intent: this.determineIntent(template),\n        createdAt: new Date().toISOString(),\n      });\n    }\n\n    return prompts;\n  }\n\n  private getPromptTemplates(\n    categoryName: string,\n    language: string\n  ): string[] {\n    // Language-specific templates\n    const templates: Record<string, Record<string, string[]>> = {\n      en: {\n        Product: [\n          \"What are the key features of {product} in {country}?\",\n          \"How does {product} work for businesses in {region}?\",\n          \"What makes {product} different from other solutions?\",\n          \"What are the main capabilities of {product}?\",\n          \"How do companies in {country} use {product}?\",\n        ],\n        Pricing: [\n          \"How much does {product} cost in {country}?\",\n          \"What are the pricing plans for {product}?\",\n          \"Is {product} affordable for small businesses in {region}?\",\n          \"What is the pricing structure for {product}?\",\n          \"Are there any discounts available for {product} in {country}?\",\n        ],\n        Comparison: [\n          \"How does {product} compare to alternatives in {country}?\",\n          \"What are the best alternatives to {product}?\",\n          \"Should I choose {product} or {competitor}?\",\n          \"How does {product} stack up against competitors?\",\n          \"What are the pros and cons of {product} vs alternatives?\",\n        ],\n        \"Use Cases\": [\n          \"What are common use cases for {product} in {region}?\",\n          \"How do companies in {country} use {product}?\",\n          \"What problems does {product} solve?\",\n          \"When should I use {product}?\",\n          \"What industries benefit from {product}?\",\n        ],\n        Industry: [\n          \"What companies in {country} use {product}?\",\n          \"Is {product} suitable for {industry} in {region}?\",\n          \"What industries does {product} serve?\",\n          \"How is {product} used in {industry}?\",\n          \"What are the main use cases for {product} in {industry}?\",\n        ],\n        \"Problems / Solutions\": [\n          \"What problems does {product} solve in {country}?\",\n          \"How does {product} address common challenges?\",\n          \"What issues can {product} help with?\",\n          \"What solutions does {product} provide?\",\n          \"How does {product} solve business problems?\",\n        ],\n        Integration: [\n          \"What integrations does {product} support?\",\n          \"How do I integrate {product} with other tools?\",\n          \"Is {product} compatible with {tool}?\",\n          \"What APIs does {product} offer?\",\n          \"How does {product} connect with existing systems?\",\n        ],\n        Support: [\n          \"How do I get started with {product}?\",\n          \"What documentation is available for {product}?\",\n          \"How do I get support for {product} in {country}?\",\n          \"What resources are available for {product} users?\",\n          \"Where can I find help with {product}?\",\n        ],\n      },\n      de: {\n        Product: [\n          \"Was sind die Hauptfunktionen von {product} in {country}?\",\n          \"Wie funktioniert {product} f\u00FCr Unternehmen in {region}?\",\n          \"Was unterscheidet {product} von anderen L\u00F6sungen?\",\n          \"Welche Hauptfunktionen bietet {product}?\",\n          \"Wie nutzen Unternehmen in {country} {product}?\",\n        ],\n        Pricing: [\n          \"Wie viel kostet {product} in {country}?\",\n          \"Welche Preismodelle gibt es f\u00FCr {product}?\",\n          \"Ist {product} f\u00FCr kleine Unternehmen in {region} erschwinglich?\",\n          \"Wie ist die Preisstruktur von {product}?\",\n          \"Gibt es Rabatte f\u00FCr {product} in {country}?\",\n        ],\n        Comparison: [\n          \"Wie schneidet {product} im Vergleich zu Alternativen in {country} ab?\",\n          \"Was sind die besten Alternativen zu {product}?\",\n          \"Sollte ich {product} oder {competitor} w\u00E4hlen?\",\n          \"Wie steht {product} im Vergleich zu Konkurrenten da?\",\n          \"Was sind die Vor- und Nachteile von {product} vs Alternativen?\",\n        ],\n        \"Use Cases\": [\n          \"Was sind h\u00E4ufige Anwendungsf\u00E4lle f\u00FCr {product} in {region}?\",\n          \"Wie nutzen Unternehmen in {country} {product}?\",\n          \"Welche Probleme l\u00F6st {product}?\",\n          \"Wann sollte ich {product} verwenden?\",\n          \"Welche Branchen profitieren von {product}?\",\n        ],\n        Industry: [\n          \"Welche Unternehmen in {country} nutzen {product}?\",\n          \"Ist {product} f\u00FCr {industry} in {region} geeignet?\",\n          \"Welche Branchen bedient {product}?\",\n          \"Wie wird {product} in {industry} eingesetzt?\",\n          \"Was sind die Hauptanwendungsf\u00E4lle f\u00FCr {product} in {industry}?\",\n        ],\n        \"Problems / Solutions\": [\n          \"Welche Probleme l\u00F6st {product} in {country}?\",\n          \"Wie adressiert {product} h\u00E4ufige Herausforderungen?\",\n          \"Bei welchen Problemen kann {product} helfen?\",\n          \"Welche L\u00F6sungen bietet {product}?\",\n          \"Wie l\u00F6st {product} Gesch\u00E4ftsprobleme?\",\n        ],\n        Integration: [\n          \"Welche Integrationen unterst\u00FCtzt {product}?\",\n          \"Wie integriere ich {product} mit anderen Tools?\",\n          \"Ist {product} kompatibel mit {tool}?\",\n          \"Welche APIs bietet {product}?\",\n          \"Wie verbindet sich {product} mit bestehenden Systemen?\",\n        ],\n        Support: [\n          \"Wie beginne ich mit {product}?\",\n          \"Welche Dokumentation ist f\u00FCr {product} verf\u00FCgbar?\",\n          \"Wie erhalte ich Support f\u00FCr {product} in {country}?\",\n          \"Welche Ressourcen stehen {product}-Nutzern zur Verf\u00FCgung?\",\n          \"Wo finde ich Hilfe zu {product}?\",\n        ],\n      },\n      fr: {\n        Product: [\n          \"Quelles sont les principales fonctionnalit\u00E9s de {product} en {country}?\",\n          \"Comment fonctionne {product} pour les entreprises en {region}?\",\n          \"Qu'est-ce qui distingue {product} des autres solutions?\",\n          \"Quelles sont les principales capacit\u00E9s de {product}?\",\n          \"Comment les entreprises en {country} utilisent-elles {product}?\",\n        ],\n        Pricing: [\n          \"Combien co\u00FBte {product} en {country}?\",\n          \"Quels sont les plans tarifaires pour {product}?\",\n          \"{product} est-il abordable pour les petites entreprises en {region}?\",\n          \"Quelle est la structure tarifaire de {product}?\",\n          \"Y a-t-il des remises disponibles pour {product} en {country}?\",\n        ],\n        Comparison: [\n          \"Comment {product} se compare-t-il aux alternatives en {country}?\",\n          \"Quelles sont les meilleures alternatives \u00E0 {product}?\",\n          \"Dois-je choisir {product} ou {competitor}?\",\n          \"Comment {product} se compare-t-il aux concurrents?\",\n          \"Quels sont les avantages et inconv\u00E9nients de {product} vs alternatives?\",\n        ],\n        \"Use Cases\": [\n          \"Quels sont les cas d'usage courants pour {product} en {region}?\",\n          \"Comment les entreprises en {country} utilisent-elles {product}?\",\n          \"Quels probl\u00E8mes {product} r\u00E9sout-il?\",\n          \"Quand devrais-je utiliser {product}?\",\n          \"Quelles industries b\u00E9n\u00E9ficient de {product}?\",\n        ],\n        Industry: [\n          \"Quelles entreprises en {country} utilisent {product}?\",\n          \"{product} est-il adapt\u00E9 \u00E0 {industry} en {region}?\",\n          \"Quelles industries {product} sert-il?\",\n          \"Comment {product} est-il utilis\u00E9 dans {industry}?\",\n          \"Quels sont les principaux cas d'usage pour {product} dans {industry}?\",\n        ],\n        \"Problems / Solutions\": [\n          \"Quels probl\u00E8mes {product} r\u00E9sout-il en {country}?\",\n          \"Comment {product} r\u00E9pond-il aux d\u00E9fis courants?\",\n          \"\u00C0 quels probl\u00E8mes {product} peut-il aider?\",\n          \"Quelles solutions {product} fournit-il?\",\n          \"Comment {product} r\u00E9sout-il les probl\u00E8mes commerciaux?\",\n        ],\n        Integration: [\n          \"Quelles int\u00E9grations {product} prend-il en charge?\",\n          \"Comment int\u00E9grer {product} avec d'autres outils?\",\n          \"{product} est-il compatible avec {tool}?\",\n          \"Quelles API {product} offre-t-il?\",\n          \"Comment {product} se connecte-t-il aux syst\u00E8mes existants?\",\n        ],\n        Support: [\n          \"Comment commencer avec {product}?\",\n          \"Quelle documentation est disponible pour {product}?\",\n          \"Comment obtenir du support pour {product} en {country}?\",\n          \"Quelles ressources sont disponibles pour les utilisateurs de {product}?\",\n          \"O\u00F9 puis-je trouver de l'aide pour {product}?\",\n        ],\n      },\n    };\n\n    const langTemplates = templates[language] || templates.en;\n    return langTemplates[categoryName] || langTemplates.Product || [];\n  }\n\n  private fillTemplate(\n    template: string,\n    userInput: UserInput,\n    category: Category\n  ): string {\n    // Extract domain name as product name\n    const productName = this.extractProductName(userInput.websiteUrl);\n\n    return template\n      .replace(/{product}/g, productName)\n      .replace(/{country}/g, userInput.country)\n      .replace(/{region}/g, userInput.region || userInput.country)\n      .replace(/{industry}/g, \"the industry\")\n      .replace(/{competitor}/g, \"competitors\")\n      .replace(/{tool}/g, \"other tools\");\n  }\n\n  private extractProductName(websiteUrl: string): string {\n    try {\n      const domain = new URL(websiteUrl).hostname;\n      const parts = domain.split(\".\");\n      return parts[0].charAt(0).toUpperCase() + parts[0].slice(1);\n    } catch {\n      return \"the product\";\n    }\n  }\n\n  private determineIntent(template: string): \"high\" | \"medium\" | \"low\" {\n    // High intent: questions with \"how\", \"what\", \"should\", \"best\"\n    if (\n      /how|what|should|best|which|when/i.test(template) &&\n      /cost|price|compare|choose|recommend/i.test(template)\n    ) {\n      return \"high\";\n    }\n    // Medium intent: questions with \"is\", \"are\", \"does\"\n    if (/is|are|does|can/i.test(template)) {\n      return \"medium\";\n    }\n    return \"low\";\n  }\n\n  private generatePromptId(categoryId: string, index: number): string {\n    return `prompt_${categoryId}_${index}_${Date.now()}`;\n  }\n}\n\n\n\n\n\n\n\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n"],
  "mappings": ";;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAGA;AAAA;AAAA;;;ACHA;AAAA;AAAA;AAAA;AAAA;AAUO,SAAS,kBAAkB,YAA0C;AAC1E,MAAI,CAAC,cAAc,WAAW,KAAK,EAAE,WAAW,GAAG;AACjD,WAAO;AAAA,EACT;AAGA,QAAM,kBAAkB,WAAW,OAAO,mBAAmB;AAC7D,MAAI,oBAAoB,IAAI;AAE1B,UAAM,aAAa,WAAW,QAAQ,MAAM,eAAe,IAAI;AAC/D,UAAM,aAAa,WAAW,UAAU,UAAU;AAGlD,UAAM,mBAAmB,WAAW,MAAM,WAAW;AACrD,QAAI,oBAAoB,iBAAiB,UAAU,QAAW;AAC5D,aAAO,WAAW,UAAU,GAAG,iBAAiB,KAAK,EAAE,KAAK;AAAA,IAC9D,OAAO;AAEL,aAAO,WAAW,KAAK;AAAA,IACzB;AAAA,EACF;AAGA,QAAM,qBAAqB;AAAA,IACzB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,aAAW,WAAW,oBAAoB;AACxC,UAAM,QAAQ,WAAW,MAAM,OAAO;AACtC,QAAI,SAAS,MAAM,CAAC,GAAG;AACrB,aAAO,MAAM,CAAC,EAAE,KAAK;AAAA,IACvB;AAAA,EACF;AAGA,SAAO;AACT;AAYO,SAAS,iBACd,MACA,WAOA;AACA,MAAI,CAAC,QAAQ,KAAK,KAAK,EAAE,WAAW,GAAG;AACrC,WAAO;AAAA,MACL,WAAW;AAAA,MACX,UAAU;AAAA,MACV,YAAY;AAAA,MACZ,cAAc,CAAC;AAAA,MACf,eAAe,CAAC;AAAA,IAClB;AAAA,EACF;AAGA,QAAM,kBAAkB;AACxB,QAAM,gBAAgB,KAAK,SAAS,kBAChC,KAAK,UAAU,GAAG,eAAe,IACjC;AAEJ,QAAM,aAAa,UAAU,YAAY;AACzC,QAAM,cAAc,WAAW,QAAQ,QAAQ,EAAE;AAIjD,QAAM,oBAAoB;AAC1B,QAAM,WAAgF,CAAC;AACvF,MAAI;AAEJ,UAAQ,QAAQ,kBAAkB,KAAK,aAAa,OAAO,MAAM;AAC/D,aAAS,KAAK;AAAA,MACZ,MAAM,MAAM,CAAC;AAAA,MACb,KAAK,MAAM,CAAC;AAAA,MACZ,OAAO,MAAM;AAAA,MACb,QAAQ,MAAM,CAAC,EAAE;AAAA,IACnB,CAAC;AAAA,EACH;AAGA,QAAM,iBAAwD,CAAC;AAC/D,QAAM,kBAAkB,oBAAI,IAAY;AACxC,QAAM,mBAAmB,oBAAI,IAAY;AAEzC,aAAW,QAAQ,UAAU;AAC3B,UAAM,WAAW,KAAK,IAAI,YAAY;AAEtC,QAAI,SAAS,SAAS,WAAW,GAAG;AAClC,qBAAe,KAAK;AAAA,QAClB,OAAO,KAAK;AAAA,QACZ,KAAK,KAAK,QAAQ,KAAK;AAAA,MACzB,CAAC;AACD,sBAAgB,IAAI,KAAK,GAAG;AAAA,IAC9B,OAAO;AACL,uBAAiB,IAAI,KAAK,GAAG;AAAA,IAC/B;AAAA,EACF;AAIA,QAAM,eAAe,eAAe,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAEpE,QAAM,eAAe,WAAW,QAAQ,uBAAuB,MAAM;AACrE,QAAM,eAAe,IAAI,OAAO,MAAM,mBAAmB,IAAI;AAE7D,MAAI,WAAW;AACf,MAAI;AAEJ,UAAQ,eAAe,aAAa,KAAK,aAAa,OAAO,MAAM;AACjE,UAAM,eAAe,aAAa;AAClC,UAAM,aAAa,eAAe,aAAa,CAAC,EAAE;AAIlD,UAAM,eAAe,aAAa;AAAA,MAChC,CAAC,UAAU,gBAAgB,MAAM,SAAS,cAAc,MAAM;AAAA,IAChE;AAEA,QAAI,CAAC,cAAc;AACjB;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AAAA,IACL,WAAW,eAAe;AAAA,IAC1B;AAAA,IACA,YAAY,iBAAiB;AAAA,IAC7B,cAAc,MAAM,KAAK,eAAe;AAAA;AAAA,IACxC,eAAe,MAAM,KAAK,gBAAgB;AAAA;AAAA,EAC5C;AACF;AA7JA;AAAA;AAAA;AAAA;AAUgB;AAoDA;AAAA;AAAA;;;AC9DhB,IAgDa;AAhDb;AAAA;AAAA;AAAA;AAgDO,IAAM,WAAN,MAAe;AAAA,MACb;AAAA,MACP,YAAY,IAAiB;AAE3B,aAAK,KAAK,MAAM;AAAA,UACd,SAAS,OAAO;AAAA,YACd,MAAM,OAAO,EAAE,OAAO,YAAY,MAAM,KAAK,aAAa,EAAE,SAAS,KAAK,IAAI,KAAK,aAAa,EAAE,SAAS,MAAM,SAAS,CAAC,EAAE,GAAG;AAAA,YAChI,OAAO,YAAY;AAAA,YACnB,KAAK,aAAa,EAAE,SAAS,KAAK;AAAA,YAClC,KAAK,aAAa,EAAE,SAAS,MAAM,SAAS,CAAC,EAAE;AAAA,UACjD;AAAA,UACA,OAAO,YAAY,CAAC;AAAA,UACpB,MAAM,aAAa,EAAE,OAAO,GAAG,UAAU,EAAE;AAAA,QAC7C;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,iBACJ,WACA,aAAqB,GACrB,YAAoB,KACpB,eACY;AACZ,YAAI;AACJ,cAAM,SAAS,iBAAiB;AAEhC,iBAAS,UAAU,GAAG,UAAU,YAAY,WAAW;AACrD,cAAI;AACF,kBAAM,YAAY,KAAK,IAAI;AAC3B,kBAAM,SAAS,MAAM,UAAU;AAC/B,kBAAM,WAAW,KAAK,IAAI,IAAI;AAE9B,gBAAI,WAAW,KAAM;AACnB,sBAAQ,IAAI,cAAc,uBAAuB,YAAY;AAAA,YAC/D;AAEA,mBAAO;AAAA,UACT,SAAS,OAAP;AACA,wBAAY;AACZ,kBAAM,eAAe,OAAO,WAAW,OAAO,KAAK;AAGnD,kBAAM,cACJ,aAAa,SAAS,UAAU,KAChC,aAAa,SAAS,SAAS,KAC/B,aAAa,SAAS,OAAO,KAC7B,aAAa,SAAS,kCAAkC,KACxD,aAAa,SAAS,oCAAoC;AAE5D,gBAAI,CAAC,eAAe,YAAY,aAAa,GAAG;AAC9C,sBAAQ,MAAM,cAAc,uBAAuB,UAAU,eAAe,YAAY;AACxF,oBAAM;AAAA,YACR;AAGA,kBAAM,iBAAiB,aAAa,SAAS,kCAAkC;AAC/E,kBAAM,kBAAkB,iBAAiB,IAAI;AAC7C,kBAAM,QAAQ,YAAY,KAAK,IAAI,GAAG,OAAO,IAAI;AAEjD,oBAAQ,KAAK,cAAc,0BAA0B,UAAU,KAAK,4BAA4B,YAAY,YAAY;AACxH,kBAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,KAAK,CAAC;AAAA,UACzD;AAAA,QACF;AAEA,cAAM;AAAA,MACR;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,cACZ,YACA,YAAoB,IACpB,eACe;AACf,YAAI,WAAW,WAAW,GAAG;AAC3B;AAAA,QACF;AAEA,cAAM,SAAS,iBAAiB,oBAAoB,WAAW;AAC/D,gBAAQ,IAAI,wBAAwB,uBAAuB,WAAW;AAGtE,iBAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK,WAAW;AACrD,gBAAM,QAAQ,WAAW,MAAM,GAAG,IAAI,SAAS;AAC/C,gBAAM,WAAW,KAAK,MAAM,IAAI,SAAS,IAAI;AAC7C,gBAAM,cAAc,KAAK,KAAK,WAAW,SAAS,SAAS;AAE3D,gBAAM,KAAK,iBAAiB,YAAY;AACtC,kBAAM,YAAY,KAAK,IAAI;AAC3B,kBAAM,KAAK,GAAG,MAAM,KAAK;AACzB,kBAAM,WAAW,KAAK,IAAI,IAAI;AAC9B,oBAAQ,IAAI,cAAc,gBAAgB,YAAY,gBAAgB,MAAM,mCAAmC,YAAY;AAAA,UAC7H,GAAG,GAAG,KAAK,GAAG,gBAAgB,YAAY,aAAa;AAGvD,cAAI,IAAI,YAAY,WAAW,QAAQ;AACrC,kBAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,EAAE,CAAC;AAAA,UACtD;AAAA,QACF;AAAA,MACF;AAAA,MAEA,MAAM,gBACJ,OACA,WACA,SAAiB,WACF;AACf,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AACnC,YAAI;AACF,gBAAM,KAAK,GACR;AAAA,YACC;AAAA;AAAA,UAEF,EACC;AAAA,YACC;AAAA,YACA,UAAU;AAAA,YACV,UAAU;AAAA,YACV,UAAU,UAAU;AAAA,YACpB,UAAU;AAAA,YACV;AAAA,YACA;AAAA,YACA;AAAA,UACF,EACC,IAAI;AAAA,QACT,SAAS,OAAP;AACA,cAAI,MAAM,SAAS,SAAS,8BAA8B,GAAG;AAC3D,kBAAM,IAAI;AAAA,cACR;AAAA,YACF;AAAA,UACF;AACA,gBAAM;AAAA,QACR;AAAA,MACF;AAAA,MAEA,MAAM,qBACJ,OACA,QACA,UACe;AACf,cAAM,eAAe,WAAW,KAAK,UAAU,QAAQ,IAAI;AAC3D,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,GACR;AAAA,YACC;AAAA,UACF,EACC,KAAK,QAAQ,eAAc,oBAAI,KAAK,GAAE,YAAY,GAAG,KAAK,EAC1D,IAAI;AAAA,QACT,GAAG,GAAG,KAAK,sBAAsB;AAAA,MACnC;AAAA,MAEA,MAAM,kBAAkB,OAKd;AACR,cAAM,MAAM,MAAM,KAAK,GACpB,QAAQ,8EAA8E,EACtF,KAAK,KAAK,EACV,MAKE;AAEL,YAAI,CAAC;AAAK,iBAAO;AAEjB,eAAO;AAAA,UACL,QAAQ,IAAI,UAAU;AAAA,UACtB,UAAU,IAAI,WAAW,KAAK,MAAM,IAAI,QAAQ,IAAI;AAAA,UACpD,OAAO,IAAI,iBAAiB;AAAA,UAC5B,MAAM,IAAI,QAAQ;AAAA,QACpB;AAAA,MACF;AAAA,MAEA,MAAM,eACJ,OACA,YACe;AACf,YAAI,WAAW,WAAW,GAAG;AAC3B;AAAA,QACF;AAKA,cAAM,aAAa,WAAW;AAAA,UAAI,CAAC,QACjC,KAAK,GACF;AAAA,YACC;AAAA;AAAA;AAAA;AAAA,UAIF,EACC;AAAA,YACC,IAAI;AAAA,YACJ;AAAA,YACA,IAAI;AAAA,YACJ,IAAI;AAAA,YACJ,IAAI;AAAA,YACJ,KAAK,UAAU,IAAI,WAAW;AAAA,YAC9B,IAAI;AAAA;AAAA,aACJ,oBAAI,KAAK,GAAE,YAAY;AAAA;AAAA,UACzB;AAAA,QACJ;AAEA,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,cAAc,YAAY,IAAI,mBAAmB,WAAW,oBAAoB;AAAA,QAC7F,GAAG,GAAG,KAAK,gBAAgB;AAAA,MAC7B;AAAA,MAEA,MAAM,YAAY,OAAe,SAAkC;AACjE,YAAI,QAAQ,WAAW,GAAG;AACxB;AAAA,QACF;AAEA,cAAM,aAAa,QAAQ;AAAA,UAAI,CAAC,WAC9B,KAAK,GACF;AAAA,YACC;AAAA;AAAA,UAEF,EACC;AAAA,YACC,OAAO;AAAA,YACP;AAAA,YACA,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO,WAAW;AAAA,YAClB,OAAO,UAAU;AAAA,YACjB,OAAO;AAAA,YACP,OAAO;AAAA,UACT;AAAA,QACJ;AAGA,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,cAAc,YAAY,IAAI,gBAAgB,QAAQ,iBAAiB;AAAA,QACpF,GAAG,GAAG,KAAK,aAAa;AAAA,MAC1B;AAAA,MAEA,MAAM,iBAAiB,WAAyC;AAC9D,YAAI,UAAU,WAAW,GAAG;AAC1B;AAAA,QACF;AAGA,cAAM,qBAAqB,UAAU,IAAI,CAAC,aAAa;AACrD,gBAAM,aAAa,QAAQ,SAAS,YAAY,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC;AACpG,iBAAO;AAAA,YACL;AAAA,YACA,WAAW,KAAK,GACb;AAAA,cACC;AAAA;AAAA,YAEF,EACC;AAAA,cACC;AAAA,cACA,SAAS;AAAA,cACT,SAAS;AAAA,cACT,SAAS;AAAA,cACT,SAAS;AAAA,YACX;AAAA,YACF,WAAW,SAAS;AAAA,UACtB;AAAA,QACF,CAAC;AAGD,cAAM,yBAAyB,mBAAmB,IAAI,QAAM,GAAG,SAAS;AACxE,YAAI,uBAAuB,SAAS,GAAG;AACrC,kBAAQ,IAAI,qBAAqB,uBAAuB,2BAA2B;AACnF,gBAAM,KAAK,iBAAiB,YAAY;AACtC,kBAAM,KAAK,cAAc,wBAAwB,IAAI,mCAAmC;AAAA,UAC1F,GAAG,GAAG,KAAK,8BAA8B;AAAA,QAC3C;AAGA,cAAM,qBAA4C,CAAC;AACnD,mBAAW,EAAE,YAAY,UAAU,KAAK,oBAAoB;AAC1D,qBAAW,YAAY,WAAW;AAChC,kBAAM,aAAa,QAAQ,cAAc,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC;AAC7F,+BAAmB;AAAA,cACjB,KAAK,GACF;AAAA,gBACC;AAAA;AAAA,cAEF,EACC;AAAA,gBACC;AAAA,gBACA;AAAA,gBACA,SAAS;AAAA,gBACT,SAAS,SAAS;AAAA,gBAClB,SAAS,WAAW;AAAA,cACtB;AAAA,YACJ;AAAA,UACF;AAAA,QACF;AAEA,YAAI,mBAAmB,SAAS,GAAG;AACjC,kBAAQ,IAAI,qBAAqB,mBAAmB,yCAAyC;AAC7F,gBAAM,KAAK,iBAAiB,YAAY;AAEtC,kBAAM,KAAK,cAAc,oBAAoB,IAAI,iCAAiC,mBAAmB,eAAe;AAAA,UACtH,GAAG,GAAG,KAAK,8BAA8B;AAAA,QAC3C;AAEA,gBAAQ,IAAI,+BAA+B,UAAU,yBAAyB,mBAAmB,kBAAkB;AAAA,MACrH;AAAA,MAEA,MAAM,mBAAmB,UAA2C;AAClE,YAAI,SAAS,WAAW,GAAG;AACzB;AAAA,QACF;AAEA,cAAM,aAAa,SAAS,IAAI,CAAC,aAAa;AAC5C,gBAAM,aAAa,YAAY,SAAS,YAAY,KAAK,IAAI;AAC7D,iBAAO;AAAA,YACL,UAAU,KAAK,GACZ;AAAA,cACC;AAAA;AAAA;AAAA;AAAA,YAIF,EACC;AAAA,cACC;AAAA,cACA,SAAS;AAAA,cACT,SAAS,cAAc;AAAA,cACvB,SAAS,cAAc;AAAA,cACvB,KAAK,UAAU,SAAS,cAAc,QAAQ;AAAA,cAC9C,SAAS;AAAA,cACT,KAAK,UAAU,SAAS,YAAY;AAAA,cACpC,SAAS,UAAU;AAAA,cACnB,SAAS,UAAU;AAAA,cACnB,KAAK,UAAU,SAAS,UAAU,QAAQ;AAAA,cAC1C,SAAS;AAAA,YACX;AAAA,YACF,aAAa,SAAS,YAAY,IAAI,CAAC,eAAe;AACpD,oBAAM,eAAe,QAAQ,cAAc,KAAK,IAAI,KAAK,KAAK,OAAO;AACrE,qBAAO,KAAK,GACT;AAAA,gBACC;AAAA;AAAA;AAAA,cAGF,EACC;AAAA,gBACC;AAAA,gBACA;AAAA,gBACA,WAAW;AAAA,gBACX,WAAW;AAAA,gBACX,KAAK,UAAU,WAAW,QAAQ;AAAA,gBAClC,KAAK,UAAU,WAAW,SAAS;AAAA,cACrC;AAAA,YACJ,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAED,cAAM,gBAAuC,CAAC;AAC9C,mBAAW,EAAE,UAAU,YAAY,KAAK,YAAY;AAClD,wBAAc,KAAK,QAAQ;AAC3B,wBAAc,KAAK,GAAG,WAAW;AAAA,QACnC;AAEA,YAAI,cAAc,SAAS,GAAG;AAC5B,gBAAM,KAAK,iBAAiB,YAAY;AAExC,kBAAM,KAAK,cAAc,eAAe,IAAI,uBAAuB,SAAS,oBAAoB,cAAc,0BAA0B;AAAA,UACxI,GAAG,GAAG,KAAK,oBAAoB;AAAA,QACjC;AAAA,MACF;AAAA,MAEA,MAAM,oBACJ,OACA,SACe;AACf,YAAI,QAAQ,WAAW,GAAG;AACxB;AAAA,QACF;AAEA,cAAM,aAAa,QAAQ,IAAI,CAAC,WAAW;AACzC,gBAAM,WAAW,UAAU,OAAO,cAAc,KAAK,IAAI;AACzD,iBAAO,KAAK,GACT;AAAA,YACC;AAAA;AAAA;AAAA;AAAA,UAIF,EACC;AAAA,YACC;AAAA,YACA;AAAA,YACA,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,UACT;AAAA,QACJ,CAAC;AAED,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,cAAc,YAAY,IAAI,wBAAwB,QAAQ,iBAAiB;AAAA,QAC5F,GAAG,GAAG,KAAK,qBAAqB;AAAA,MAClC;AAAA,MAEA,MAAM,wBACJ,OACA,UACe;AACf,cAAM,aAAa,iBAAiB,SAAS,KAAK,IAAI;AACtD,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,GACR;AAAA,YACC;AAAA;AAAA;AAAA;AAAA,UAIF,EACC;AAAA,YACC;AAAA,YACA;AAAA,YACA,SAAS;AAAA,YACT,KAAK,UAAU,SAAS,gBAAgB;AAAA,YACxC,KAAK,UAAU,SAAS,gBAAgB;AAAA,YACxC,KAAK,UAAU,SAAS,gBAAgB;AAAA,YACxC,KAAK,UAAU,SAAS,mBAAmB;AAAA,YAC3C,SAAS;AAAA,UACX,EACC,IAAI;AAAA,QACT,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,mBACJ,OACA,MACe;AACf,cAAM,SAAS,MAAM,SAAS,KAAK,IAAI;AACvC,cAAM,KAAK,iBAAiB,YAAY;AACtC,gBAAM,KAAK,GACR;AAAA,YACC;AAAA;AAAA;AAAA;AAAA,UAIF,EACC;AAAA,YACC;AAAA,YACA;AAAA,YACA,KAAK;AAAA,YACL,KAAK;AAAA,YACL,KAAK;AAAA,YACL,KAAK;AAAA,YACL,KAAK;AAAA,UACP,EACC,IAAI;AAAA,QACT,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,YACJ,OACA,SACe;AAEf,cAAM,eAAe,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,GAAG,CAAC;AAC9D,cAAM,YAAY,WAAW,SAAS,KAAK,IAAI,KAAK;AACpD,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AAInC,cAAM,KAAK,iBAAiB,YAAY;AAEtC,gBAAM,KAAK,GACR,QAAQ,0DAA0D,EAClE,KAAK,KAAK,EACV,IAAI;AAGP,gBAAM,KAAK,GACR;AAAA,YACC;AAAA;AAAA;AAAA,UAGF,EACC;AAAA,YACC;AAAA,YACA;AAAA,YACA,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,KAAK,UAAU,QAAQ,WAAW;AAAA,YAClC,KAAK,UAAU,QAAQ,YAAY;AAAA,YACnC;AAAA,UACF,EACC,IAAI;AAAA,QACT,GAAG,GAAG,KAAK,aAAa;AAAA,MAC1B;AAAA,MAEA,MAAM,WAAW,OAAgD;AAC/D,cAAM,SAAS,MAAM,KAAK,GACvB;AAAA,UACC;AAAA;AAAA;AAAA;AAAA,QAIF,EACC,KAAK,KAAK,EACV,MAME;AAEL,YAAI,CAAC;AAAQ,iBAAO;AAEpB,eAAO;AAAA,UACL,eAAe,OAAO;AAAA,UACtB,gBAAgB,OAAO;AAAA,UACvB,aAAa,KAAK,MAAM,OAAO,gBAAgB,IAAI;AAAA,UACnD,cAAc,KAAK,MAAM,OAAO,iBAAiB,IAAI;AAAA,QACvD;AAAA,MACF;AAAA,MAEA,MAAM,sBAAsB,OAYxB;AACF,eAAO,KAAK,iBAAiB,YAAY;AACvC,gBAAM,EAAE,mBAAAA,oBAAmB,kBAAAC,kBAAiB,IAAI,MAAM;AAGtD,gBAAM,UAAU,MAAM,KAAK,GACxB,QAAQ,oDAAoD,EAC5D,KAAK,KAAK,EACV,MAA+B;AAGlC,cAAI,YAAY;AAChB,cAAI,SAAS,aAAa;AACxB,gBAAI;AACF,oBAAM,SAAS,IAAI,IAAI,QAAQ,WAAW,EAAE;AAC5C,oBAAM,QAAQ,OAAO,MAAM,GAAG;AAC9B,0BAAY,MAAM,CAAC,EAAE,OAAO,CAAC,EAAE,YAAY,IAAI,MAAM,CAAC,EAAE,MAAM,CAAC;AAAA,YACjE,QAAE;AAAA,YAEF;AAAA,UACF;AAEA,gBAAM,SAAS,MAAM,KAAK,GACvB;AAAA,YACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAeF,EACC,KAAK,KAAK,EACV,IAOE;AAGL,gBAAM,UAAU,OAAO,WAAW,CAAC;AACnC,gBAAM,YAAY;AAClB,gBAAM,mBAYD,CAAC;AAEN,mBAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK,WAAW;AAClD,kBAAM,QAAQ,QAAQ,MAAM,GAAG,IAAI,SAAS;AAE5C,kBAAM,eAAe,MAAM,IAAI,OAAK;AAClC,kBAAI;AAEF,sBAAM,aAAaD,mBAAkB,EAAE,MAAM;AAI7C,sBAAM,QAAQ,EAAE,UAAU,EAAE,OAAO,KAAK,EAAE,SAAS,IAC/CC,kBAAiB,EAAE,QAAQ,SAAS,IACpC;AAEJ,uBAAO;AAAA,kBACL,IAAI,EAAE;AAAA,kBACN,UAAU,EAAE;AAAA,kBACZ,QAAQ;AAAA;AAAA,kBACR,YAAY,EAAE;AAAA,kBACd,cAAc,EAAE;AAAA,kBAChB,WAAW,EAAE;AAAA;AAAA,kBAEb,WAAW,OAAO,aAAa;AAAA,kBAC/B,UAAU,OAAO,YAAY;AAAA,kBAC7B,YAAY,OAAO,cAAc;AAAA,kBACjC,cAAc,OAAO,gBAAgB,CAAC;AAAA,kBACtC,eAAe,OAAO,iBAAiB,CAAC;AAAA,gBAC1C;AAAA,cACF,SAAS,OAAP;AAEA,wBAAQ,MAAM,2BAA2B,EAAE,OAAO,KAAK;AACvD,uBAAO;AAAA,kBACL,IAAI,EAAE;AAAA,kBACN,UAAU,EAAE;AAAA,kBACZ,QAAQD,mBAAkB,EAAE,MAAM;AAAA,kBAClC,YAAY,EAAE;AAAA,kBACd,cAAc,EAAE;AAAA,kBAChB,WAAW,EAAE;AAAA,kBACb,WAAW;AAAA,kBACX,UAAU;AAAA,kBACV,YAAY;AAAA,kBACZ,cAAc,CAAC;AAAA,kBACf,eAAe,CAAC;AAAA,gBAClB;AAAA,cACF;AAAA,YACF,CAAC;AAED,6BAAiB,KAAK,GAAG,YAAY;AAGrC,gBAAI,IAAI,YAAY,QAAQ,QAAQ;AAClC,oBAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,EAAE,CAAC;AAAA,YACtD;AAAA,UACF;AAEA,iBAAO;AAAA,QACT,GAAG,GAAG,KAAK,0BAA0B,QAAQ;AAAA,MAC/C;AAAA,MAEA,MAAM,eAAe,OAA+C;AAClE,eAAO,KAAK,iBAAiB,YAAY;AACvC,gBAAM,MAAM,MAAM,KAAK,GACpB,QAAQ,0CAA0C,EAClD,KAAK,KAAK,EACV,MAQE;AAEL,cAAI,CAAC;AAAK,mBAAO;AAGjB,gBAAM,mBAAmB,MAAM,KAAK,GACjC,QAAQ,oDAAoD,EAC5D,KAAK,KAAK,EACV,IAME;AAEL,gBAAM,cAA0B,iBAAiB,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,YACxE,IAAI,EAAE;AAAA,YACN,MAAM,EAAE;AAAA,YACR,aAAa,EAAE;AAAA,YACf,YAAY,EAAE;AAAA,YACd,aAAa,KAAK,MAAM,EAAE,gBAAgB,IAAI;AAAA,UAChD,EAAE;AAGF,gBAAM,gBAAgB,MAAM,KAAK,GAC9B,QAAQ,iDAAiD,EACzD,KAAK,KAAK,EACV,IASE;AAEL,gBAAM,WAAqB,cAAc,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,YAChE,IAAI,EAAE;AAAA,YACN,YAAY,EAAE;AAAA,YACd,UAAU,EAAE;AAAA,YACZ,UAAU,EAAE;AAAA,YACZ,SAAS,EAAE,WAAW;AAAA,YACtB,QAAQ,EAAE,UAAU;AAAA,YACpB,QAAQ,EAAE;AAAA,YACV,WAAW,EAAE;AAAA,UACf,EAAE;AAIF,gBAAM,iBAAiB,MAAM,KAAK,GAC/B,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAQR,EACA,KAAK,KAAK,EACV,IAaE;AAEL,gBAAM,YAA8B,eAAe,WAAW,CAAC,GAAG,IAAI,OAAK;AACzE,kBAAM,cAAqB,EAAE,mBACzB,EAAE,iBAAiB,MAAM,KAAK,EAAE,IAAI,OAAK;AACvC,oBAAM,CAAC,MAAM,KAAK,IAAI,EAAE,MAAM,GAAG;AACjC,qBAAO,EAAE,MAAM,OAAO,SAAS,SAAS,KAAK,EAAE,GAAG,UAAU,CAAC,GAAG,WAAW,CAAC,EAAE;AAAA,YAChF,CAAC,IACD,CAAC;AAEL,mBAAO;AAAA,cACL,UAAU,EAAE;AAAA,cACZ,eAAe;AAAA,gBACb,OAAO,EAAE;AAAA,gBACT,OAAO,EAAE;AAAA,gBACT,UAAU,KAAK,MAAM,EAAE,2BAA2B,IAAI;AAAA,cACxD;AAAA,cACA,eAAe,EAAE;AAAA,cACjB,cAAc,KAAK,MAAM,EAAE,iBAAiB,IAAI;AAAA,cAChD,gBAAgB,CAAC;AAAA,cACjB;AAAA,cACA,WAAW;AAAA,gBACT,MAAM,EAAE;AAAA,gBACR,YAAY,EAAE;AAAA,gBACd,UAAU,KAAK,MAAM,EAAE,sBAAsB,IAAI;AAAA,cACnD;AAAA,cACA,WAAW,EAAE;AAAA,cACb,aAAc,EAAE,uBAAuB,EAAE,uBAAwB;AAAA,cACjE,cAAc,EAAE,uBAAuB,EAAE;AAAA,cACzC,SAAS,EAAE,iBAAiB;AAAA,cAC5B,iBAAiB,KAAK,MAAM,EAAE,iBAAiB,IAAI,EAAE,IAAI,CAAC,SAAiB,EAAE,IAAI,EAAE;AAAA,cACnF,mBAAmB,YAAY,IAAI,QAAM,EAAE,MAAM,EAAE,MAAM,OAAO,EAAE,OAAO,WAAW,CAAC,EAAE,EAAE;AAAA,YAC3F;AAAA,UACF,CAAC;AAGD,gBAAM,gBAAgB,MAAM,KAAK,GAC9B,QAAQ,0DAA0D,EAClE,KAAK,KAAK,EACV,IAQE;AAEL,gBAAM,mBAAsC,cAAc,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,YACjF,YAAY,EAAE;AAAA,YACd,iBAAiB,EAAE;AAAA,YACnB,cAAc,EAAE;AAAA,YAChB,kBAAkB,EAAE;AAAA,YACpB,uBAAuB,EAAE;AAAA,YACzB,WAAW,EAAE;AAAA,UACf,EAAE;AAGF,gBAAM,oBAAoB,MAAM,KAAK,GAClC,QAAQ,8FAA8F,EACtG,KAAK,KAAK,EACV,MAOE;AAEL,gBAAM,sBAA2C,oBAAoB;AAAA,YACnE,YAAY,kBAAkB;AAAA,YAC9B,kBAAkB,KAAK,MAAM,kBAAkB,qBAAqB,IAAI;AAAA,YACxE,kBAAkB,KAAK,MAAM,kBAAkB,sBAAsB,IAAI;AAAA,YACzE,kBAAkB,KAAK,MAAM,kBAAkB,qBAAqB,IAAI;AAAA,YACxE,qBAAqB,KAAK,MAAM,kBAAkB,yBAAyB,IAAI;AAAA,YAC/E,WAAW,kBAAkB;AAAA,UAC/B,IAAI;AAAA,YACF,YAAY;AAAA,YACZ,kBAAkB,CAAC;AAAA,YACnB,kBAAkB,CAAC;AAAA,YACnB,kBAAkB,CAAC;AAAA,YACnB,qBAAqB,CAAC;AAAA,YACtB,WAAW,IAAI;AAAA,UACjB;AAGA,gBAAM,mBAAmB,MAAM,KAAK,GACjC,QAAQ,4EAA4E,EACpF,KAAK,KAAK,EACV,IAME;AAEL,gBAAM,cAAgC,iBAAiB,WAAW,CAAC,GAAG,IAAI,SAAO;AAAA,YAC/E,WAAW,GAAG;AAAA,YACd,iBAAiB,GAAG;AAAA,YACpB,eAAe,GAAG;AAAA,YAClB,mBAAmB,GAAG;AAAA,YACtB,wBAAwB,GAAG;AAAA,UAC7B,EAAE;AAEF,iBAAO;AAAA,YACL,YAAY,IAAI;AAAA,YAChB,SAAS,IAAI;AAAA,YACb,UAAU,IAAI;AAAA,YACd;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA,WAAW,IAAI;AAAA,YACf,WAAW,IAAI;AAAA,UACjB;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,qBACJ,YACwB;AACxB,cAAM,MAAM,MAAM,KAAK,GACpB;AAAA,UACC;AAAA,QACF,EACC,KAAK,UAAU,EACf,MAAsB;AAEzB,eAAO,KAAK,MAAM;AAAA,MACpB;AAAA,MAEA,MAAM,eAAe,OAA8B;AAGjD,cAAM,KAAK,iBAAiB,YAAY;AAEtC,gBAAM,UAAU,MAAM,KAAK,GACxB,QAAQ,kDAAkD,EAC1D,KAAK,KAAK,EACV,IAAoB;AAEvB,gBAAM,aAAa,QAAQ,WAAW,CAAC,GAAG,IAAI,OAAK,EAAE,EAAE;AAEvD,cAAI,UAAU,SAAS,GAAG;AAExB,kBAAM,YAAY;AAClB,qBAAS,IAAI,GAAG,IAAI,UAAU,QAAQ,KAAK,WAAW;AACpD,oBAAM,QAAQ,UAAU,MAAM,GAAG,IAAI,SAAS;AAG9C,oBAAM,YAAY,MAAM,KAAK,GAC1B,QAAQ;AAAA;AAAA;AAAA;AAAA,iEAI4C,MAAM,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AAAA,aACjF,EACA,KAAK,OAAO,GAAG,KAAK,EACpB,IAAoB;AAEvB,oBAAM,eAAe,UAAU,WAAW,CAAC,GAAG,IAAI,OAAK,EAAE,EAAE;AAE3D,kBAAI,YAAY,SAAS,GAAG;AAE1B,yBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,wBAAM,gBAAgB,YAAY,MAAM,GAAG,IAAI,SAAS;AACxD,wBAAM,KAAK,GACR,QAAQ,mDAAmD,cAAc,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EACpG,KAAK,GAAG,aAAa,EACrB,IAAI;AAAA,gBACT;AAGA,yBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,wBAAM,gBAAgB,YAAY,MAAM,GAAG,IAAI,SAAS;AACxD,wBAAM,KAAK,GACR,QAAQ,0CAA0C,cAAc,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EAC3F,KAAK,GAAG,aAAa,EACrB,IAAI;AAAA,gBACT;AAAA,cACF;AAGA,oBAAM,WAAW,MAAM,KAAK,GACzB,QAAQ;AAAA;AAAA;AAAA;AAAA,iEAI4C,MAAM,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AAAA,aACjF,EACA,KAAK,OAAO,GAAG,KAAK,EACpB,IAAoB;AAEvB,oBAAM,eAAe,SAAS,WAAW,CAAC,GAAG,IAAI,OAAK,EAAE,EAAE;AAE1D,kBAAI,YAAY,SAAS,GAAG;AAE1B,yBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,wBAAM,gBAAgB,YAAY,MAAM,GAAG,IAAI,SAAS;AACxD,wBAAM,KAAK,GACR,QAAQ,gEAAgE,cAAc,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EACjH,KAAK,GAAG,aAAa,EACrB,IAAI;AAAA,gBACT;AAGA,yBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,wBAAM,gBAAgB,YAAY,MAAM,GAAG,IAAI,SAAS;AACxD,wBAAM,KAAK,GACR,QAAQ,4CAA4C,cAAc,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EAC7F,KAAK,GAAG,aAAa,EACrB,IAAI;AAAA,gBACT;AAAA,cACF;AAGA,oBAAM,KAAK,GACR,QAAQ,oCAAoC,MAAM,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EAC7E,KAAK,GAAG,KAAK,EACb,IAAI;AAAA,YACT;AAAA,UACF;AAGA,gBAAM,KAAK,GACR,QAAQ,wDAAwD,EAChE,KAAK,KAAK,EACV,IAAI;AAGP,gBAAM,KAAK,GACR,QAAQ,4DAA4D,EACpE,KAAK,KAAK,EACV,IAAI;AAGP,gBAAM,KAAK,GACR,QAAQ,mDAAmD,EAC3D,KAAK,KAAK,EACV,IAAI;AAGP,gBAAM,KAAK,GACR,QAAQ,kDAAkD,EAC1D,KAAK,KAAK,EACV,IAAI;AAGP,gBAAM,KAAK,GACR,QAAQ,wCAAwC,EAChD,KAAK,KAAK,EACV,IAAI;AAAA,QACT,CAAC;AAAA,MACH;AAAA;AAAA,MAGA,MAAM,cAAc,SAA2E;AAC7F,cAAM,KAAK,WAAW,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,GAAG,CAAC;AAC7E,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AACnC,cAAM,KAAK,GACR;AAAA,UACC;AAAA;AAAA,QAEF,EACC;AAAA,UACC;AAAA,UACA,QAAQ;AAAA,UACR,QAAQ;AAAA,UACR,QAAQ;AAAA,UACR,QAAQ;AAAA,UACR,QAAQ,UAAU;AAAA,UAClB,QAAQ,eAAe;AAAA,UACvB,QAAQ,WAAW,IAAI;AAAA,UACvB;AAAA,UACA;AAAA,QACF,EACC,IAAI;AACP,eAAO;AAAA,MACT;AAAA,MAEA,MAAM,WAAW,WAA4C;AAC3D,cAAM,UAAU,MAAM,KAAK,GACxB,QAAQ,sCAAsC,EAC9C,KAAK,SAAS,EACd,MAWE;AAEL,YAAI,CAAC;AAAS,iBAAO;AAErB,eAAO;AAAA,UACL,IAAI,QAAQ;AAAA,UACZ,MAAM,QAAQ;AAAA,UACd,YAAY,QAAQ;AAAA,UACpB,SAAS,QAAQ;AAAA,UACjB,UAAU,QAAQ;AAAA,UAClB,QAAQ,QAAQ,UAAU;AAAA,UAC1B,aAAa,QAAQ,eAAe;AAAA,UACpC,UAAU,QAAQ,cAAc;AAAA,UAChC,WAAW,QAAQ;AAAA,UACnB,WAAW,QAAQ;AAAA,QACrB;AAAA,MACF;AAAA,MAEA,MAAM,kBAAsC;AAG1C,cAAM,YAAY,MAAM,KAAK,GAC1B;AAAA,UACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAUF,EACC,IAOE;AAEL,gBAAQ,UAAU,WAAW,CAAC,GAAG,IAAI,CAAC,MAAM;AAE1C,cAAI,cAAc,EAAE;AACpB,cAAI;AACF,kBAAM,MAAM,IAAI,IAAI,EAAE,YAAY,WAAW,MAAM,IAAI,EAAE,cAAc,WAAW,EAAE,aAAa;AACjG,0BAAc,IAAI,SAAS,QAAQ,QAAQ,EAAE;AAAA,UAC/C,SAAS,GAAP;AAAA,UAEF;AAGA,iBAAO;AAAA,YACL,IAAI,mBAAmB,EAAE,WAAW;AAAA,YACpC,MAAM;AAAA,YACN,YAAY,EAAE;AAAA,YACd,SAAS,EAAE;AAAA,YACX,UAAU,EAAE;AAAA,YACZ,QAAQ,EAAE,UAAU;AAAA,YACpB,aAAa;AAAA,YACb,UAAU;AAAA,YACV,WAAW,EAAE;AAAA,YACb,WAAW,EAAE;AAAA,UACf;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,cAAc,WAAmB,SAA0C;AAC/E,cAAM,SAAmB,CAAC;AAC1B,cAAM,SAAgB,CAAC;AAEvB,YAAI,QAAQ,SAAS,QAAW;AAC9B,iBAAO,KAAK,UAAU;AACtB,iBAAO,KAAK,QAAQ,IAAI;AAAA,QAC1B;AACA,YAAI,QAAQ,eAAe,QAAW;AACpC,iBAAO,KAAK,iBAAiB;AAC7B,iBAAO,KAAK,QAAQ,UAAU;AAAA,QAChC;AACA,YAAI,QAAQ,YAAY,QAAW;AACjC,iBAAO,KAAK,aAAa;AACzB,iBAAO,KAAK,QAAQ,OAAO;AAAA,QAC7B;AACA,YAAI,QAAQ,aAAa,QAAW;AAClC,iBAAO,KAAK,cAAc;AAC1B,iBAAO,KAAK,QAAQ,QAAQ;AAAA,QAC9B;AACA,YAAI,QAAQ,WAAW,QAAW;AAChC,iBAAO,KAAK,YAAY;AACxB,iBAAO,KAAK,QAAQ,UAAU,IAAI;AAAA,QACpC;AACA,YAAI,QAAQ,gBAAgB,QAAW;AACrC,iBAAO,KAAK,iBAAiB;AAC7B,iBAAO,KAAK,QAAQ,eAAe,IAAI;AAAA,QACzC;AACA,YAAI,QAAQ,aAAa,QAAW;AAClC,iBAAO,KAAK,eAAe;AAC3B,iBAAO,KAAK,QAAQ,WAAW,IAAI,CAAC;AAAA,QACtC;AAEA,eAAO,KAAK,gBAAgB;AAC5B,eAAO,MAAK,oBAAI,KAAK,GAAE,YAAY,CAAC;AACpC,eAAO,KAAK,SAAS;AAErB,cAAM,KAAK,GACR,QAAQ,wBAAwB,OAAO,KAAK,IAAI,gBAAgB,EAChE,KAAK,GAAG,MAAM,EACd,IAAI;AAAA,MACT;AAAA;AAAA,MAGA,MAAM,kBAAkB,QAAgF;AACtG,cAAM,KAAK,UAAU,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,GAAG,CAAC;AAC5E,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AACnC,cAAM,KAAK,GACR;AAAA,UACC;AAAA;AAAA,QAEF,EACC;AAAA,UACC;AAAA,UACA,OAAO;AAAA,UACP,OAAO;AAAA,UACP,OAAO,cAAc;AAAA,UACrB,OAAO,gBAAgB;AAAA,UACvB,OAAO;AAAA,UACP,OAAO,WAAW;AAAA,UAClB,OAAO,UAAU;AAAA,UACjB,OAAO,WAAW,IAAI;AAAA,UACtB;AAAA,UACA;AAAA,QACF,EACC,IAAI;AACP,eAAO;AAAA,MACT;AAAA,MAEA,MAAM,kBAAkB,WAAmB,aAAsB,MAAgC;AAC/F,cAAM,QAAQ,aACV,kGACA;AAEJ,cAAM,UAAU,MAAM,KAAK,GACxB,QAAQ,KAAK,EACb,KAAK,SAAS,EACd,IAYE;AAEL,gBAAQ,QAAQ,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,UACvC,IAAI,EAAE;AAAA,UACN,WAAW,EAAE;AAAA,UACb,UAAU,EAAE;AAAA,UACZ,YAAY,EAAE,eAAe;AAAA,UAC7B,cAAc,EAAE,iBAAiB;AAAA,UACjC,UAAU,EAAE;AAAA,UACZ,SAAS,EAAE,WAAW;AAAA,UACtB,QAAQ,EAAE,UAAU;AAAA,UACpB,UAAU,EAAE,cAAc;AAAA,UAC1B,WAAW,EAAE;AAAA,UACb,WAAW,EAAE;AAAA,QACf,EAAE;AAAA,MACJ;AAAA,MAEA,MAAM,uBAAuB,WAAmB,QAAgB,IAAoB;AAElF,cAAM,aAAa,mBAAmB,SAAS;AAE/C,cAAM,OAAO,MAAM,KAAK,GACrB;AAAA,UACC;AAAA;AAAA;AAAA;AAAA;AAAA,QAKF,EACC,KAAK,YAAY,KAAK,EACtB,IASE;AAEL,gBAAQ,KAAK,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,UACpC,IAAI,EAAE;AAAA,UACN,YAAY,EAAE;AAAA,UACd,SAAS,EAAE;AAAA,UACX,UAAU,EAAE;AAAA,UACZ,QAAQ,EAAE,UAAU;AAAA,UACpB,QAAQ,EAAE,UAAU;AAAA,UACpB,WAAW,EAAE;AAAA,UACb,WAAW,EAAE;AAAA,QACf,EAAE;AAAA,MACJ;AAAA,MAEA,MAAM,mBAAmB,QAAgB,KAAqB;AAC5D,YAAI;AACJ,gBAAM,OAAO,MAAM,KAAK,GACrB;AAAA,YACC;AAAA;AAAA;AAAA;AAAA,UAIF,EACC,KAAK,KAAK,EACV,IAUE;AAGH,cAAI,CAAC,QAAQ,CAAC,KAAK,SAAS;AAC1B,mBAAO,CAAC;AAAA,UACV;AAEA,iBAAO,KAAK,QAAQ,IAAI,QAAM;AAAA,YAC9B,IAAI,EAAE;AAAA,YACN,YAAY,EAAE;AAAA,YACd,SAAS,EAAE;AAAA,YACX,UAAU,EAAE;AAAA,YACZ,QAAQ,EAAE,UAAU;AAAA,YAClB,QAAQ,EAAE,UAAU;AAAA,YACtB,WAAW,EAAE;AAAA,YACb,WAAW,EAAE;AAAA,YACb,WAAW,EAAE,cAAc;AAAA,UAC7B,EAAE;AAAA,QACF,SAAS,OAAP;AACA,kBAAQ,MAAM,gCAAgC,KAAK;AACnD,iBAAO,CAAC;AAAA,QACV;AAAA,MACF;AAAA;AAAA,MAGA,MAAM,yBAA+F;AAMnG,eAAO,KAAK,iBAAiB,YAAY;AACvC,cAAI;AACF,kBAAM,SAAS,MAAM,KAAK,GACvB;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAYF,EACC,IAIE;AAEL,oBAAQ,OAAO,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,cACtC,MAAM,EAAE;AAAA,cACR,aAAa,EAAE,eAAe;AAAA,cAC9B,OAAO,EAAE;AAAA,YACX,EAAE;AAAA,UACJ,SAAS,OAAP;AACA,oBAAQ,MAAM,2DAA2D,KAAK;AAE9E,kBAAM,iBAAiB,MAAM,KAAK,GAC/B;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAUF,EACC,IAIE;AAEL,oBAAQ,eAAe,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,cAC9C,MAAM,EAAE;AAAA,cACR,aAAa,EAAE,eAAe;AAAA,cAC9B,OAAO,EAAE;AAAA,YACX,EAAE;AAAA,UACJ;AAAA,QACF,CAAC,EAAE,MAAM,CAAC,UAAU;AAClB,kBAAQ,MAAM,yDAAyD,KAAK;AAE5E,iBAAO,CAAC;AAAA,QACV,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,2BAA2B,cAiB9B;AAGD,eAAO,KAAK,iBAAiB,YAAY;AACvC,cAAI;AAEF,kBAAM,SAAS,MAAM,KAAK,GACvB;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAkBF,EACC,KAAK,YAAY,EACjB,IAUE;AAGL,kBAAM,UAAU,OAAO,WAAW,CAAC;AACnC,kBAAM,YAAY,QAAQ,IAAI,OAAK,EAAE,EAAE;AAEvC,gBAAI,UAAU,WAAW,GAAG;AAC1B,qBAAO,EAAE,SAAS,CAAC,GAAG,aAAa,CAAC,EAAE;AAAA,YACxC;AAGA,kBAAM,gBAAgB,MAAM,KAAK,GAC9B;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKuB,UAAU,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AAAA,YAC1D,EACC,KAAK,GAAG,SAAS,EACjB,IAIE;AAGL,kBAAM,YAAY,oBAAI,IAAoB;AAC1C,aAAC,cAAc,WAAW,CAAC,GAAG,QAAQ,OAAK;AACzC,kBAAI,EAAE,OAAO,KAAK,EAAE,eAAe,EAAE,YAAY,KAAK,GAAG;AACvD,0BAAU,IAAI,EAAE,WAAW,EAAE,WAAW;AAAA,cAC1C;AAAA,YACF,CAAC;AAGD,kBAAM,kBAAkB,MAAM,KAAK,GAChC;AAAA,cACC;AAAA;AAAA;AAAA;AAAA,sCAI0B,UAAU,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AAAA,YAC7D,EACC,KAAK,GAAG,SAAS,EACjB,IAEE;AAGL,kBAAM,iBAAiB,oBAAI,IAAoB;AAC/C,aAAC,gBAAgB,WAAW,CAAC,GAAG,QAAQ,cAAY;AAClD,kBAAI;AACF,sBAAM,SAAS,IAAI,IAAI,SAAS,GAAG;AAEnC,sBAAM,SAAS,OAAO,SAAS,QAAQ,UAAU,EAAE,EAAE,YAAY;AACjE,+BAAe,IAAI,SAAS,eAAe,IAAI,MAAM,KAAK,KAAK,CAAC;AAAA,cAClE,QAAE;AAAA,cAEF;AAAA,YACF,CAAC;AAGD,kBAAM,cAAc,MAAM,KAAK,eAAe,QAAQ,CAAC,EACpD,IAAI,CAAC,CAAC,QAAQ,KAAK,OAAO,EAAE,QAAQ,MAAM,EAAE,EAC5C,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAGnC,kBAAM,qBAAqB,QACxB,IAAI,OAAK;AACR,oBAAM,SAAS,UAAU,IAAI,EAAE,EAAE;AACjC,kBAAI,CAAC;AAAQ,uBAAO;AACpB,qBAAO;AAAA,gBACL,IAAI,EAAE;AAAA,gBACN,UAAU,EAAE;AAAA,gBACZ;AAAA,gBACA,UAAU,EAAE;AAAA,gBACZ,SAAS,EAAE,WAAW;AAAA,gBACtB,QAAQ,EAAE,UAAU;AAAA,gBACpB,QAAQ,EAAE;AAAA,gBACV,WAAW,EAAE;AAAA,gBACb,eAAe,EAAE;AAAA,gBACjB,YAAY,EAAE;AAAA,cAChB;AAAA,YACF,CAAC,EACA,OAAO,CAAC,MAAkC,MAAM,IAAI;AAGvD,kBAAM,cAAc,oBAAI,IAA0C;AAClE,+BAAmB,QAAQ,YAAU;AACnC,oBAAM,WAAW,YAAY,IAAI,OAAO,QAAQ;AAChD,kBAAI,CAAC,YAAY,IAAI,KAAK,OAAO,SAAS,IAAI,IAAI,KAAK,SAAS,SAAS,GAAG;AAC1E,4BAAY,IAAI,OAAO,UAAU,MAAM;AAAA,cACzC;AAAA,YACF,CAAC;AAGD,kBAAM,sBAAsB,MAAM,KAAK,YAAY,OAAO,CAAC,EACxD,KAAK,CAAC,GAAG,MAAM,IAAI,KAAK,EAAE,SAAS,EAAE,QAAQ,IAAI,IAAI,KAAK,EAAE,SAAS,EAAE,QAAQ,CAAC;AAEnF,mBAAO;AAAA,cACL,SAAS;AAAA,cACT;AAAA,YACF;AAAA,UACF,SAAS,OAAP;AACA,oBAAQ,MAAM,8DAA8D,KAAK;AAEjF,kBAAM,iBAAiB,MAAM,KAAK,GAC/B;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAgBF,EACC,KAAK,YAAY,EACjB,IAUE;AAGL,kBAAM,qBAAqB,eAAe,WAAW,CAAC,GAAG,IAAI,OAAK,EAAE,EAAE;AACtE,gBAAI,kBAAkB,WAAW,GAAG;AAClC,qBAAO,EAAE,SAAS,CAAC,GAAG,aAAa,CAAC,EAAE;AAAA,YACxC;AAEA,kBAAM,wBAAwB,MAAM,KAAK,GACtC;AAAA,cACC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKuB,kBAAkB,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AAAA,YAClE,EACC,KAAK,GAAG,iBAAiB,EACzB,IAIE;AAEL,kBAAM,oBAAoB,oBAAI,IAAoB;AAClD,aAAC,sBAAsB,WAAW,CAAC,GAAG,QAAQ,OAAK;AACjD,kBAAI,EAAE,OAAO,KAAK,EAAE,eAAe,EAAE,YAAY,KAAK,GAAG;AACvD,kCAAkB,IAAI,EAAE,WAAW,EAAE,WAAW;AAAA,cAClD;AAAA,YACF,CAAC;AAGD,kBAAM,8BAA8B,eAAe,WAAW,CAAC,GAC5D,IAAI,OAAK;AACR,oBAAM,SAAS,kBAAkB,IAAI,EAAE,EAAE;AACzC,kBAAI,CAAC;AAAQ,uBAAO;AACpB,qBAAO;AAAA,gBACL,IAAI,EAAE;AAAA,gBACN,UAAU,EAAE;AAAA,gBACZ;AAAA,gBACA,UAAU,EAAE;AAAA,gBACZ,SAAS,EAAE,WAAW;AAAA,gBACtB,QAAQ,EAAE,UAAU;AAAA,gBACpB,QAAQ,EAAE;AAAA,gBACV,WAAW,EAAE;AAAA,gBACb,eAAe,EAAE;AAAA,gBACjB,YAAY,EAAE;AAAA,cAChB;AAAA,YACF,CAAC,EACA,OAAO,CAAC,MAAkC,MAAM,IAAI;AAGvD,kBAAM,sBAAsB,oBAAI,IAAkD;AAClF,uCAA2B,QAAQ,YAAU;AAC3C,oBAAM,WAAW,oBAAoB,IAAI,OAAO,QAAQ;AACxD,kBAAI,CAAC,YAAY,IAAI,KAAK,OAAO,SAAS,IAAI,IAAI,KAAK,SAAS,SAAS,GAAG;AAC1E,oCAAoB,IAAI,OAAO,UAAU,MAAM;AAAA,cACjD;AAAA,YACF,CAAC;AAED,kBAAM,8BAA8B,MAAM,KAAK,oBAAoB,OAAO,CAAC,EACxE,KAAK,CAAC,GAAG,MAAM,IAAI,KAAK,EAAE,SAAS,EAAE,QAAQ,IAAI,IAAI,KAAK,EAAE,SAAS,EAAE,QAAQ,CAAC;AAEnF,mBAAO;AAAA,cACL,SAAS;AAAA,cACT,aAAa,CAAC;AAAA,YAChB;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,MAAM,qBAAqB,WAAmB,OAAe,IAA+B;AAC1F,cAAM,aAAa,oBAAI,KAAK;AAC5B,mBAAW,QAAQ,WAAW,QAAQ,IAAI,IAAI;AAE9C,cAAM,aAAa,MAAM,KAAK,GAC3B;AAAA,UACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAMF,EACC,KAAK,WAAW,WAAW,YAAY,CAAC,EACxC,IAME;AAEL,gBAAQ,WAAW,WAAW,CAAC,GAAG,IAAI,SAAO;AAAA,UAC3C,WAAW,GAAG;AAAA,UACd,iBAAiB,GAAG;AAAA,UACpB,eAAe,GAAG;AAAA,UAClB,mBAAmB,GAAG;AAAA,UACtB,wBAAwB,GAAG;AAAA,QAC7B,EAAE;AAAA,MACJ;AAAA;AAAA,MAGA,MAAM,mBAAmB,UAAiF;AACxG,cAAM,KAAK,YAAY,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,GAAG,CAAC;AAC9E,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AACnC,cAAM,KAAK,GACR;AAAA,UACC;AAAA;AAAA,QAEF,EACC;AAAA,UACC;AAAA,UACA,SAAS;AAAA,UACT,SAAS;AAAA,UACT,SAAS;AAAA,UACT,SAAS,aAAa;AAAA,UACtB,SAAS,WAAW,IAAI;AAAA,UACxB;AAAA,UACA;AAAA,QACF,EACC,IAAI;AACP,eAAO;AAAA,MACT;AAAA,MAEA,MAAM,iBAAiB,WAAoB,aAAsB,MAA+B;AAC9F,YAAI,QAAQ;AACZ,cAAM,aAAuB,CAAC;AAC9B,cAAM,SAAgB,CAAC;AAEvB,YAAI,WAAW;AACb,qBAAW,KAAK,gBAAgB;AAChC,iBAAO,KAAK,SAAS;AAAA,QACvB;AACA,YAAI,YAAY;AACd,qBAAW,KAAK,eAAe;AAAA,QACjC;AAEA,YAAI,WAAW,SAAS,GAAG;AACzB,mBAAS,YAAY,WAAW,KAAK,OAAO;AAAA,QAC9C;AAEA,iBAAS;AAET,cAAM,YAAY,MAAM,KAAK,GAC1B,QAAQ,KAAK,EACb,KAAK,GAAG,MAAM,EACd,IASE;AAEL,gBAAQ,UAAU,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,UACzC,IAAI,EAAE;AAAA,UACN,WAAW,EAAE;AAAA,UACb,cAAc,EAAE;AAAA,UAChB,WAAW,EAAE;AAAA,UACb,WAAW,EAAE,eAAe;AAAA,UAC5B,UAAU,EAAE,cAAc;AAAA,UAC1B,WAAW,EAAE;AAAA,UACb,WAAW,EAAE;AAAA,QACf,EAAE;AAAA,MACJ;AAAA,MAEA,MAAM,mBAAmB,YAAoB,SAA+C;AAC1F,cAAM,SAAmB,CAAC;AAC1B,cAAM,SAAgB,CAAC;AAEvB,YAAI,QAAQ,iBAAiB,QAAW;AACtC,iBAAO,KAAK,mBAAmB;AAC/B,iBAAO,KAAK,QAAQ,YAAY;AAAA,QAClC;AACA,YAAI,QAAQ,cAAc,QAAW;AACnC,iBAAO,KAAK,iBAAiB;AAC7B,iBAAO,KAAK,QAAQ,SAAS;AAAA,QAC/B;AACA,YAAI,QAAQ,cAAc,QAAW;AACnC,iBAAO,KAAK,iBAAiB;AAC7B,iBAAO,KAAK,QAAQ,aAAa,IAAI;AAAA,QACvC;AACA,YAAI,QAAQ,aAAa,QAAW;AAClC,iBAAO,KAAK,eAAe;AAC3B,iBAAO,KAAK,QAAQ,WAAW,IAAI,CAAC;AAAA,QACtC;AAEA,eAAO,KAAK,gBAAgB;AAC5B,eAAO,MAAK,oBAAI,KAAK,GAAE,YAAY,CAAC;AACpC,eAAO,KAAK,UAAU;AAEtB,cAAM,KAAK,GACR,QAAQ,6BAA6B,OAAO,KAAK,IAAI,gBAAgB,EACrE,KAAK,GAAG,MAAM,EACd,IAAI;AAAA,MACT;AAAA,MAEA,MAAM,sBAA+C;AACnD,cAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AACnC,cAAM,YAAY,MAAM,KAAK,GAC1B;AAAA,UACC;AAAA;AAAA;AAAA,QAGF,EACC,KAAK,GAAG,EACR,IASE;AAEL,gBAAQ,UAAU,WAAW,CAAC,GAAG,IAAI,QAAM;AAAA,UACzC,IAAI,EAAE;AAAA,UACN,WAAW,EAAE;AAAA,UACb,cAAc,EAAE;AAAA,UAChB,WAAW,EAAE;AAAA,UACb,WAAW,EAAE,eAAe;AAAA,UAC5B,UAAU,EAAE,cAAc;AAAA,UAC1B,WAAW,EAAE;AAAA,UACb,WAAW,EAAE;AAAA,QACf,EAAE;AAAA,MACJ;AAAA,IACF;AA7wDa;AAAA;AAAA;;;AChDb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AAAA;;;ACJA;;;ACAA;;;ACAA;;;ACAA;;;ACAA;AAUO,IAAM,SAA4B;AAAA;AAAA,EAEvC,EAAE,QAAQ,QAAQ,MAAM,uBAAuB,SAAS,iBAAiB;AAAA,EACzE,EAAE,QAAQ,QAAQ,MAAM,uBAAuB,SAAS,iBAAiB;AAAA,EACzE,EAAE,QAAQ,OAAO,MAAM,2CAA2C,SAAS,0BAA0B;AAAA,EACrG,EAAE,QAAQ,QAAQ,MAAM,uBAAuB,SAAS,iBAAiB;AAAA,EACzE,EAAE,QAAQ,QAAQ,MAAM,uBAAuB,SAAS,iBAAiB;AAAA,EACzE,EAAE,QAAQ,QAAQ,MAAM,0BAA0B,SAAS,oBAAoB;AAAA,EAC/E,EAAE,QAAQ,QAAQ,MAAM,iCAAiC,SAAS,2BAA2B;AAAA,EAC7F,EAAE,QAAQ,QAAQ,MAAM,6BAA6B,SAAS,uBAAuB;AAAA;AAAA,EAGrF,EAAE,QAAQ,OAAO,MAAM,iBAAiB,SAAS,kBAAkB;AAAA,EACnE,EAAE,QAAQ,OAAO,MAAM,gDAAgD,SAAS,gCAAgC;AAAA,EAChH,EAAE,QAAQ,UAAU,MAAM,+BAA+B,SAAS,kBAAkB;AAAA;AAAA,EAGpF,EAAE,QAAQ,OAAO,MAAM,kBAAkB,SAAS,2BAA2B;AAAA,EAC7E,EAAE,QAAQ,OAAO,MAAM,0CAA0C,SAAS,8BAA8B;AAAA,EACxG,EAAE,QAAQ,OAAO,MAAM,0BAA0B,SAAS,+BAA+B;AAAA,EACzF,EAAE,QAAQ,OAAO,MAAM,kDAAkD,SAAS,sCAAsC;AAAA;AAAA,EAGxH,EAAE,QAAQ,OAAO,MAAM,eAAe,SAAS,eAAe;AAChE;AAEO,SAAS,WACd,MACA,QACmE;AACnE,aAAW,SAAS,QAAQ;AAC1B,QAAI,MAAM,WAAW;AAAQ;AAE7B,QAAI,OAAO,MAAM,SAAS,UAAU;AAClC,UAAI,MAAM,SAAS,MAAM;AACvB,eAAO,EAAE,OAAO,QAAQ,CAAC,EAAE;AAAA,MAC7B;AAAA,IACF,OAAO;AACL,YAAM,QAAQ,KAAK,MAAM,MAAM,IAAI;AACnC,UAAI,OAAO;AACT,cAAM,SAAiC,CAAC;AAExC,YAAI,MAAM,QAAQ;AAChB,iBAAO,OAAO,QAAQ,MAAM,MAAM;AAAA,QACpC,OAAO;AAEL,gBAAM,MAAM,CAAC,EAAE,QAAQ,CAAC,OAAO,UAAU;AACvC,mBAAO,QAAQ,OAAO,IAAI;AAAA,UAC5B,CAAC;AAAA,QACH;AACA,eAAO,EAAE,OAAO,OAAO;AAAA,MACzB;AAAA,IACF;AAAA,EACF;AACA,SAAO;AACT;AA7BgB;;;ACpChB;;;ACAA;AAUO,SAAS,iBAA8B;AAC5C,SAAO;AAAA,IACL,+BAA+B;AAAA,IAC/B,gCAAgC;AAAA,IAChC,gCAAgC;AAAA,EAClC;AACF;AANgB;AAQT,SAAS,WAAW,SAAmC;AAC5D,MAAI,QAAQ,WAAW,WAAW;AAChC,WAAO,IAAI,SAAS,MAAM,EAAE,SAAS,eAAe,EAAE,CAAC;AAAA,EACzD;AACA,SAAO;AACT;AALgB;;;AClBhB;AAMO,SAAS,YAAY,OAAgB,aAA0D;AACpG,UAAQ,MAAM,cAAc,KAAK;AACjC,SAAO,IAAI;AAAA,IACT,KAAK,UAAU;AAAA,MACb,OAAO;AAAA,MACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,IACpD,CAAC;AAAA,IACD;AAAA,MACE,QAAQ;AAAA,MACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,IAChE;AAAA,EACF;AACF;AAZgB;AAcT,SAAS,eAAe,aAA0D;AACvF,SAAO,IAAI;AAAA,IACT,KAAK,UAAU;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,IACX,CAAC;AAAA,IACD;AAAA,MACE,QAAQ;AAAA,MACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,IAChE;AAAA,EACF;AACF;AAXgB;;;ACpBhB;;;ACAA;AAQO,IAAM,cAAN,MAAkB;AAAA,EACvB,YAAoB,QAAgB;AAAhB;AAAA,EAAiB;AAAA,EAErC,MAAM,cAAc,QAAsC;AACxD,UAAM,WAAW,MAAM,KAAK,iBAAiB,OAAO,QAAQ;AAE5D,WAAO;AAAA,MACL,UAAU,OAAO;AAAA,MACjB,YAAY,SAAS;AAAA,MACrB,WAAW,SAAS;AAAA,MACpB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MAClC,OAAO,KAAK,OAAO,OAAO;AAAA,IAC5B;AAAA,EACF;AAAA,EAEA,MAAM,eAAe,SAA2C;AAC9D,UAAM,YAA2B,CAAC;AAGlC,eAAW,UAAU,SAAS;AAC5B,UAAI;AACF,cAAM,WAAW,MAAM,KAAK,cAAc,MAAM;AAEhD,YAAI,YAAY,SAAS,cAAc,SAAS,WAAW,KAAK,EAAE,SAAS,GAAG;AAC5E,oBAAU,KAAK,QAAQ;AAAA,QACzB,OAAO;AACL,kBAAQ,KAAK,UAAU,OAAO,0CAA0C;AAAA,QAC1E;AAAA,MACF,SAAS,OAAP;AACA,gBAAQ,MAAM,4BAA4B,OAAO,OAAO,KAAK;AAAA,MAE/D;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,MAAc,iBAAiB,UAG5B;AAED,QAAI,KAAK,OAAO,OAAO,SAAS;AAC9B,cAAQ,IAAI,kEAA2D;AACvE,aAAO,KAAK,iBAAiB,QAAQ;AAAA,IACvC;AAMA,UAAM,MAAM;AAEZ,QAAI,CAAC,KAAK,OAAO,OAAO,QAAQ;AAC9B,YAAM,IAAI,MAAM,kCAAkC;AAAA,IACpD;AAEA,UAAM,cAAc;AAAA,MAClB,OAAO,KAAK,OAAO,OAAO;AAAA,MAC1B,OAAO;AAAA,QACL;AAAA,UACE,MAAM;AAAA,QACR;AAAA,MACF;AAAA,MACA,OAAO;AAAA,IACT;AAEA,YAAQ,IAAI,oDAA6C;AACzD,YAAQ,IAAI,UAAU,GAAG;AACzB,YAAQ,IAAI,YAAY,KAAK,OAAO,OAAO,KAAK;AAChD,YAAQ,IAAI,sBAAsB,CAAC,CAAC,KAAK,OAAO,OAAO,MAAM;AAC7D,YAAQ,IAAI,qBAAqB,KAAK,OAAO,OAAO,QAAQ,UAAU,CAAC;AACvE,YAAQ,IAAI,mBAAmB,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC;AAEnE,QAAI;AACJ,QAAI;AACF,iBAAW,MAAM,MAAM,KAAK;AAAA,QAC1B,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,UAChB,eAAe,UAAU,KAAK,OAAO,OAAO;AAAA,QAC9C;AAAA,QACA,MAAM,KAAK,UAAU,WAAW;AAAA,MAClC,CAAC;AAAA,IACH,SAAS,YAAP;AACA,cAAQ,MAAM,uBAAkB,UAAU;AAC1C,YAAM,IAAI,MAAM,oCAAoC,sBAAsB,QAAQ,WAAW,UAAU,OAAO,UAAU,GAAG;AAAA,IAC7H;AAEA,YAAQ,IAAI,8BAAuB,SAAS,QAAQ,SAAS,UAAU;AACvE,YAAQ,IAAI,+BAAwB,OAAO,YAAY,SAAS,QAAQ,QAAQ,CAAC,CAAC;AAElF,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,YAAY;AAChB,UAAI;AACF,oBAAY,MAAM,SAAS,KAAK;AAChC,gBAAQ,MAAM,mCAA8B,SAAS;AAAA,MACvD,SAAS,GAAP;AACA,oBAAY;AACZ,gBAAQ,MAAM,yCAAoC,CAAC;AAAA,MACrD;AACA,cAAQ,MAAM,qCAAgC,SAAS,MAAM;AAC7D,cAAQ,MAAM,0CAAqC,SAAS,UAAU;AAGtE,UAAI,YAAiB;AACrB,UAAI;AACF,oBAAY,KAAK,MAAM,SAAS;AAChC,gBAAQ,MAAM,0BAAqB,KAAK,UAAU,WAAW,MAAM,CAAC,CAAC;AAAA,MACvE,SAAS,GAAP;AAAA,MAEF;AAEA,YAAM,eAAe,WAAW,OAAO,WAAW,WAAW,SAAS,aAAa,SAAS;AAC5F,YAAM,IAAI;AAAA,QACR,qBAAqB,SAAS,UAAU,SAAS,gBAAgB,aAAa,UAAU,GAAG,GAAG;AAAA,MAChG;AAAA,IACF;AAEA,QAAI;AACJ,QAAI;AACF,aAAO,MAAM,SAAS,KAAK;AAC3B,cAAQ,IAAI,oCAA6B,MAAM,QAAQ,IAAI,IAAI,UAAU,OAAO,IAAI;AACpF,UAAI;AACF,gBAAQ,IAAI,+BAAwB,KAAK,UAAU,MAAM,MAAM,CAAC,CAAC;AAAA,MACnE,SAAS,GAAP;AACA,gBAAQ,MAAM,wCAAmC,CAAC;AAAA,MACpD;AAAA,IACF,SAAS,WAAP;AACA,YAAM,eAAe,MAAM,SAAS,KAAK;AACzC,cAAQ,MAAM,yCAAoC,SAAS;AAC3D,cAAQ,MAAM,yBAAoB,YAAY;AAC9C,YAAM,IAAI,MAAM,iCAAiC,qBAAqB,QAAQ,UAAU,UAAU,OAAO,SAAS,gBAAgB,aAAa,UAAU,GAAG,GAAG,GAAG;AAAA,IACpK;AAQA,QAAI;AACJ,QAAI;AACJ,QAAI;AACF,mBAAa,KAAK,kBAAkB,IAAI;AACxC,kBAAY,KAAK,iBAAiB,IAAI;AAAA,IACxC,SAAS,cAAP;AACA,YAAM;AAAA,IACR;AAEA,YAAQ,IAAI,0CAAmC,WAAW,MAAM;AAChE,YAAQ,IAAI,2CAAoC,WAAW,UAAU,GAAG,GAAG,CAAC;AAC5E,YAAQ,IAAI,wCAAiC,UAAU,MAAM;AAC7D,QAAI,UAAU,SAAS,GAAG;AACxB,cAAQ,IAAI,kCAA2B,KAAK,UAAU,WAAW,MAAM,CAAC,CAAC;AAAA,IAC3E,OAAO;AACL,cAAQ,KAAK,4DAAkD,KAAK,UAAU,MAAM,MAAM,CAAC,EAAE,UAAU,GAAG,GAAI,CAAC;AAAA,IACjH;AAEA,QAAI,CAAC,cAAc,WAAW,KAAK,EAAE,WAAW,GAAG;AACjD,cAAQ,MAAM,2CAAsC;AACpD,cAAQ,MAAM,yBAAoB,KAAK,UAAU,MAAM,MAAM,CAAC,CAAC;AAC/D,YAAM,IAAI,MAAM,oFAAiF;AAAA,IACnG;AAEA,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,kBAAkB,MAAmB;AAC3C,YAAQ,IAAI,kDAA2C,MAAM,QAAQ,IAAI,IAAI,UAAU,OAAO,IAAI;AAQlG,QAAI,QAAQ,OAAO,SAAS,YAAY,MAAM,QAAS,KAAa,MAAM,GAAG;AAC3E,YAAM,cAAe,KAAa;AAElC,YAAM,aAAa,YAAY;AAAA,QAC7B,CAAC,SAAc,KAAK,SAAS,aAAa,KAAK,WAAW;AAAA,MAC5D;AAEA,UAAI,YAAY,WAAW,MAAM,QAAQ,WAAW,OAAO,GAAG;AAE5D,cAAM,iBAAiB,WAAW,QAAQ;AAAA,UACxC,CAAC,SAAc,KAAK,SAAS;AAAA,QAC/B;AAEA,YAAI,gBAAgB,MAAM;AACxB,iBAAO,eAAe;AAAA,QACxB;AAAA,MACF;AAAA,IACF;AAGA,QAAI,QAAQ,OAAO,SAAS,YAAY,MAAM,QAAS,KAAa,IAAI,GAAG;AAEzE,aAAO,KAAK,kBAAmB,KAAa,IAAI;AAAA,IAClD;AAGA,QAAI,QAAQ,OAAO,SAAS,YAAY,iBAAiB,MAAM;AAC7D,cAAQ,IAAI,sDAAiD;AAC7D,aAAQ,KAAa;AAAA,IACvB;AAGA,QAAI,MAAM,QAAQ,IAAI,GAAG;AACvB,cAAQ,IAAI,oCAA6B,KAAK,MAAM;AAIpD,YAAM,aAAa,KAAK;AAAA,QACtB,CAAC,SAAc,KAAK,SAAS,aAAa,KAAK,WAAW;AAAA,MAC5D;AAEA,cAAQ,IAAI,+BAAwB,aAAa,QAAQ,IAAI;AAE7D,UAAI,YAAY,WAAW,MAAM,QAAQ,WAAW,OAAO,GAAG;AAC5D,gBAAQ,IAAI,kDAA2C,WAAW,QAAQ,MAAM;AAIhF,cAAM,iBAAiB,WAAW,QAAQ;AAAA,UACxC,CAAC,SAAc,KAAK,SAAS;AAAA,QAC/B;AAEA,gBAAQ,IAAI,mCAA4B,iBAAiB,QAAQ,IAAI;AAErE,YAAI,gBAAgB,MAAM;AACxB,kBAAQ,IAAI,2DAAsD,eAAe,KAAK,MAAM;AAC5F,iBAAO,eAAe;AAAA,QACxB,WAAW,gBAAgB;AACzB,kBAAQ,KAAK,iEAAuD,OAAO,KAAK,cAAc,CAAC;AAAA,QACjG;AAAA,MACF;AAAA,IACF;AAGA,QAAI,MAAM,SAAS,aAAa;AAC9B,cAAQ,IAAI,iDAA4C;AACxD,aAAO,KAAK,QAAQ;AAAA,IACtB;AAEA,QAAI,MAAM,YAAY;AACpB,cAAQ,IAAI,wCAAmC;AAC/C,aAAO,KAAK;AAAA,IACd;AAEA,YAAQ,MAAM,+CAA0C;AACxD,YAAQ,MAAM,0BAAqB,KAAK,UAAU,MAAM,MAAM,CAAC,CAAC;AAChE,WAAO;AAAA,EACT;AAAA,EAEQ,iBAAiB,MAAgC;AACvD,UAAM,YAAiC,CAAC;AAOxC,QAAI,QAAQ,OAAO,SAAS,YAAY,MAAM,QAAS,KAAa,MAAM,GAAG;AAC3E,YAAM,cAAe,KAAa;AAElC,YAAM,aAAa,YAAY;AAAA,QAC7B,CAAC,SAAc,KAAK,SAAS,aAAa,KAAK,WAAW;AAAA,MAC5D;AAEA,UAAI,YAAY,WAAW,MAAM,QAAQ,WAAW,OAAO,GAAG;AAE5D,cAAM,iBAAiB,WAAW,QAAQ;AAAA,UACxC,CAAC,SAAc,KAAK,SAAS;AAAA,QAC/B;AAIA,YAAI,gBAAgB,eAAe,MAAM,QAAQ,eAAe,WAAW,GAAG;AAC5E,qBAAW,cAAc,eAAe,aAAa;AACnD,gBAAI,WAAW,SAAS,kBAAkB,WAAW,KAAK;AACxD,wBAAU,KAAK;AAAA,gBACb,KAAK,WAAW;AAAA,gBAChB,OAAO,WAAW,SAAS,WAAW;AAAA,gBACtC,SAAS,WAAW,WAAW;AAAA,cACjC,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,MAAM,QAAQ,IAAI,GAAG;AAEvB,YAAM,aAAa,KAAK;AAAA,QACtB,CAAC,SAAc,KAAK,SAAS,aAAa,KAAK,WAAW;AAAA,MAC5D;AAEA,UAAI,YAAY,WAAW,MAAM,QAAQ,WAAW,OAAO,GAAG;AAE5D,cAAM,iBAAiB,WAAW,QAAQ;AAAA,UACxC,CAAC,SAAc,KAAK,SAAS;AAAA,QAC/B;AAIA,YAAI,gBAAgB,eAAe,MAAM,QAAQ,eAAe,WAAW,GAAG;AAC5E,qBAAW,cAAc,eAAe,aAAa;AACnD,gBAAI,WAAW,SAAS,kBAAkB,WAAW,KAAK;AACxD,wBAAU,KAAK;AAAA,gBACb,KAAK,WAAW;AAAA,gBAChB,OAAO,WAAW,SAAS,WAAW;AAAA,gBACtC,SAAS,WAAW,WAAW;AAAA,cACjC,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,MAAM,SAAS,WAAW,MAAM,QAAQ,KAAK,QAAQ,OAAO,GAAG;AACjE,iBAAW,QAAQ,KAAK,QAAQ,SAAS;AACvC,YAAI,KAAK,eAAe,MAAM,QAAQ,KAAK,WAAW,GAAG;AACvD,qBAAW,cAAc,KAAK,aAAa;AACzC,gBAAI,WAAW,SAAS,kBAAkB,WAAW,KAAK;AACxD,wBAAU,KAAK;AAAA,gBACb,KAAK,WAAW;AAAA,gBAChB,OAAO,WAAW,SAAS,WAAW;AAAA,gBACtC,SAAS,WAAW,WAAW;AAAA,cACjC,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,UAAM,kBAAkB,oBAAI,IAA+B;AAC3D,eAAW,YAAY,WAAW;AAChC,UAAI,SAAS,OAAO,CAAC,gBAAgB,IAAI,SAAS,GAAG,GAAG;AACtD,wBAAgB,IAAI,SAAS,KAAK,QAAQ;AAAA,MAC5C;AAAA,IACF;AAEA,WAAO,MAAM,KAAK,gBAAgB,OAAO,CAAC;AAAA,EAC5C;AAAA,EAEQ,iBAAiB,UAGvB;AAEA,UAAM,kBAAkB,+DAA4D;AAAA;AAAA;AAAA;AAAA;AAMpF,UAAM,iBAAsC;AAAA,MAC1C;AAAA,QACE,KAAK;AAAA,QACL,OAAO;AAAA,QACP,SAAS;AAAA,MACX;AAAA,MACA;AAAA,QACE,KAAK;AAAA,QACL,OAAO;AAAA,QACP,SAAS;AAAA,MACX;AAAA,MACA;AAAA,QACE,KAAK;AAAA,QACL,OAAO;AAAA,QACP,SAAS;AAAA,MACX;AAAA,IACF;AAEA,WAAO;AAAA,MACL,YAAY;AAAA,MACZ,WAAW;AAAA,IACb;AAAA,EACF;AACF;AAnYa;;;ACRb;AAkCO,SAAS,UAAU,KAAkC;AAC1D,QAAM,iBAAiB,IAAI;AAC3B,QAAM,eAAe,mBAAmB,UAAU,mBAAmB,OAAO,mBAAmB;AAE/F,UAAQ,IAAI,yCAAkC,gBAAgB,mBAAc,YAAY;AAExF,MAAI,cAAc;AAChB,YAAQ,IAAI,8EAAuE;AAAA,EACrF;AAEA,SAAO;AAAA,IACL,OAAO;AAAA,MACL,SAAS;AAAA,IACX;AAAA,IACA,QAAQ;AAAA,MACN,QAAQ,IAAI,kBAAkB;AAAA,MAC9B,OAAO,IAAI,gBAAgB;AAAA;AAAA,MAC3B,iBAAiB;AAAA,IACnB;AAAA,IACA,UAAU;AAAA,MACR,UAAU,SAAS,IAAI,aAAa,IAAI;AAAA,MACxC,UAAU,SAAS,IAAI,aAAa,GAAG;AAAA,MACvC,SAAS,SAAS,IAAI,iBAAiB,OAAO;AAAA,MAC9C,WAAW,IAAI,cAAc;AAAA,IAC/B;AAAA,IACA,UAAU;AAAA,MACR,eAAgB,IAAI,mBAA0C;AAAA,MAC9D,qBAAqB,WAAW,IAAI,yBAAyB,KAAK;AAAA,MAClE,8BAA8B;AAAA,QAC5B,IAAI,kCAAkC;AAAA,MACxC;AAAA,IACF;AAAA,IACA,YAAY;AAAA,MACV,eAAe,WAAW,IAAI,2BAA2B,KAAK;AAAA,MAC9D,eAAe,SAAS,IAAI,kBAAkB,IAAI;AAAA,IACpD;AAAA,IACA,SAAS;AAAA,MACP,sBAAsB,SAAS,IAAI,0BAA0B,GAAG;AAAA,MAChE,gBAAgB,WAAW,IAAI,oBAAoB,KAAK;AAAA,IAC1D;AAAA,EACF;AACF;AAzCgB;;;AFzBhB;;;AGTA;;;ACAA;AAUO,IAAM,uBAAN,MAA2B;AAAA,EACxB;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,WAAmB,iBAAyB,KAAK,QAAiB,OAAO;AACnF,SAAK,YAAY;AACjB,SAAK,iBAAiB;AACtB,SAAK,QAAQ;AAAA,EACf;AAAA;AAAA;AAAA;AAAA,EAKA,SAAS,SAAwB;AAC/B,SAAK,QAAQ;AAAA,EACf;AAAA,EAEA,eAAe,UAAqC;AAClD,UAAM,UAAU,SAAS;AACzB,UAAM,YAAY,QAAQ,YAAY;AAEtC,UAAM,aAAa,KAAK,UAAU,YAAY;AAC9C,UAAM,cAAc,WAAW,QAAQ,QAAQ,EAAE;AAEjD,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,2CAA2C;AACvD,cAAQ,IAAI,sCAAsC,KAAK,SAAS;AAChE,cAAQ,IAAI,uCAAuC,UAAU;AAC7D,cAAQ,IAAI,wCAAwC,WAAW;AAC/D,cAAQ,IAAI,uCAAuC,QAAQ,MAAM;AACjE,cAAQ,IAAI,wCAAwC,QAAQ,UAAU,GAAG,GAAG,CAAC;AAAA,IAC/E;AAIA,UAAM,iBAAiB,KAAK,mBAAmB,WAAW,WAAW;AACrE,UAAM,YAAY,eAAe;AAIjC,UAAM,QAAQ,KAAK;AAAA,MACjB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,UAAM,WAAW,KAAK,gBAAgB,SAAS,YAAY,WAAW;AAEtE,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,gEAAgE,KAAK;AACjF,cAAQ,IAAI,2CAA2C,SAAS;AAChE,cAAQ,IAAI,2CAA2C,cAAc;AACrE,cAAQ,IAAI,0CAA0C,SAAS,MAAM;AACrE,cAAQ,IAAI,oCAAoC,QAAQ;AAAA,IAC1D;AAEA,WAAO;AAAA,MACL;AAAA,MACA,OAAO;AAAA;AAAA,MACP;AAAA,MACA;AAAA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOQ,qCACN,SACA,WACA,OACA,gBACQ;AACR,UAAM,eAAe,KAAK,YAAY,KAAK;AAG3C,UAAM,QAAQ,IAAI,OAAO,MAAM,mBAAmB,IAAI;AAEtD,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,yDAAyD,MAAM,MAAM;AACjF,cAAQ,IAAI,yDAAyD,YAAY;AAAA,IACnF;AAEA,QAAI,QAAQ;AACZ,QAAI;AAGJ,YAAQ,QAAQ,MAAM,KAAK,SAAS,OAAO,MAAM;AAC/C,YAAM,aAAa,MAAM;AACzB,YAAM,WAAW,aAAa,MAAM,CAAC,EAAE;AAGvC,YAAM,eAAe,eAAe;AAAA,QAAK,WACvC,cAAc,MAAM,SAAS,YAAY,MAAM;AAAA,MACjD;AAEA,UAAI,CAAC,cAAc;AACjB;AACA,YAAI,KAAK,OAAO;AACd,kBAAQ,IAAI,2DAA2D,cAAc,cAAc,MAAM,CAAC,IAAI;AAAA,QAChH;AAAA,MACF,OAAO;AACL,YAAI,KAAK,OAAO;AACd,kBAAQ,IAAI,6DAA6D,cAAc,wBAAwB;AAAA,QACjH;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,6EAA6E,KAAK;AAAA,IAChG;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,mBACN,MACA,aACuC;AAGvC,UAAM,gBAAgB,KAAK,YAAY,WAAW;AAGlD,UAAM,gBAAgB,IAAI;AAAA,MACxB,0BAA0B;AAAA,MAC1B;AAAA,IACF;AAEA,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,uCAAuC,cAAc,MAAM;AACvE,cAAQ,IAAI,wCAAwC,aAAa;AAAA,IACnE;AAEA,UAAM,SAAgD,CAAC;AACvD,QAAI;AAEJ,YAAQ,QAAQ,cAAc,KAAK,IAAI,OAAO,MAAM;AAClD,aAAO,KAAK;AAAA,QACV,OAAO,MAAM;AAAA,QACb,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE;AAAA,MAC9B,CAAC;AAAA,IACH;AAEA,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,yCAAyC,OAAO,MAAM;AAClE,cAAQ,IAAI,yCAAyC,MAAM;AAAA,IAC7D;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOQ,gBACN,MACA,OACA,aACU;AACV,UAAM,YAAY,KACf,MAAM,eAAe,EACrB,IAAI,OAAK,EAAE,KAAK,CAAC,EACjB,OAAO,OAAO;AAEjB,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,sCAAsC,UAAU,MAAM;AAAA,IACpE;AAEA,UAAM,WAAqB,CAAC;AAE5B,eAAW,YAAY,WAAW;AAChC,YAAM,QAAQ,SAAS,YAAY;AAEnC,UAAI,MAAM,SAAS,KAAK,KAAK,MAAM,SAAS,WAAW,GAAG;AACxD,YAAI,CAAC,SAAS,SAAS,QAAQ,GAAG;AAChC,mBAAS,KAAK,QAAQ;AAAA,QACxB;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,OAAO;AACd,cAAQ,IAAI,qCAAqC,SAAS,MAAM;AAAA,IAClE;AAEA,WAAO,SAAS,MAAM,GAAG,CAAC;AAAA,EAC5B;AAAA;AAAA;AAAA;AAAA,EAKQ,YAAY,KAAqB;AACvC,WAAO,IAAI,QAAQ,uBAAuB,MAAM;AAAA,EAClD;AACF;AA9Ma;;;ACVb;AAMO,IAAM,oBAAN,MAAwB;AAAA,EACZ,mBAAmB;AAAA,IAClC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAAA,EAEiB,mBAAmB;AAAA,IAClC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAAA,EAEA,iBAAiB,UAA0C;AACzD,UAAM,OAAO,SAAS,WAAW,YAAY;AAC7C,UAAM,QAAQ,KAAK,MAAM,KAAK;AAE9B,QAAI,gBAAgB;AACpB,QAAI,gBAAgB;AACpB,UAAM,gBAA0B,CAAC;AAEjC,eAAW,QAAQ,OAAO;AACxB,YAAM,YAAY,KAAK,QAAQ,aAAa,EAAE;AAE9C,UAAI,KAAK,iBAAiB,SAAS,SAAS,GAAG;AAC7C;AACA,YAAI,CAAC,cAAc,SAAS,SAAS,GAAG;AACtC,wBAAc,KAAK,SAAS;AAAA,QAC9B;AAAA,MACF;AAEA,UAAI,KAAK,iBAAiB,SAAS,SAAS,GAAG;AAC7C;AACA,YAAI,CAAC,cAAc,SAAS,SAAS,GAAG;AACtC,wBAAc,KAAK,SAAS;AAAA,QAC9B;AAAA,MACF;AAAA,IACF;AAGA,QAAI;AACJ,UAAM,aAAa,gBAAgB;AAEnC,QAAI,eAAe,GAAG;AACpB,aAAO;AAAA,IACT,WAAW,gBAAgB,gBAAgB,GAAG;AAC5C,aAAO;AAAA,IACT,WAAW,gBAAgB,gBAAgB,GAAG;AAC5C,aAAO;AAAA,IACT,OAAO;AACL,aAAO;AAAA,IACT;AAGA,UAAM,aAAa,KAAK;AAAA,MACtB,aAAa,KAAK,IAAI,MAAM,SAAS,KAAK,CAAC;AAAA,MAC3C;AAAA,IACF;AAEA,WAAO;AAAA,MACL;AAAA,MACA,YAAY,KAAK,IAAI,YAAY,GAAG;AAAA;AAAA,MACpC,UAAU,cAAc,MAAM,GAAG,EAAE;AAAA,IACrC;AAAA,EACF;AACF;AAnGa;;;AFSN,IAAM,iBAAN,MAAqB;AAAA,EAClB;AAAA,EACA;AAAA,EACA;AAAA,EAER,YACE,WACA,iBAAyB,KACzB;AACA,SAAK,YAAY;AACjB,SAAK,uBAAuB,IAAI;AAAA,MAC9B;AAAA,MACA;AAAA,IACF;AACA,SAAK,oBAAoB,IAAI,kBAAkB;AAAA,EACjD;AAAA,EAEA,iBACE,SACA,WACkB;AAClB,UAAM,WAA6B,CAAC;AAEpC,eAAW,UAAU,SAAS;AAC5B,YAAM,WAAW,UAAU,KAAK,CAAC,MAAM,EAAE,aAAa,OAAO,EAAE;AAC/D,UAAI,CAAC;AAAU;AAEf,YAAM,WAAW,KAAK,sBAAsB,QAAQ,QAAQ;AAC5D,eAAS,KAAK,QAAQ;AAAA,IACxB;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,sBACN,QACA,UACgB;AAChB,UAAM,gBAAgB,KAAK,qBAAqB,eAAe,QAAQ;AACvE,UAAM,YAAY,KAAK,kBAAkB,iBAAiB,QAAQ;AAGlE,UAAM,iBAAiB,KAAK,mBAAmB,QAAQ;AAGvD,UAAM,cAAc,cAAc,QAAQ,KAAK,cAAc,QAAQ;AACrE,UAAM,eAAe,cAAc,QAAQ,cAAc;AACzD,UAAM,UAAU,eAAe,SAAS;AAGxC,UAAM,kBAAkB,eAAe,IAAI,QAAM;AAAA,MAC/C,KAAK,EAAE;AAAA,MACP,OAAO,EAAE;AAAA,MACT,SAAS,EAAE;AAAA,IACb,EAAE;AAEF,WAAO;AAAA,MACL,UAAU,OAAO;AAAA,MACjB;AAAA,MACA,eAAe,SAAS,UAAU;AAAA,MAClC,cAAc,SAAS,UAAU,IAAI,CAAC,MAAM,EAAE,GAAG;AAAA,MACjD;AAAA,MACA;AAAA,MACA,WAAW,SAAS;AAAA;AAAA,MAEpB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,mBAAmB,UAAwC;AACjE,UAAM,aAAa,KAAK,UAAU,YAAY;AAC9C,UAAM,aAAa,WAAW,QAAQ,QAAQ,EAAE;AAChD,UAAM,iBAAkC,CAAC;AAEzC,eAAW,YAAY,SAAS,WAAW;AACzC,YAAM,eAAe,GAAG,SAAS,SAAS,MAAM,SAAS,WAAW,KAAK,YAAY;AACrF,YAAM,WAAW,SAAS,IAAI,YAAY;AAG1C,YAAM,kBAAkB,aAAa,SAAS,UAAU;AACxD,YAAM,iBAAiB,SAAS,SAAS,UAAU;AAEnD,UAAI,mBAAmB,gBAAgB;AAErC,YAAI,UAAU;AACd,YAAI,iBAAiB;AACnB,oBAAU,KAAK,gCAAgC,UAAU,UAAU;AAAA,QACrE,WAAW,gBAAgB;AAEzB,oBAAU,KAAK,qBAAqB,SAAS,YAAY,SAAS,GAAG;AAAA,QACvE;AAEA,uBAAe,KAAK;AAAA,UAClB,KAAK,SAAS;AAAA,UACd,OAAO,SAAS;AAAA,UAChB,SAAS,SAAS;AAAA,UAClB;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,qBAAqB,MAAc,KAAqB;AAG9D,UAAM,aAAa,IAAI,QAAQ,uBAAuB,MAAM;AAC5D,UAAM,kBAAkB,IAAI,OAAO,qBAAqB,iBAAiB,GAAG;AAC5E,UAAM,QAAQ,KAAK,MAAM,eAAe;AAExC,QAAI,SAAS,MAAM,CAAC,GAAG;AACrB,aAAO,MAAM,CAAC;AAAA,IAChB;AAGA,UAAM,YAAY,KAAK,MAAM,QAAQ;AACrC,eAAW,YAAY,WAAW;AAChC,UAAI,SAAS,SAAS,GAAG,GAAG;AAC1B,eAAO,SAAS,KAAK;AAAA,MACvB;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,gCACN,UACA,YACoB;AACpB,UAAM,OAAO,GAAG,SAAS,SAAS,MAAM,SAAS,WAAW;AAC5D,UAAM,YAAY,KAAK,MAAM,QAAQ;AAErC,eAAW,YAAY,WAAW;AAChC,UAAI,SAAS,YAAY,EAAE,SAAS,UAAU,GAAG;AAC/C,eAAO,SAAS,KAAK;AAAA,MACvB;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,yBACE,YACA,SACA,UACiB;AACjB,UAAM,kBAAkB,QAAQ,OAAO,CAAC,MAAM,EAAE,eAAe,UAAU;AACzE,UAAM,mBAAmB,SAAS;AAAA,MAAO,CAAC,MACxC,gBAAgB,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,QAAQ;AAAA,IACjD;AAEA,QAAI,iBAAiB,WAAW,GAAG;AACjC,aAAO;AAAA,QACL;AAAA,QACA,iBAAiB;AAAA,QACjB,cAAc;AAAA,QACd,kBAAkB;AAAA,QAClB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC;AAAA,IACF;AAEA,UAAM,eAAe,gBAAgB;AACrC,UAAM,2BAA2B,iBAAiB;AAAA,MAChD,CAAC,MAAM,EAAE,cAAc,QAAQ,KAAK,EAAE,cAAc,QAAQ;AAAA,IAC9D,EAAE;AACF,UAAM,iBAAiB,iBAAiB;AAAA,MACtC,CAAC,KAAK,MAAM,MAAM,EAAE;AAAA,MACpB;AAAA,IACF;AAEA,UAAM,kBAAkB,KAAK,yBAAyB,gBAAgB;AACtE,UAAM,eAAe,iBAAiB;AACtC,UAAM,mBAAmB,2BAA2B;AAEpD,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IACpC;AAAA,EACF;AAAA,EAEQ,yBAAyB,UAAoC;AAMnE,QAAI,QAAQ;AAEZ,eAAW,YAAY,UAAU;AAE/B,eAAS,SAAS,cAAc,QAAQ;AACxC,eAAS,SAAS,cAAc,QAAQ;AAGxC,eAAS,SAAS,gBAAgB;AAGlC,UAAI,SAAS,UAAU,SAAS,YAAY;AAC1C,iBAAS;AAAA,MACX,WAAW,SAAS,UAAU,SAAS,YAAY;AACjD,iBAAS;AAAA,MACX;AAAA,IACF;AAGA,UAAM,mBAAmB,SAAS,SAAS;AAC3C,WAAO,KAAK,IAAI,KAAK,IAAK,QAAQ,mBAAoB,KAAK,CAAC,GAAG,GAAG;AAAA,EACpE;AAAA,EAEA,2BACE,UACA,SACqB;AACrB,UAAM,gBAAgB,SAAS;AAAA,MAC7B,CAAC,KAAK,MAAM,MAAM,EAAE,cAAc,QAAQ,EAAE,cAAc;AAAA,MAC1D;AAAA,IACF;AAGA,UAAM,aAAa;AAGnB,UAAM,mBAAmB,QACtB,OAAO,CAAC,MAAM;AACb,YAAM,WAAW,SAAS,KAAK,CAAC,MAAM,EAAE,aAAa,EAAE,EAAE;AACzD,UAAI,CAAC;AAAU,eAAO;AACtB,aACE,SAAS,cAAc,UAAU,KACjC,SAAS,cAAc,UAAU;AAAA,IAErC,CAAC,EACA,IAAI,CAAC,MAAM,EAAE,QAAQ;AAGxB,UAAM,sBAAsB,QACzB,OAAO,CAAC,MAAM;AACb,YAAM,WAAW,SAAS,KAAK,CAAC,MAAM,EAAE,aAAa,EAAE,EAAE;AACzD,UAAI,CAAC;AAAU,eAAO;AACtB,aACE,SAAS,cAAc,UAAU,KACjC,SAAS,cAAc,UAAU;AAAA,IAErC,CAAC,EACA,IAAI,CAAC,MAAM,EAAE,EAAE;AAElB,WAAO;AAAA,MACL;AAAA,MACA,kBAAkB,CAAC;AAAA,MACnB;AAAA,MACA,kBAAkB,CAAC;AAAA,MACnB;AAAA,MACA,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IACpC;AAAA,EACF;AACF;AArQa;;;AGfb;AAIO,SAAS,iBAAiB,YAA4B;AAC3D,MAAI;AACF,UAAM,MAAM,IAAI,IAAI,UAAU;AAC9B,UAAM,WAAW,IAAI;AAErB,UAAM,SAAS,SAAS,QAAQ,UAAU,EAAE;AAE5C,UAAM,YAAY,OAAO,MAAM,GAAG,EAAE,CAAC;AAErC,WAAO,UAAU,OAAO,CAAC,EAAE,YAAY,IAAI,UAAU,MAAM,CAAC;AAAA,EAC9D,SAAS,GAAP;AAEA,WAAO,WAAW,QAAQ,gBAAgB,EAAE,EAAE,QAAQ,UAAU,EAAE,EAAE,MAAM,GAAG,EAAE,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC;AAAA,EAChG;AACF;AAdgB;;;ACJhB;AAOA,eAAsB,aAAa,SAAgF;AACjH,QAAM,cAAc;AAAA,IAClB,GAAG;AAAA,IACH,GAAG;AAAA,IACH,GAAG;AAAA,EACL;AAEA,aAAW,cAAc,aAAa;AACpC,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,YAAY;AAAA,QACvC,SAAS,EAAE,cAAc,mBAAmB;AAAA,QAC5C,QAAQ,YAAY,QAAQ,GAAK;AAAA,MACnC,CAAC;AAED,UAAI,SAAS,IAAI;AACf,cAAM,UAAU,MAAM,SAAS,KAAK;AACpC,cAAM,OAAO,aAAa,OAAO;AACjC,YAAI,KAAK,SAAS,GAAG;AACnB,iBAAO,EAAE,OAAO,MAAM,MAAM,QAAQ;AAAA,QACtC;AAAA,MACF;AAAA,IACF,SAAS,OAAP;AAEA;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,OAAO,OAAO,MAAM,CAAC,EAAE;AAClC;AA5BsB;AAiCf,SAAS,aAAa,KAAuB;AAClD,QAAM,OAAiB,CAAC;AAGxB,QAAM,oBAAoB,IAAI,MAAM,gDAAgD;AACpF,MAAI,mBAAmB;AACrB,UAAM,eAAe,IAAI,SAAS,qEAAqE;AACvG,eAAW,SAAS,cAAc;AAChC,WAAK,KAAK,MAAM,CAAC,EAAE,KAAK,CAAC;AAAA,IAC3B;AACA,WAAO;AAAA,EACT;AAGA,QAAM,aAAa,IAAI,SAAS,6DAA6D;AAC7F,aAAW,SAAS,YAAY;AAC9B,SAAK,KAAK,MAAM,CAAC,EAAE,KAAK,CAAC;AAAA,EAC3B;AAEA,SAAO;AACT;AApBgB;AAyBT,SAAS,qBAAqB,MAAc,SAA2B;AAC5E,QAAM,QAAkB,CAAC;AACzB,QAAM,aAAa,IAAI,IAAI,OAAO;AAGlC,QAAM,cAAc,KAAK,SAAS,sCAAsC;AAExE,aAAW,SAAS,aAAa;AAC/B,QAAI,OAAO,MAAM,CAAC,EAAE,KAAK;AAGzB,QAAI,KAAK,WAAW,GAAG,KAAK,KAAK,WAAW,aAAa,KAAK,KAAK,WAAW,SAAS,KAAK,KAAK,WAAW,MAAM,GAAG;AACnH;AAAA,IACF;AAEA,QAAI;AAEF,UAAI,KAAK,WAAW,GAAG,GAAG;AACxB,eAAO,GAAG,WAAW,aAAa,WAAW,OAAO;AAAA,MACtD,WAAW,CAAC,KAAK,WAAW,MAAM,GAAG;AACnC,eAAO,IAAI,IAAI,MAAM,OAAO,EAAE,SAAS;AAAA,MACzC;AAGA,YAAM,UAAU,IAAI,IAAI,IAAI;AAC5B,UAAI,QAAQ,aAAa,WAAW,YAAY,QAAQ,SAAS,SAAS,MAAM,WAAW,QAAQ,GAAG;AACpG,cAAM,KAAK,IAAI;AAAA,MACjB;AAAA,IACF,SAAS,OAAP;AAEA;AAAA,IACF;AAAA,EACF;AAGA,SAAO,CAAC,GAAG,IAAI,IAAI,KAAK,CAAC;AAC3B;AApCgB;AAyCT,SAAS,mBAAmB,MAAsB;AAEvD,MAAI,OAAO,KAAK,QAAQ,qCAAqC,EAAE;AAC/D,SAAO,KAAK,QAAQ,mCAAmC,EAAE;AACzD,SAAO,KAAK,QAAQ,yCAAyC,EAAE;AAG/D,SAAO,KAAK,QAAQ,YAAY,GAAG;AAGnC,SAAO,KAAK,QAAQ,QAAQ,GAAG,EAAE,KAAK;AAEtC,SAAO;AACT;AAbgB;AAkBT,SAAS,eAAe,KAAsB;AACnD,QAAM,WAAW,IAAI,YAAY;AACjC,QAAM,qBAAqB;AAAA,IACzB;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAS;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAS;AAAA,IAAQ;AAAA,IAClE;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IACxC;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IACxB;AAAA,IAAQ;AAAA,IAAS;AAAA,IAAQ;AAAA,IAAS;AAAA,IAAQ;AAAA,IAC1C;AAAA,IAAQ;AAAA,IAAO;AAAA,IAAS;AAAA,IAAQ;AAAA,EAClC;AAGA,aAAW,OAAO,oBAAoB;AACpC,QAAI,SAAS,SAAS,GAAG,GAAG;AAC1B,aAAO;AAAA,IACT;AAAA,EACF;AAGA,MAAI,SAAS,SAAS,UAAU,KAAK,SAAS,SAAS,OAAO,KAC1D,SAAS,SAAS,UAAU,MAAM,SAAS,SAAS,MAAM,KAAK,SAAS,SAAS,MAAM,KAAK,SAAS,SAAS,MAAM,IAAI;AAC1H,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAxBgB;AA6BT,SAAS,aAAa,KAAqB;AAChD,MAAI;AACF,UAAM,SAAS,IAAI,IAAI,GAAG;AAG1B,QAAI,OAAO,SAAS,SAAS,KAAK,OAAO,SAAS,SAAS,GAAG,GAAG;AAC/D,aAAO,WAAW,OAAO,SAAS,MAAM,GAAG,EAAE;AAAA,IAC/C;AAGA,WAAO,WAAW,OAAO,SAAS,YAAY;AAG9C,QAAK,OAAO,aAAa,YAAY,OAAO,SAAS,SAChD,OAAO,aAAa,WAAW,OAAO,SAAS,MAAO;AACzD,aAAO,OAAO;AAAA,IAChB;AAGA,QAAI,OAAO,QAAQ;AACjB,YAAM,SAAS,IAAI,gBAAgB,OAAO,MAAM;AAChD,YAAM,eAAe,IAAI,gBAAgB;AACzC,YAAM,KAAK,OAAO,KAAK,CAAC,EAAE,KAAK,EAAE,QAAQ,SAAO;AAC9C,qBAAa,OAAO,KAAK,OAAO,IAAI,GAAG,KAAK,EAAE;AAAA,MAChD,CAAC;AACD,aAAO,SAAS,aAAa,SAAS;AAAA,IACxC;AAGA,WAAO,OAAO;AAEd,WAAO,OAAO,SAAS;AAAA,EACzB,SAAS,OAAP;AAEA,WAAO;AAAA,EACT;AACF;AApCgB;AAyCT,SAAS,gBAAgB,MAA0B;AACxD,QAAM,OAAO,oBAAI,IAAY;AAC7B,QAAM,SAAmB,CAAC;AAE1B,aAAW,OAAO,MAAM;AACtB,UAAM,aAAa,aAAa,GAAG;AACnC,QAAI,CAAC,KAAK,IAAI,UAAU,GAAG;AACzB,WAAK,IAAI,UAAU;AACnB,aAAO,KAAK,GAAG;AAAA,IACjB;AAAA,EACF;AAEA,SAAO;AACT;AAbgB;;;APpLT,IAAM,mBAAN,MAAuB;AAAA,EAC5B,YAAoB,gBAAgC;AAAhC;AAAA,EAAiC;AAAA,EAErD,MAAM,YACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,OAAO,MAAM,QAAQ,KAAK;AAMhC,UAAI,aAAa,KAAK,YAAY,KAAK;AAEvC,UAAI,YAAY;AACd,cAAM,aAAa,IAAI,OAAO,kBAAkB,GAAG;AACnD,YAAI,CAAC,WAAW,KAAK,UAAU,GAAG;AAChC,uBAAa,aAAa;AAAA,QAC5B;AAAA,MACF;AACA,YAAM,YAAuB;AAAA,QAC3B,YAAY,cAAc;AAAA,QAC1B,SAAS,KAAK,WAAW;AAAA,QACzB,QAAQ,KAAK;AAAA,QACb,UAAU,KAAK,YAAY;AAAA,MAC7B;AAEA,YAAM,SAAS,MAAM,KAAK,eAAe,iBAAiB,WAAW,GAAG;AAExE,aAAO,IAAI,SAAS,KAAK,UAAU;AAAA,QACjC,OAAO,OAAO;AAAA,QACd,MAAM,OAAO;AAAA,QACb,cAAc,OAAO;AAAA,QACrB,SAAS,OAAO,eACZ,kBAAkB,OAAO,KAAK,gBAC9B,qBAAqB,OAAO,KAAK;AAAA,MACvC,CAAC,GAAG;AAAA,QACF,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,yBAAyB,KAAK;AAC5C,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QACpD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,YACJ,SACA,KACA,aACmB;AACnB,UAAM,OAAO,MAAM,QAAQ,KAAK;AAKhC,UAAM,EAAE,OAAO,SAAS,SAAS,IAAI;AAErC,UAAM,aAAa,MAAM,KAAK,eAAe;AAAA,MAC3C;AAAA,MACA;AAAA,MACA,YAAY;AAAA,MACZ;AAAA,IACF;AAEA,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,WAAW,CAAC,GAAG;AAAA,MAClD,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,IAChE,CAAC;AAAA,EACH;AAAA,EAEA,MAAM,qBACJ,OACA,SACA,KACA,aACmB;AACnB,UAAM,OAAO,MAAM,QAAQ,KAAK;AAIhC,UAAM,EAAE,qBAAqB,iBAAiB,IAAI;AAElD,UAAM,KAAK,eAAe;AAAA,MACxB;AAAA,MACA,uBAAuB,CAAC;AAAA,MACxB,oBAAoB,CAAC;AAAA,MACrB;AAAA,IACF;AAEA,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,KAAK,CAAC,GAAG;AAAA,MACrD,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,IAChE,CAAC;AAAA,EACH;AAAA,EAEA,MAAM,YACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,OAAO,MAAM,QAAQ,KAAK;AAQhC,YAAM,EAAE,OAAO,YAAY,WAAW,sBAAsB,UAAU,IAAI;AAE1E,UAAI,CAAC,OAAO;AACV,eAAO,IAAI;AAAA,UACT,KAAK,UAAU,EAAE,OAAO,oBAAoB,CAAC;AAAA,UAC7C;AAAA,YACE,QAAQ;AAAA,YACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,UAChE;AAAA,QACF;AAAA,MACF;AAEA,UAAI,CAAC,cAAc,WAAW,WAAW,GAAG;AAC1C,eAAO,IAAI;AAAA,UACT,KAAK,UAAU,EAAE,OAAO,0BAA0B,CAAC;AAAA,UACnD;AAAA,YACE,QAAQ;AAAA,YACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,UAChE;AAAA,QACF;AAAA,MACF;AAEA,YAAM,UAAU,MAAM,KAAK,eAAe;AAAA,QACxC;AAAA,QACA;AAAA,QACA,aAAa,EAAE,YAAY,IAAI,SAAS,IAAI,UAAU,KAAK;AAAA,QAC3D,KAAK,WAAW;AAAA,QAChB;AAAA,QACA,wBAAwB;AAAA,QACxB;AAAA,MACF;AAEA,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,QAAQ,CAAC,GAAG;AAAA,QAC/C,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,yBAAyB,KAAK;AAC5C,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,UAClD,OAAO,iBAAiB,QAAQ,MAAM,QAAQ;AAAA,QAChD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,YACJ,SACA,KACA,aACmB;AACnB,UAAM,OAAO,MAAM,QAAQ,KAAK;AAIhC,UAAM,EAAE,OAAO,SAAS,gBAAgB,IAAI;AAE5C,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,eAAe;AAAA,QACvC;AAAA,QACA,mBAAmB,CAAC;AAAA,QACpB;AAAA,MACF;AAGA,YAAM,SAAS,UAAU,GAAG;AAC5B,YAAM,KAAK,IAAI,SAAS,IAAI,MAAa;AAGzC,YAAM,UAAU,MAAM,GAAG,iBAAiB,YAAY;AACpD,eAAO,MAAM,GAAG,GACb,QAAQ,oDAAoD,EAC5D,KAAK,KAAK,EACV,MAA+B;AAAA,MACpC,GAAG,GAAG,KAAK,oBAAoB;AAE/B,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,MAAM,wBAAwB;AAAA,MAC1C;AAEA,YAAM,YAAY,iBAAiB,QAAQ,WAAW;AACtD,YAAM,iBAAiB,IAAI,eAAe,WAAW,OAAO,SAAS,mBAAmB;AAGxF,cAAQ,IAAI,yCAAyC,OAAO;AAC5D,YAAM,eAAe,KAAK,IAAI;AAC9B,YAAM,eAAe,MAAM,GAAG,iBAAiB,YAAY;AACzD,eAAO,MAAM,GAAG,GACb,QAAQ,iDAAiD,EACzD,KAAK,KAAK,EACV,IAAS;AAAA,MACd,GAAG,GAAG,KAAK,qBAAqB;AAChC,cAAQ,IAAI,qBAAqB,aAAa,SAAS,UAAU,gBAAgB,KAAK,IAAI,IAAI,gBAAgB;AAK9G,cAAQ,IAAI,0DAA0D,OAAO;AAC7E,YAAM,iBAAiB,KAAK,IAAI;AAChC,UAAI;AACJ,UAAI;AACF,yBAAiB,MAAM,GAAG,iBAAiB,YAAY;AACrD,iBAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aAQR,EACA,KAAK,KAAK,EACV,IAAS;AAAA,QACd,GAAG,GAAG,KAAK,4BAA4B;AACvC,gBAAQ,IAAI,qBAAqB,eAAe,SAAS,UAAU,kBAAkB,KAAK,IAAI,IAAI,kBAAkB;AAAA,MACtH,SAAS,OAAP;AACA,gBAAQ,MAAM,uFAAuF,MAAM,OAAO;AAElH,cAAM,gBAAgB,MAAM,GAAG,iBAAiB,YAAY;AAC1D,iBAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,aAKR,EACA,KAAK,KAAK,EACV,IAAS;AAAA,QACd,GAAG,GAAG,KAAK,mBAAmB;AAE9B,cAAM,eAAe,cAAc,WAAW,CAAC,GAAG,IAAI,CAAC,MAAW,EAAE,EAAE;AACtE,cAAM,eAAe,oBAAI,IAAmB;AAE5C,YAAI,YAAY,SAAS,GAAG;AAE1B,gBAAM,YAAY;AAClB,mBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,kBAAM,QAAQ,YAAY,MAAM,GAAG,IAAI,SAAS;AAChD,kBAAM,YAAY,MAAM,GAAG,iBAAiB,YAAY;AACtD,qBAAO,MAAM,GAAG,GACb,QAAQ,qDAAqD,MAAM,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG,IAAI,EAC9F,KAAK,GAAG,KAAK,EACb,IAAS;AAAA,YACd,GAAG,GAAG,KAAK,sBAAsB,GAAG;AAEpC,aAAC,UAAU,WAAW,CAAC,GAAG,QAAQ,CAAC,SAAc;AAC/C,kBAAI,CAAC,aAAa,IAAI,KAAK,eAAe,GAAG;AAC3C,6BAAa,IAAI,KAAK,iBAAiB,CAAC,CAAC;AAAA,cAC3C;AACA,2BAAa,IAAI,KAAK,eAAe,EAAG,KAAK,IAAI;AAAA,YACnD,CAAC;AAAA,UACH;AAAA,QACF;AAGA,yBAAiB;AAAA,UACf,UAAU,cAAc,WAAW,CAAC,GAAG,IAAI,CAAC,OAAY;AAAA,YACtD,GAAG;AAAA,YACH,iBAAiB,aAAa,IAAI,EAAE,EAAE,KAAK,CAAC,GAAG;AAAA,cAAI,OACjD,GAAG,EAAE,OAAO,EAAE,SAAS,MAAM,EAAE,WAAW;AAAA,YAC5C,EAAE,KAAK,KAAK;AAAA,UACd,EAAE;AAAA,QACJ;AACA,gBAAQ,IAAI,qBAAqB,eAAe,SAAS,UAAU,oCAAoC,KAAK,IAAI,IAAI,kBAAkB;AAAA,MACxI;AAGA,YAAM,0BAA0B,eAAe,WAAW,CAAC,GAAG,IAAI,CAAC,MAAW;AAC5E,cAAM,YAAY,EAAE,iBAChB,EAAE,eAAe,MAAM,KAAK,EAAE,IAAI,CAAC,MAAc;AAC/C,gBAAM,CAAC,KAAK,OAAO,OAAO,IAAI,EAAE,MAAM,GAAG;AACzC,iBAAO,EAAE,KAAK,OAAO,SAAS,IAAI,SAAS,WAAW,GAAG;AAAA,QAC3D,CAAC,IACD,CAAC;AACL,eAAO;AAAA,UACL,GAAG;AAAA,UACH;AAAA,QACF;AAAA,MACF,CAAC;AAGD,YAAM,eAAgB,aAAa,WAAW,CAAC;AAC/C,YAAM,WAAW,eAAe;AAAA,QAC9B;AAAA,QACA;AAAA,MACF;AAGA,YAAM,GAAG,mBAAmB,QAAQ;AAIpC,cAAQ,IAAI,sDAAsD,OAAO;AACzE,YAAM,eAAe,KAAK,IAAI;AAC9B,UAAI;AACJ,UAAI;AACF,0BAAkB,MAAM,GAAG,iBAAiB,YAAY;AACtD,iBAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aAQR,EACA,KAAK,KAAK,EACV,IAAS;AAAA,QACd,GAAG,GAAG,KAAK,0BAA0B;AACrC,gBAAQ,IAAI,6CAA6C,KAAK,IAAI,IAAI,gBAAgB;AAAA,MACxF,SAAS,OAAP;AACA,gBAAQ,MAAM,oDAAoD,MAAM,OAAO;AAC/E,0BAAkB,EAAE,SAAS,CAAC,EAAE;AAAA,MAClC;AAGA,YAAM,sBAAsB,EAAE,SAAS,CAAC,EAAE;AAE1C,cAAQ,IAAI,iDAAiD,OAAO;AACpE,YAAM,UAAU,KAAK,IAAI;AACzB,UAAI;AACJ,UAAI;AACF,qBAAa,MAAM,GAAG,iBAAiB,YAAY;AACjD,iBAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aAOR,EACA,KAAK,KAAK,EACV,IAAS;AAAA,QACd,GAAG,GAAG,KAAK,qBAAqB;AAChC,gBAAQ,IAAI,wCAAwC,KAAK,IAAI,IAAI,WAAW;AAAA,MAC9E,SAAS,OAAP;AACA,gBAAQ,MAAM,+CAA+C,MAAM,OAAO;AAC1E,qBAAa,EAAE,SAAS,CAAC,EAAE;AAAA,MAC7B;AAGA,YAAM,GAAG,qBAAqB,OAAO,aAAa;AAAA,QAChD,MAAM;AAAA,QACN,UAAU;AAAA,QACV,SAAS;AAAA,MACX,CAAC;AAGD,cAAQ,IAAI,4CAA4C,OAAO;AAC/D,UAAI;AAEF,cAAM,iBAAiB,MAAM,GAAG,GAC7B,QAAQ,oDAAoD,EAC5D,KAAK,KAAK,EACV,MAA+B;AAElC,YAAI,gBAAgB;AAClB,gBAAM,mBAAmB,iBAAiB,eAAe,WAAW;AACpE,gBAAM,oBAAoB,iBAAiB,YAAY;AACvD,gBAAM,aAAa,kBAAkB,QAAQ,QAAQ,EAAE;AAIvD,gBAAM,UAAU,MAAM,GAAG,sBAAsB,KAAK;AACpD,gBAAM,gBAAgB,QAAQ,OAAO,CAAC,KAAK,WAAW,OAAO,OAAO,YAAY,IAAI,CAAC;AACrF,gBAAM,iBAAiB,QAAQ,OAAO,CAAC,KAAK,WAAW,OAAO,OAAO,aAAa,IAAI,CAAC;AAEvF,gBAAM,cAAc,QACjB,IAAI,CAAC,YAAY;AAAA,YAChB,UAAU,OAAO;AAAA,YACjB,UAAU,OAAO,YAAY;AAAA,YAC7B,WAAW,OAAO,aAAa;AAAA,UACjC,EAAE,EACD,KAAK,CAAC,GAAG,MAAO,EAAE,WAAW,EAAE,aAAc,EAAE,WAAW,EAAE,UAAU,EACtE,MAAM,GAAG,EAAE;AAGd,cAAI,mBAAmB;AACvB,cAAI;AACF,kBAAM,gBAAgB,IAAI,IAAI,eAAe,WAAW;AACxD,+BAAmB,cAAc,SAAS,QAAQ,QAAQ,EAAE,EAAE,YAAY;AAAA,UAC5E,QAAE;AACA,+BAAmB;AAAA,UACrB;AAEA,gBAAM,eAAe,wBAAC,WAAmB;AACvC,kBAAM,cAAc,OAAO,YAAY;AACvC,mBAAO,YAAY,SAAS,gBAAgB,KAAK,YAAY,SAAS,iBAAiB;AAAA,UACzF,GAHqB;AAKrB,gBAAM,qBAAqB,MAAM,GAAG,iBAAiB,YAAY;AAC/D,mBAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAMR,EACA,KAAK,KAAK,EACV,IAAS;AAAA,UACd,GAAG,GAAG,KAAK,2BAA2B;AAEtC,gBAAM,eAAuC,CAAC;AAC9C,WAAC,mBAAmB,WAAW,CAAC,GAAG,QAAQ,CAAC,aAAa;AACvD,gBAAI;AACF,oBAAM,SAAS,IAAI,IAAI,SAAS,GAAG;AACnC,oBAAM,SAAS,OAAO,SAAS,QAAQ,QAAQ,EAAE,EAAE,YAAY;AAC/D,kBAAI,CAAC,aAAa,MAAM,GAAG;AACzB,6BAAa,MAAM,KAAK,aAAa,MAAM,KAAK,KAAK;AAAA,cACvD;AAAA,YACF,QAAE;AACA,oBAAM,WAAW,SAAS,IAAI,YAAY;AAC1C,kBAAI,CAAC,aAAa,QAAQ,GAAG;AAC3B,6BAAa,SAAS,GAAG,KAAK,aAAa,SAAS,GAAG,KAAK,KAAK;AAAA,cACnE;AAAA,YACF;AAAA,UACF,CAAC;AAED,gBAAM,UAAU;AAAA,YACd;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAEA,gBAAM,GAAG,YAAY,OAAO,OAAO;AACnC,kBAAQ,IAAI,qDAAqD,OAAO;AAAA,QAC1E;AAAA,MACF,SAAS,OAAP;AACA,gBAAQ,MAAM,wDAAwD,KAAK;AAAA,MAE7E;AAEA,aAAO,IAAI,SAAS,KAAK,UAAU;AAAA,QACjC,SAAS;AAAA,QACT;AAAA,QACA,QAAQ;AAAA,UACN,iBAAiB,gBAAgB,WAAW,CAAC;AAAA,UAC7C,qBAAqB,oBAAoB,WAAW,CAAC;AAAA,UACrD,YAAY,WAAW,WAAW,CAAC;AAAA,QACrC;AAAA,MACF,CAAC,GAAG;AAAA,QACF,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,yBAAyB,KAAK;AAC5C,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QACpD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,eACJ,SACA,KACA,aACmB;AACnB,UAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,UAAM,EAAE,IAAI,IAAI;AAEhB,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;AAAA,QACT,KAAK,UAAU,EAAE,OAAO,kBAAkB,CAAC;AAAA,QAC3C;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAEA,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,KAAK;AAAA,QAChC,SAAS,EAAE,cAAc,mBAAmB;AAAA,QAC5C,QAAQ,YAAY,QAAQ,GAAK;AAAA,MACnC,CAAC;AAED,UAAI,SAAS,IAAI;AACf,cAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,YAAI,OAAO,KAAK,QAAQ,qCAAqC,EAAE;AAC/D,eAAO,KAAK,QAAQ,mCAAmC,EAAE;AACzD,eAAO,KAAK,QAAQ,YAAY,GAAG;AACnC,eAAO,KAAK,QAAQ,QAAQ,GAAG,EAAE,KAAK;AAEtC,eAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,MAAM,KAAW,CAAC,GAAG;AAAA,UACjE,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE,CAAC;AAAA,MACH,OAAO;AACL,eAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,MAAM,OAAO,kBAAkB,CAAC,GAAG;AAAA,UAC/E,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE,CAAC;AAAA,MACH;AAAA,IACF,SAAS,OAAP;AACA,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,sBACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,OAAO,MAAM,QAAQ,KAAK;AAKhC,YAAM,EAAE,MAAM,IAAI;AAElB,YAAM,KAAK,IAAI,SAAS,IAAI,MAAa;AAGzC,YAAM,UAAU,MAAM,GAAG,iBAAiB,YAAY;AACpD,eAAO,MAAM,GAAG,GACb,QAAQ,oDAAoD,EAC5D,KAAK,KAAK,EACV,MAA+B;AAAA,MACpC,GAAG,GAAG,KAAK,sBAAsB;AAEjC,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,MAAM,wBAAwB;AAAA,MAC1C;AAEA,YAAM,YAAY,iBAAiB,QAAQ,WAAW;AACtD,YAAM,aAAa,UAAU,YAAY;AACzC,YAAM,aAAa,WAAW,QAAQ,QAAQ,EAAE;AAIhD,YAAM,UAAU,MAAM,GAAG,sBAAsB,KAAK;AACpD,YAAM,gBAAgB,QAAQ,OAAO,CAAC,KAAK,WAAW,OAAO,OAAO,YAAY,IAAI,CAAC;AAGrF,YAAM,qBAAqB,MAAM,GAAG,iBAAiB,YAAY;AAC/D,eAAO,MAAM,GAAG,GACb,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,WAUR,EACA,KAAK,KAAK,EACV,IAAmE;AAAA,MACxE,GAAG,GAAG,KAAK,wBAAwB;AAGnC,YAAM,kBAAkB,mBAAmB,WAAW,CAAC,GAAG,OAAO,CAAC,aAAa;AAC7E,cAAM,eAAe,GAAG,SAAS,SAAS,MAAM,SAAS,WAAW,KAAK,YAAY;AACrF,cAAM,WAAW,SAAS,IAAI,YAAY;AAG1C,cAAM,kBAAkB,aAAa,SAAS,UAAU;AACxD,cAAM,iBAAiB,SAAS,SAAS,UAAU;AAEnD,eAAO,mBAAmB;AAAA,MAC5B,CAAC;AAED,YAAM,iBAAiB,eAAe;AAItC,YAAM,cAAc,QACjB,IAAI,CAAC,YAAY;AAAA,QAChB,UAAU,OAAO;AAAA,QACjB,UAAU,OAAO,YAAY;AAAA,QAC7B,WAAW,OAAO,aAAa;AAAA,MACjC,EAAE,EACD,KAAK,CAAC,GAAG,MAAO,EAAE,WAAW,EAAE,aAAc,EAAE,WAAW,EAAE,UAAU,EACtE,MAAM,GAAG,EAAE;AAId,UAAI,mBAAmB;AACvB,UAAI,sBAAsB,WAAW,QAAQ,QAAQ,EAAE;AACvD,UAAI;AACF,cAAM,gBAAgB,IAAI,IAAI,QAAQ,WAAW;AACjD,2BAAmB,cAAc,SAAS,QAAQ,QAAQ,EAAE,EAAE,YAAY;AAE1E,cAAM,cAAc,iBAAiB,MAAM,GAAG;AAC9C,YAAI,YAAY,SAAS,GAAG;AAC1B,gCAAsB,YAAY,CAAC;AAAA,QACrC;AAAA,MACF,QAAE;AAEA,2BAAmB;AAAA,MACrB;AAGA,YAAM,eAAe,wBAAC,WAA4B;AAChD,cAAM,cAAc,OAAO,YAAY;AAEvC,YAAI,gBAAgB;AAAkB,iBAAO;AAE7C,YAAI,YAAY,WAAW,sBAAsB,GAAG,KAAK,gBAAgB,qBAAqB;AAC5F,iBAAO;AAAA,QACT;AAEA,cAAM,mBAAmB,YAAY,MAAM,GAAG,EAAE,CAAC;AACjD,YAAI,qBAAqB;AAAqB,iBAAO;AACrD,eAAO;AAAA,MACT,GAZqB;AAcrB,YAAM,eAAuC,CAAC;AAM9C,YAAM,eAAe,oBAAI,IAAyB;AAIlD,OAAC,mBAAmB,WAAW,CAAC,GAAG,QAAQ,CAAC,aAAa;AACvD,YAAI;AACF,gBAAM,SAAS,IAAI,IAAI,SAAS,GAAG;AAEnC,cAAI,SAAS,OAAO,SAAS,QAAQ,UAAU,EAAE,EAAE,YAAY,EAAE,QAAQ,OAAO,EAAE;AAGlF,cAAI,CAAC,aAAa,MAAM,GAAG;AAEzB,gBAAI,CAAC,aAAa,IAAI,MAAM,GAAG;AAC7B,2BAAa,IAAI,QAAQ,oBAAI,IAAY,CAAC;AAAA,YAC5C;AAGA,kBAAM,gBAAgB,OAAO,SAAS,OAAO;AAC7C,yBAAa,IAAI,MAAM,EAAG,IAAI,aAAa;AAAA,UAC7C;AAAA,QACF,QAAE;AAEA,cAAI;AAEF,kBAAM,cAAc,SAAS,IAAI,MAAM,kCAAkC;AACzE,gBAAI,eAAe,YAAY,CAAC,GAAG;AACjC,kBAAI,SAAS,YAAY,CAAC,EAAE,QAAQ,UAAU,EAAE,EAAE,YAAY,EAAE,QAAQ,OAAO,EAAE;AACjF,kBAAI,CAAC,aAAa,MAAM,GAAG;AACzB,oBAAI,CAAC,aAAa,IAAI,MAAM,GAAG;AAC7B,+BAAa,IAAI,QAAQ,oBAAI,IAAY,CAAC;AAAA,gBAC5C;AAEA,6BAAa,IAAI,MAAM,EAAG,IAAI,SAAS,GAAG;AAAA,cAC5C;AAAA,YACF;AAAA,UACF,QAAE;AAAA,UAEF;AAAA,QACF;AAAA,MACF,CAAC;AAGD,mBAAa,QAAQ,CAAC,QAAQ,WAAW;AACvC,qBAAa,MAAM,IAAI,OAAO;AAAA,MAChC,CAAC;AAGD,YAAM,UAAU;AAAA,QACd;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAGA,YAAM,GAAG,YAAY,OAAO,OAAO;AAEnC,aAAO,IAAI;AAAA,QACT,KAAK,UAAU,OAAO;AAAA,QACtB;AAAA,UACE,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF,SAAS,OAAP;AACA,cAAQ,MAAM,mCAAmC,KAAK;AACtD,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QACpD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,kBACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,OAAO,MAAM,QAAQ,KAAK;AAChC,YAAM,UAAU,KAAK,KAAK,KAAK;AAE/B,UAAI,CAAC,SAAS;AACZ,eAAO,IAAI;AAAA,UACT,KAAK,UAAU,EAAE,OAAO,kBAAkB,CAAC;AAAA,UAC3C;AAAA,YACE,QAAQ;AAAA,YACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,UAChE;AAAA,QACF;AAAA,MACF;AAGA,UAAI,gBAAgB;AACpB,UAAI,CAAC,cAAc,MAAM,eAAe,GAAG;AACzC,wBAAgB,aAAa;AAAA,MAC/B;AAEA,YAAM,WAwBF;AAAA,QACF,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,QAClC,SAAS;AAAA,QACT,WAAW;AAAA,UACT,OAAO;AAAA,QACT;AAAA,QACA,SAAS;AAAA,UACP,OAAO;AAAA,UACP,MAAM,CAAC;AAAA,QACT;AAAA,QACA,OAAO,CAAC;AAAA,MACV;AAGA,UAAI;AACF,cAAM,YAAY,IAAI,IAAI,eAAe,aAAa,EAAE,SAAS;AACjE,cAAM,iBAAiB,MAAM,MAAM,WAAW;AAAA,UAC5C,SAAS,EAAE,cAAc,mBAAmB;AAAA,UAC5C,QAAQ,YAAY,QAAQ,GAAK;AAAA,QACnC,CAAC;AACD,YAAI,eAAe,IAAI;AACrB,gBAAM,gBAAgB,MAAM,eAAe,KAAK;AAChD,mBAAS,YAAY;AAAA,YACnB,OAAO;AAAA,YACP,SAAS;AAAA,UACX;AAAA,QACF,OAAO;AACL,mBAAS,YAAY,EAAE,OAAO,MAAM;AAAA,QACtC;AAAA,MACF,SAAS,OAAP;AACA,iBAAS,YAAY,EAAE,OAAO,MAAM;AAAA,MACtC;AAGA,YAAM,gBAAgB,MAAM,aAAa,aAAa;AACtD,eAAS,UAAU;AAAA,QACjB,OAAO,cAAc;AAAA,QACrB,SAAS,cAAc;AAAA,QACvB,MAAM,cAAc;AAAA,MACtB;AAEA,UAAI,cAAwB,CAAC;AAE7B,UAAI,cAAc,SAAS,cAAc,KAAK,SAAS,GAAG;AAExD,YAAI,cAAc,KAAK,KAAK,SAAO,IAAI,SAAS,SAAS,CAAC,GAAG;AAC3D,gBAAM,UAAoB,CAAC;AAC3B,qBAAW,cAAc,cAAc,KAAK,MAAM,GAAG,EAAE,GAAG;AACxD,gBAAI;AACF,oBAAM,WAAW,MAAM,MAAM,YAAY;AAAA,gBACvC,SAAS,EAAE,cAAc,mBAAmB;AAAA,gBAC5C,QAAQ,YAAY,QAAQ,GAAK;AAAA,cACnC,CAAC;AACD,kBAAI,SAAS,IAAI;AACf,sBAAM,UAAU,MAAM,SAAS,KAAK;AACpC,sBAAM,aAAa,aAAa,OAAO;AACvC,wBAAQ,KAAK,GAAG,UAAU;AAAA,cAC5B;AAAA,YACF,SAAS,OAAP;AAEA;AAAA,YACF;AAAA,UACF;AACA,wBAAc;AAAA,QAChB,OAAO;AACL,wBAAc,cAAc;AAAA,QAC9B;AAAA,MACF,OAAO;AAEL,YAAI;AACF,gBAAM,WAAW,MAAM,MAAM,eAAe;AAAA,YAC1C,SAAS,EAAE,cAAc,mBAAmB;AAAA,YAC5C,QAAQ,YAAY,QAAQ,GAAK;AAAA,UACnC,CAAC;AACD,cAAI,SAAS,IAAI;AACf,kBAAM,OAAO,MAAM,SAAS,KAAK;AACjC,kBAAM,QAAQ,qBAAqB,MAAM,aAAa;AACtD,0BAAc,MAAM,MAAM,GAAG,EAAE;AAAA,UACjC;AAAA,QACF,SAAS,OAAP;AAAA,QAEF;AAAA,MACF;AAGA,UAAI,CAAC,YAAY,SAAS,aAAa,GAAG;AACxC,oBAAY,QAAQ,aAAa;AAAA,MACnC;AAGA,oBAAc,YAAY,OAAO,SAAO,eAAe,GAAG,CAAC;AAG3D,oBAAc,gBAAgB,WAAW;AAGzC,oBAAc,YAAY,MAAM,GAAG,EAAE;AAGrC,iBAAW,OAAO,aAAa;AAC7B,cAAM,YAAY,KAAK,IAAI;AAC3B,YAAI;AACF,gBAAM,WAAW,MAAM,MAAM,KAAK;AAAA,YAChC,SAAS,EAAE,cAAc,mBAAmB;AAAA,YAC5C,QAAQ,YAAY,QAAQ,IAAK;AAAA,UACnC,CAAC;AAED,gBAAM,YAAY,KAAK,IAAI,IAAI;AAG/B,gBAAM,cAAc,SAAS,QAAQ,IAAI,cAAc,KAAK;AAC5D,cAAI,CAAC,YAAY,SAAS,WAAW,KAAK,CAAC,YAAY,SAAS,mBAAmB,GAAG;AACpF,qBAAS,MAAM,KAAK;AAAA,cAClB;AAAA,cACA;AAAA,cACA,SAAS;AAAA,cACT,SAAS;AAAA,cACT,OAAO,4BAA4B;AAAA,YACrC,CAAC;AACD;AAAA,UACF;AAEA,cAAI,SAAS,IAAI;AACf,kBAAM,OAAO,MAAM,SAAS,KAAK;AACjC,kBAAM,cAAc,mBAAmB,IAAI;AAE3C,qBAAS,MAAM,KAAK;AAAA,cAClB;AAAA,cACA;AAAA,cACA,SAAS;AAAA,cACT,SAAS;AAAA,YACX,CAAC;AAAA,UACH,OAAO;AACL,qBAAS,MAAM,KAAK;AAAA,cAClB;AAAA,cACA;AAAA,cACA,SAAS;AAAA,cACT,SAAS;AAAA,cACT,OAAO,QAAQ,SAAS,WAAW,SAAS;AAAA,YAC9C,CAAC;AAAA,UACH;AAAA,QACF,SAAS,OAAP;AACA,gBAAM,YAAY,KAAK,IAAI,IAAI;AAC/B,mBAAS,MAAM,KAAK;AAAA,YAClB;AAAA,YACA;AAAA,YACA,SAAS;AAAA,YACT,SAAS;AAAA,YACT,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,UAClD,CAAC;AAAA,QACH;AAAA,MACF;AAGA,UAAI,eAAe,KAAK,eAAe,QAAQ;AAG/C,YAAM,SAAS,UAAU,GAAG;AAC5B,UAAI,OAAO,OAAO,QAAQ;AACxB,YAAI;AACF,gBAAM,cAAc,IAAI,YAAY,MAAM;AAC1C,gBAAM,qBAAqB;AAAA;AAAA,EAEnC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAYQ,gBAAM,SAAiB;AAAA,YACrB,IAAI;AAAA,YACJ,YAAY;AAAA,YACZ,UAAU;AAAA,YACV,UAAU;AAAA,YACV,QAAQ;AAAA,YACR,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,UACpC;AACA,gBAAM,iBAAiB,MAAM,YAAY,cAAc,MAAM;AAE7D,cAAI;AAEF,kBAAM,YAAY,eAAe,WAAW,MAAM,aAAa;AAC/D,gBAAI,WAAW;AACb,uBAAS,WAAW,KAAK,MAAM,UAAU,CAAC,CAAC;AAAA,YAC7C,OAAO;AAEL,uBAAS,WAAW;AAAA,gBAClB,SAAS,eAAe;AAAA,gBACxB,iBAAiB,eAAe,WAAW,MAAM,IAAI,EAAE,OAAO,UAAQ,KAAK,KAAK,EAAE,WAAW,GAAG,KAAK,KAAK,KAAK,EAAE,WAAW,QAAG,CAAC;AAAA,cAClI;AAAA,YACF;AAAA,UACF,SAAS,YAAP;AACA,qBAAS,WAAW;AAAA,cAClB,SAAS,eAAe;AAAA,cACxB,iBAAiB,CAAC;AAAA,YACpB;AAAA,UACF;AAGA,yBAAe,KAAK,eAAe,QAAQ;AAAA,QAC7C,SAAS,OAAP;AACA,kBAAQ,MAAM,0BAA0B,KAAK;AAAA,QAE/C;AAAA,MACF;AAEA,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,SAAS;AAAA,UACT;AAAA,UACA;AAAA,QACF,CAAC;AAAA,QACD;AAAA,UACE,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF,SAAS,OAAP;AACA,cAAQ,MAAM,+BAA+B,KAAK;AAClD,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO;AAAA,UACP,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QACpD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,eAAe,UAAuB;AAC5C,QAAI,OAAO;AAAA;AAAA;AAAA;AAAA,aAIF,SAAS;AAAA,WACX,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAOhB,QAAI,SAAS,UAAU,OAAO;AAC5B,cAAQ;AAAA;AACR,cAAQ;AAAA;AAAA,EAAe,SAAS,UAAU;AAAA;AAAA,IAC5C,OAAO;AACL,cAAQ;AAAA;AAAA,IACV;AAEA,YAAQ;AAAA;AAAA;AAAA;AAAA;AAKR,QAAI,SAAS,QAAQ,OAAO;AAC1B,cAAQ;AAAA;AACR,cAAQ,8BAA8B,SAAS,QAAQ,KAAK;AAAA;AAC5D,UAAI,SAAS,QAAQ,SAAS;AAC5B,gBAAQ;AAAA;AAAA,EAA+C,SAAS,QAAQ,QAAQ,UAAU,GAAG,GAAI;AAAA;AAAA,MACnG;AAAA,IACF,OAAO;AACL,cAAQ;AAAA;AACR,cAAQ;AAAA;AAAA,IACV;AAEA,YAAQ;AAAA;AAAA;AAAA;AAAA,mBAGO,SAAS,MAAM;AAAA,cACpB,SAAS,MAAM,OAAO,CAAC,MAAW,EAAE,OAAO,EAAE;AAAA,UACjD,SAAS,MAAM,OAAO,CAAC,MAAW,CAAC,EAAE,OAAO,EAAE;AAAA;AAAA,qBAEnC,KAAK;AAAA,MACpB,SAAS,MAAM,OAAO,CAAC,KAAa,MAAW,MAAM,EAAE,WAAW,CAAC,IAAI,SAAS,MAAM;AAAA,IACxF;AAAA;AAAA;AAIA,aAAS,MAAM,QAAQ,CAAC,MAAW,UAAkB;AACnD,cAAQ;AAAA,GAAM,QAAQ,MAAM,KAAK;AAAA;AACjC,cAAQ,cAAc,KAAK,UAAU,sBAAiB;AAAA;AACtD,cAAQ,iBAAiB,KAAK;AAAA;AAC9B,UAAI,KAAK,OAAO;AACd,gBAAQ,aAAa,KAAK;AAAA;AAAA,MAC5B;AACA,cAAQ;AAAA,KAA2C,KAAK,QAAQ,UAAU,GAAG,GAAI,EAAE,QAAQ,OAAO,GAAG,IAAI,KAAK,QAAQ,SAAS,MAAO,QAAQ;AAAA;AAAA,IAChJ,CAAC;AAED,YAAQ;AAAA;AAAA;AAER,WAAO;AAAA,EACT;AAEF;AA9jCa;;;AQdb;AAMO,IAAM,mBAAN,MAAuB;AAAA,EAC5B,cAAc;AAAA,EAAC;AAAA,EAEf,MAAM,qBACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAE,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,WAAW,MAAM,GAAG,mBAAmB,GAAG;AAGhD,YAAM,gBAAgB,MAAM,QAAQ,QAAQ,IAAI,WAAW,CAAC;AAE5D,aAAO,IAAI,SAAS,KAAK,UAAU,aAAa,GAAG;AAAA,QACjD,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,+BAA+B,KAAK;AAClD,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,sBACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,YAAY,MAAM,GAAG,gBAAgB;AAE3C,aAAO,IAAI,SAAS,KAAK,UAAU,SAAS,GAAG;AAAA,QAC7C,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,gCAAgC,KAAK;AACnD,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,yBACJ,WACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,WAAW,MAAM,GAAG,uBAAuB,WAAW,GAAG;AAE/D,aAAO,IAAI,SAAS,KAAK,UAAU,QAAQ,GAAG;AAAA,QAC5C,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,mCAAmC,KAAK;AACtD,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,0BACJ,SACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,aAAa,MAAM,GAAG,uBAAuB;AAGnD,aAAO,IAAI,SAAS,KAAK,UAAU,cAAc,CAAC,CAAC,GAAG;AAAA,QACpD,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,oCAAoC,KAAK;AAGvD,aAAO,IAAI,SAAS,KAAK,UAAU,CAAC,CAAC,GAAG;AAAA,QACtC,QAAQ;AAAA,QACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH;AAAA,EACF;AAAA,EAEA,MAAM,iCACJ,cACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,UAAU,MAAM,GAAG,2BAA2B,YAAY;AAEhE,aAAO,IAAI,SAAS,KAAK,UAAU,OAAO,GAAG;AAAA,QAC3C,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,6CAA6C,KAAK;AAChE,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,qBACJ,OACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AACzC,YAAM,GAAG,eAAe,KAAK;AAE7B,aAAO,IAAI;AAAA,QACT,KAAK,UAAU,EAAE,SAAS,MAAM,SAAS,mBAAmB,CAAC;AAAA,QAC7D;AAAA,UACE,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF,SAAS,OAAP;AACA,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,mCACJ,OACA,KACA,aACmB;AACnB,QAAI;AACF,YAAM,EAAE,UAAAA,UAAS,IAAI,MAAM;AAC3B,YAAM,KAAK,IAAIA,UAAS,IAAI,MAAa;AAGzC,YAAM,UAAU,MAAM,GAAG,sBAAsB,KAAK;AAGpD,YAAM,UAAU,MAAM,GAAG,WAAW,KAAK;AAEzC,aAAO,IAAI,SAAS,KAAK,UAAU;AAAA,QACjC;AAAA,QACA;AAAA,MACF,CAAC,GAAG;AAAA,QACF,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,OAAP;AACA,cAAQ,MAAM,+CAA+C,KAAK;AAClE,aAAO,IAAI;AAAA,QACT,KAAK,UAAU;AAAA,UACb,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAClD,CAAC;AAAA,QACD;AAAA,UACE,QAAQ;AAAA,UACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,QAChE;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AA3Ma;;;ACNb;;;ACAA;AAWO,IAAM,gBAAN,MAAoB;AAAA,EACzB,MAAM,oBAAoB,SAAqE;AAC7F,UAAM,cAAc;AAAA,MAClB,GAAG;AAAA,MACH,GAAG;AAAA,MACH,GAAG;AAAA,IACL;AAEA,eAAW,cAAc,aAAa;AACpC,UAAI;AACF,cAAM,WAAW,MAAM,MAAM,YAAY;AAAA,UACvC,SAAS;AAAA,YACP,cAAc;AAAA,UAChB;AAAA,UACA,QAAQ,YAAY,QAAQ,GAAK;AAAA;AAAA,QACnC,CAAC;AAED,YAAI,SAAS,IAAI;AACf,gBAAM,MAAM,MAAM,SAAS,KAAK;AAChC,gBAAMC,QAAO,KAAK,aAAa,GAAG;AAClC,cAAIA,MAAK,SAAS,GAAG;AACnB,mBAAO,EAAE,MAAAA,OAAM,cAAc,KAAK;AAAA,UACpC;AAAA,QACF;AAAA,MACF,SAAS,OAAP;AAEA;AAAA,MACF;AAAA,IACF;AAGA,YAAQ,IAAI,wFAA8E;AAC1F,UAAM,OAAO,MAAM,KAAK,sBAAsB,OAAO;AACrD,WAAO,EAAE,MAAM,cAAc,MAAM;AAAA,EACrC;AAAA,EAEA,MAAc,sBAAsB,SAAoC;AACtE,UAAM,OAAiB,CAAC;AACxB,UAAM,aAAa,IAAI,IAAI,OAAO;AAClC,UAAM,UAAU,oBAAI,IAAY;AAEhC,QAAI;AAEF,YAAM,WAAW,MAAM,MAAM,SAAS;AAAA,QACpC,SAAS;AAAA,UACP,cAAc;AAAA,QAChB;AAAA,QACA,QAAQ,YAAY,QAAQ,GAAK;AAAA;AAAA,MACnC,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,gBAAQ,MAAM,6BAA6B,SAAS,MAAM;AAC1D,eAAO,CAAC,OAAO;AAAA,MACjB;AAEA,YAAM,OAAO,MAAM,SAAS,KAAK;AACjC,WAAK,KAAK,OAAO;AACjB,cAAQ,IAAI,OAAO;AAGnB,YAAM,YAAY;AAClB,UAAI;AACJ,YAAM,aAAa,oBAAI,IAAY;AAEnC,cAAQ,QAAQ,UAAU,KAAK,IAAI,OAAO,MAAM;AAC9C,cAAM,OAAO,MAAM,CAAC,EAAE,KAAK;AAC3B,YAAI,CAAC,QAAQ,KAAK,WAAW,GAAG,KAAK,KAAK,WAAW,aAAa,KAAK,KAAK,WAAW,SAAS,GAAG;AACjG;AAAA,QACF;AAEA,YAAI;AAEF,gBAAM,cAAc,IAAI,IAAI,MAAM,OAAO,EAAE;AAC3C,gBAAM,SAAS,IAAI,IAAI,WAAW;AAGlC,cAAI,OAAO,aAAa,WAAW,YAAY,OAAO,aAAa,OAAO,WAAW,cAAc,WAAW,aAAa,OAAO,OAAO,YAAY;AAEnJ,kBAAM,gBAAgB,OAAO,SAAS,OAAO,YAAY,OAAO,UAAU;AAC1E,gBAAI,CAAC,QAAQ,IAAI,aAAa,KAAK,CAAC,cAAc,SAAS,MAAM,KAAK,CAAC,cAAc,SAAS,MAAM,KAAK,CAAC,cAAc,SAAS,MAAM,KAAK,CAAC,cAAc,SAAS,MAAM,KAAK,CAAC,cAAc,SAAS,MAAM,GAAG;AAC9M,yBAAW,IAAI,aAAa;AAAA,YAC9B;AAAA,UACF;AAAA,QACF,SAAS,GAAP;AAEA;AAAA,QACF;AAAA,MACF;AAGA,YAAM,YAAY,MAAM,KAAK,UAAU;AACvC,YAAM,WAAW;AACjB,WAAK,KAAK,GAAG,UAAU,MAAM,GAAG,QAAQ,CAAC;AAEzC,cAAQ,IAAI,UAAK,KAAK,0CAA0C,WAAW,8BAA8B;AAEzG,aAAO;AAAA,IACT,SAAS,OAAP;AACA,cAAQ,MAAM,4BAA4B,KAAK;AAE/C,aAAO,CAAC,OAAO;AAAA,IACjB;AAAA,EACF;AAAA,EAEQ,aAAa,KAAuB;AAC1C,UAAM,OAAiB,CAAC;AAGxB,UAAM,WAAW;AACjB,QAAI;AACJ,YAAQ,QAAQ,SAAS,KAAK,GAAG,OAAO,MAAM;AAC5C,YAAM,MAAM,MAAM,CAAC,EAAE,KAAK;AAC1B,UAAI,KAAK;AACP,aAAK,KAAK,GAAG;AAAA,MACf;AAAA,IACF;AAGA,UAAM,oBAAoB;AAC1B,YAAQ,QAAQ,kBAAkB,KAAK,GAAG,OAAO,MAAM;AACrD,YAAM,aAAa,MAAM,CAAC,EAAE,KAAK;AAEjC,cAAQ,IAAI,wBAAwB,UAAU;AAAA,IAChD;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,MAAM,oBAAoB,YAAuC;AAC/D,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,YAAY;AAAA,QACvC,SAAS;AAAA,UACP,cAAc;AAAA,QAChB;AAAA,QACA,QAAQ,YAAY,QAAQ,GAAK;AAAA;AAAA,MACnC,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,eAAO,CAAC;AAAA,MACV;AAEA,YAAM,MAAM,MAAM,SAAS,KAAK;AAChC,aAAO,KAAK,aAAa,GAAG;AAAA,IAC9B,SAAS,OAAP;AACA,cAAQ,MAAM,0BAA0B,KAAK;AAC7C,aAAO,CAAC;AAAA,IACV;AAAA,EACF;AACF;AApJa;;;ACXb;;;ACAA;AAcO,IAAM,iBAAN,MAAqB;AAAA,EAK1B,YAAoB,SAAuB;AAAvB;AAAA,EAAwB;AAAA,EAJpC,cAAc,oBAAI,IAAY;AAAA,EAC9B,QAAuB,CAAC;AAAA,EACxB;AAAA,EAIR,MAAM,MAAM,SAAyC;AACnD,SAAK,UAAU,IAAI,IAAI,OAAO;AAC9B,SAAK,YAAY,MAAM;AACvB,SAAK,QAAQ,CAAC;AAEd,UAAM,KAAK,UAAU,SAAS,CAAC;AAC/B,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,MAAc,UAAU,KAAa,OAA8B;AACjE,QAAI,QAAQ,KAAK,QAAQ;AAAU;AACnC,QAAI,KAAK,MAAM,UAAU,KAAK,QAAQ;AAAU;AAEhD,UAAM,gBAAgB,KAAK,aAAa,GAAG;AAC3C,QAAI,KAAK,YAAY,IAAI,aAAa;AAAG;AAEzC,SAAK,YAAY,IAAI,aAAa;AAElC,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,KAAK;AAAA,QAChC,SAAS;AAAA,UACP,cAAc,KAAK,QAAQ;AAAA,QAC7B;AAAA,QACA,QAAQ,YAAY,QAAQ,KAAK,QAAQ,OAAO;AAAA,MAClD,CAAC;AAED,UAAI,CAAC,SAAS;AAAI;AAElB,YAAM,OAAO,MAAM,SAAS,KAAK;AACjC,YAAM,OAAO,MAAM,KAAK,UAAU,KAAK,IAAI;AAE3C,UAAI,MAAM;AACR,aAAK,MAAM,KAAK,IAAI;AAGpB,YAAI,QAAQ,KAAK,QAAQ,UAAU;AACjC,gBAAM,QAAQ,KAAK,aAAa,MAAM,GAAG;AACzC,qBAAW,QAAQ,OAAO;AACxB,gBAAI,KAAK,MAAM,UAAU,KAAK,QAAQ;AAAU;AAChD,kBAAM,KAAK,UAAU,MAAM,QAAQ,CAAC;AAAA,UACtC;AAAA,QACF;AAAA,MACF;AAAA,IACF,SAAS,OAAP;AAEA,cAAQ,MAAM,mBAAmB,QAAQ,KAAK;AAAA,IAChD;AAAA,EACF;AAAA,EAEQ,aAAa,KAAqB;AACxC,QAAI;AACF,YAAM,SAAS,IAAI,IAAI,GAAG;AAC1B,aAAO,GAAG,OAAO,aAAa,OAAO,OAAO,OAAO,WAAW,YAAY;AAAA,IAC5E,QAAE;AACA,aAAO,IAAI,YAAY;AAAA,IACzB;AAAA,EACF;AAAA,EAEQ,aAAa,MAAc,SAA2B;AAC5D,UAAM,QAAkB,CAAC;AACzB,UAAM,OAAO,IAAI,IAAI,OAAO;AAC5B,UAAM,YAAY;AAElB,QAAI;AACJ,YAAQ,QAAQ,UAAU,KAAK,IAAI,OAAO,MAAM;AAC9C,UAAI;AACF,cAAM,OAAO,MAAM,CAAC;AACpB,cAAM,cAAc,IAAI,IAAI,MAAM,IAAI,EAAE;AAGxC,YAAI,IAAI,IAAI,WAAW,EAAE,aAAa,KAAK,UAAU;AACnD,gBAAM,KAAK,WAAW;AAAA,QACxB;AAAA,MACF,QAAE;AAAA,MAEF;AAAA,IACF;AAEA,WAAO,CAAC,GAAG,IAAI,IAAI,KAAK,CAAC;AAAA,EAC3B;AAAA,EAEA,MAAc,UAAU,KAAa,MAA2C;AAE9E,UAAM,aAAa,KAAK,MAAM,+BAA+B;AAC7D,UAAM,QAAQ,aAAa,KAAK,UAAU,WAAW,CAAC,CAAC,IAAI;AAE3D,UAAM,WAAqB,CAAC;AAC5B,UAAM,eAAe;AACrB,QAAI;AACJ,YAAQ,eAAe,aAAa,KAAK,IAAI,OAAO,MAAM;AACxD,eAAS,KAAK,KAAK,UAAU,aAAa,CAAC,CAAC,CAAC;AAAA,IAC/C;AAGA,UAAM,YAAY,KAAK,MAAM,gCAAgC;AAC7D,UAAM,cAAc,YAAY,UAAU,CAAC,IAAI;AAC/C,UAAM,cAAc,KAAK,mBAAmB,WAAW;AAGvD,UAAM,SAAS,KAAK,cAAc,WAAW;AAG7C,UAAM,WAAW,KAAK,gBAAgB,WAAW;AAEjD,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA,SAAS;AAAA,MACT;AAAA,MACA;AAAA,MACA,UAAU,KAAK,QAAQ,YAAY;AAAA,IACrC;AAAA,EACF;AAAA,EAEQ,UAAU,MAAsB;AACtC,WAAO,KACJ,QAAQ,QAAQ,GAAG,EACnB,QAAQ,WAAW,GAAG,EACtB,QAAQ,UAAU,GAAG,EACrB,QAAQ,SAAS,GAAG,EACpB,QAAQ,SAAS,GAAG,EACpB,QAAQ,WAAW,GAAG,EACtB,KAAK;AAAA,EACV;AAAA,EAEQ,mBAAmB,MAAsB;AAE/C,QAAI,OAAO,KAAK,QAAQ,qCAAqC,EAAE;AAC/D,WAAO,KAAK,QAAQ,mCAAmC,EAAE;AAEzD,WAAO,KAAK,QAAQ,YAAY,GAAG;AAEnC,WAAO,KAAK,UAAU,IAAI;AAAA,EAC5B;AAAA,EAEQ,cAAc,MAAwB;AAE5C,UAAM,QAAQ,KACX,YAAY,EACZ,MAAM,KAAK,EACX,OAAO,CAAC,MAAM,EAAE,SAAS,CAAC;AAE7B,UAAM,WAAW,oBAAI,IAAoB;AACzC,eAAW,QAAQ,OAAO;AACxB,eAAS,IAAI,OAAO,SAAS,IAAI,IAAI,KAAK,KAAK,CAAC;AAAA,IAClD;AAEA,WAAO,MAAM,KAAK,SAAS,QAAQ,CAAC,EACjC,KAAK,CAAC,GAAG,MAAM,EAAE,CAAC,IAAI,EAAE,CAAC,CAAC,EAC1B,MAAM,GAAG,EAAE,EACX,IAAI,CAAC,CAAC,IAAI,MAAM,IAAI;AAAA,EACzB;AAAA,EAEQ,gBAAgB,MAAwB;AAE9C,UAAM,cAAc;AACpB,UAAM,WAAW,oBAAI,IAAY;AACjC,QAAI;AAEJ,YAAQ,QAAQ,YAAY,KAAK,IAAI,OAAO,MAAM;AAChD,YAAM,SAAS,MAAM,CAAC;AACtB,UAAI,OAAO,SAAS,KAAK,OAAO,SAAS,IAAI;AAC3C,iBAAS,IAAI,MAAM;AAAA,MACrB;AAAA,IACF;AAEA,WAAO,MAAM,KAAK,QAAQ,EAAE,MAAM,GAAG,EAAE;AAAA,EACzC;AACF;AAhLa;;;ACdb;AAOO,IAAM,iBAAN,MAAqB;AAAA,EAC1B,YAAoB,QAAsB;AAAtB;AAAA,EAAuB;AAAA,EAE3C,MAAM,cACJ,YACA,UACyB;AACzB,UAAM,UAAU,IAAI,eAAe;AAAA,MACjC,GAAG,KAAK;AAAA,MACR;AAAA,IACF,CAAC;AAED,UAAM,QAAQ,MAAM,QAAQ,MAAM,UAAU;AAC5C,UAAM,oBAAoB,KAAK,iBAAiB,OAAO,QAAQ;AAE/D,WAAO;AAAA,MACL,YAAY,IAAI,IAAI,UAAU,EAAE;AAAA,MAChC;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,iBAAiB,OAAsB,UAA0B;AAEvE,UAAM,UAAU,MACb,IAAI,CAAC,SAAS;AACb,YAAM,QAAQ;AAAA,QACZ,KAAK;AAAA,QACL,GAAG,KAAK;AAAA,QACR,KAAK;AAAA,QACL,GAAG,KAAK;AAAA,MACV;AACA,aAAO,MAAM,KAAK,GAAG;AAAA,IACvB,CAAC,EACA,KAAK,MAAM;AAGd,WAAO,KAAK,cAAc,SAAS,QAAQ;AAAA,EAC7C;AAAA,EAEQ,cAAc,MAAc,UAA0B;AAE5D,QAAI,aAAa,KACd,QAAQ,QAAQ,GAAG,EACnB,QAAQ,WAAW,MAAM,EACzB,KAAK;AAIR,QAAI,aAAa,MAAM;AAErB,mBAAa,WAAW,QAAQ,MAAM,IAAI;AAAA,IAC5C;AAEA,WAAO;AAAA,EACT;AACF;AAzDa;;;ACPb;AAOO,IAAM,oBAAN,MAAwB;AAAA,EACZ,oBAAoB;AAAA,IACnC;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,WAAW,WAAW,YAAY,YAAY,SAAS;AAAA,MAClE,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,SAAS,QAAQ,WAAW,QAAQ,gBAAgB,KAAK;AAAA,MACpE,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,WAAW,MAAM,UAAU,eAAe,YAAY;AAAA,MACjE,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,YAAY,WAAW,YAAY,eAAe,QAAQ;AAAA,MACrE,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,YAAY,UAAU,YAAY,UAAU,QAAQ;AAAA,MAC/D,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,WAAW,YAAY,aAAa,SAAS,OAAO;AAAA,MAC/D,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,aAAa,OAAO,cAAc,cAAc,YAAY;AAAA,MACvE,aAAa;AAAA,IACf;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,UAAU,CAAC,WAAW,QAAQ,iBAAiB,SAAS,UAAU;AAAA,MAClE,aAAa;AAAA,IACf;AAAA,EACF;AAAA,EAEA,mBACE,SACA,gBAAwB,KACxB,gBAAwB,IACZ;AACZ,UAAM,aAAyB,CAAC;AAChC,UAAM,cAAc,QAAQ,kBAAkB,YAAY;AAC1D,UAAM,WAAW,QAAQ,MAAM,IAAI,CAAC,MAAM,EAAE,GAAG;AAE/C,eAAW,YAAY,KAAK,mBAAmB;AAC7C,YAAM,aAAa,KAAK;AAAA,QACtB;AAAA,QACA;AAAA,QACA,QAAQ;AAAA,MACV;AAEA,UAAI,cAAc,eAAe;AAC/B,cAAM,cAAc,KAAK,kBAAkB,UAAU,QAAQ,KAAK;AAElE,mBAAW,KAAK;AAAA,UACd,IAAI,KAAK,mBAAmB,SAAS,IAAI;AAAA,UACzC,MAAM,SAAS;AAAA,UACf,aAAa,SAAS;AAAA,UACtB;AAAA,UACA,aAAa,YAAY,IAAI,CAAC,MAAM,EAAE,GAAG;AAAA,QAC3C,CAAC;AAAA,MACH;AAAA,IACF;AAGA,WAAO,WACJ,KAAK,CAAC,GAAG,MAAM,EAAE,aAAa,EAAE,UAAU,EAC1C,MAAM,GAAG,aAAa;AAAA,EAC3B;AAAA,EAEQ,4BACN,UACA,aACA,OACQ;AACR,QAAI,iBAAiB;AACrB,QAAI,gBAAgB,SAAS,SAAS;AAEtC,eAAW,WAAW,SAAS,UAAU;AACvC,UAAI,YAAY,SAAS,QAAQ,YAAY,CAAC,GAAG;AAC/C;AAAA,MACF;AAAA,IACF;AAGA,QAAI,aAAa,iBAAiB;AAGlC,UAAM,oBAAoB,MAAM,OAAO,CAAC,SAAS;AAC/C,YAAM,WAAW,KAAK,QAAQ,YAAY;AAC1C,aAAO,SAAS,SAAS,KAAK,CAAC,OAAO,SAAS,SAAS,GAAG,YAAY,CAAC,CAAC;AAAA,IAC3E,CAAC,EAAE;AAEH,QAAI,MAAM,SAAS,GAAG;AACpB,oBAAe,oBAAoB,MAAM,SAAU;AAAA,IACrD;AAEA,WAAO,KAAK,IAAI,YAAY,CAAG;AAAA,EACjC;AAAA,EAEQ,kBACN,UACA,OACyB;AACzB,WAAO,MAAM,OAAO,CAAC,SAAS;AAC5B,YAAM,YACJ,KAAK,QACL,MACA,KAAK,SAAS,KAAK,GAAG,IACtB,MACA,KAAK,SACL,YAAY;AAEd,aAAO,SAAS,SAAS;AAAA,QAAK,CAAC,OAC7B,SAAS,SAAS,GAAG,YAAY,CAAC;AAAA,MACpC;AAAA,IACF,CAAC;AAAA,EACH;AAAA,EAEQ,mBAAmB,MAAsB;AAC/C,WAAO,OAAO,KAAK,YAAY,EAAE,QAAQ,QAAQ,GAAG,KAAK,KAAK,IAAI;AAAA,EACpE;AACF;AAnIa;;;ACPb;AAOO,IAAM,kBAAN,MAAsB;AAAA,EAC3B,gBACE,YACA,WACA,uBAA+B,GACrB;AACV,UAAM,UAAoB,CAAC;AAE3B,eAAW,YAAY,YAAY;AACjC,YAAM,kBAAkB,KAAK;AAAA,QAC3B;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,cAAQ,KAAK,GAAG,eAAe;AAAA,IACjC;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,wBACN,UACA,WACA,OACU;AACV,UAAM,UAAoB,CAAC;AAC3B,UAAM,YAAY,KAAK,mBAAmB,SAAS,MAAM,UAAU,QAAQ;AAE3E,aAAS,IAAI,GAAG,IAAI,SAAS,IAAI,UAAU,QAAQ,KAAK;AACtD,YAAM,WAAW,UAAU,CAAC;AAC5B,YAAM,WAAW,KAAK,aAAa,UAAU,WAAW,QAAQ;AAEhE,cAAQ,KAAK;AAAA,QACX,IAAI,KAAK,iBAAiB,SAAS,IAAI,CAAC;AAAA,QACxC,YAAY,SAAS;AAAA,QACrB;AAAA,QACA,UAAU,UAAU;AAAA,QACpB,SAAS,UAAU;AAAA,QACnB,QAAQ,UAAU;AAAA,QAClB,QAAQ,KAAK,gBAAgB,QAAQ;AAAA,QACrC,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,mBACN,cACA,UACU;AAEV,UAAM,YAAsD;AAAA,MAC1D,IAAI;AAAA,QACF,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,YAAY;AAAA,UACV;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,UAAU;AAAA,UACR;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,wBAAwB;AAAA,UACtB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,MACA,IAAI;AAAA,QACF,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,YAAY;AAAA,UACV;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,UAAU;AAAA,UACR;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,wBAAwB;AAAA,UACtB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,MACA,IAAI;AAAA,QACF,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,YAAY;AAAA,UACV;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,UAAU;AAAA,UACR;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,wBAAwB;AAAA,UACtB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,aAAa;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,QACA,SAAS;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,gBAAgB,UAAU,QAAQ,KAAK,UAAU;AACvD,WAAO,cAAc,YAAY,KAAK,cAAc,WAAW,CAAC;AAAA,EAClE;AAAA,EAEQ,aACN,UACA,WACA,UACQ;AAER,UAAM,cAAc,KAAK,mBAAmB,UAAU,UAAU;AAEhE,WAAO,SACJ,QAAQ,cAAc,WAAW,EACjC,QAAQ,cAAc,UAAU,OAAO,EACvC,QAAQ,aAAa,UAAU,UAAU,UAAU,OAAO,EAC1D,QAAQ,eAAe,cAAc,EACrC,QAAQ,iBAAiB,aAAa,EACtC,QAAQ,WAAW,aAAa;AAAA,EACrC;AAAA,EAEQ,mBAAmB,YAA4B;AACrD,QAAI;AACF,YAAM,SAAS,IAAI,IAAI,UAAU,EAAE;AACnC,YAAM,QAAQ,OAAO,MAAM,GAAG;AAC9B,aAAO,MAAM,CAAC,EAAE,OAAO,CAAC,EAAE,YAAY,IAAI,MAAM,CAAC,EAAE,MAAM,CAAC;AAAA,IAC5D,QAAE;AACA,aAAO;AAAA,IACT;AAAA,EACF;AAAA,EAEQ,gBAAgB,UAA6C;AAEnE,QACE,mCAAmC,KAAK,QAAQ,KAChD,uCAAuC,KAAK,QAAQ,GACpD;AACA,aAAO;AAAA,IACT;AAEA,QAAI,mBAAmB,KAAK,QAAQ,GAAG;AACrC,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAAA,EAEQ,iBAAiB,YAAoB,OAAuB;AAClE,WAAO,UAAU,cAAc,SAAS,KAAK,IAAI;AAAA,EACnD;AACF;AAtRa;;;ANMb;AAIO,IAAM,iBAAN,MAAqB;AAAA,EAClB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACR,YAAY,KAA0B;AACpC,SAAK,SAAS,UAAU,GAAG;AAC3B,SAAK,iBAAiB,IAAI,eAAe,KAAK,OAAO,QAAQ;AAC7D,SAAK,oBAAoB,IAAI,kBAAkB;AAC/C,SAAK,kBAAkB,IAAI,gBAAgB;AAC3C,SAAK,cAAc,IAAI,YAAY,KAAK,MAAM;AAC9C,SAAK,gBAAgB,IAAI,cAAc;AAAA,EACzC;AAAA;AAAA,EAGA,MAAM,iBACJ,WACA,KACmE;AACnE,QAAI;AACF,YAAM,QAAQ,OAAO,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,OAAO,GAAG,CAAC;AACzE,YAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAEhD,YAAM,GAAG,gBAAgB,OAAO,WAAW,SAAS;AAEpD,YAAM,SAAS,MAAM,KAAK,cAAc;AAAA,QACtC,UAAU;AAAA,MACZ;AAEA,YAAM,GAAG,GACN;AAAA,QACC;AAAA,MACF,EACC,KAAK,KAAK,UAAU,OAAO,IAAI,GAAG,YAAW,oBAAI,KAAK,GAAE,YAAY,GAAG,KAAK,EAC5E,IAAI;AAEP,aAAO,EAAE,OAAO,MAAM,OAAO,MAAM,cAAc,OAAO,aAAa;AAAA,IACvE,SAAS,OAAP;AACA,cAAQ,MAAM,8BAA8B,KAAK;AACjD,YAAM;AAAA,IACR;AAAA,EACF;AAAA,EAEQ,mBAAmB,MAAsB;AAE/C,QAAI,OAAO,KAAK,QAAQ,qCAAqC,EAAE;AAC/D,WAAO,KAAK,QAAQ,mCAAmC,EAAE;AAEzD,WAAO,KAAK,QAAQ,YAAY,GAAG;AAEnC,WAAO,KAAK,QAAQ,QAAQ,GAAG,EAAE,KAAK;AAAA,EACxC;AAAA;AAAA,EAGA,MAAM,wBACJ,OACA,SACA,UACA,KACqB;AACrB,UAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAGhD,UAAM,SAAS;AAAA;AAAA,8BAEW,QAAQ,UAAU,GAAG,GAAI;AAAA,YAC3C;AAAA;AAGR,QAAI;AAEF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,GAAK;AAE5D,UAAI;AACJ,UAAI;AACF,mBAAW,MAAM,MAAM,8CAA8C;AAAA,UACnE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,eAAe,UAAU,KAAK,OAAO,OAAO;AAAA,UAC9C;AAAA,UACA,MAAM,KAAK,UAAU;AAAA,YACnB,OAAO;AAAA,YACP,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,OAAO,CAAC;AAAA,YAC5C,iBAAiB,EAAE,MAAM,cAAc;AAAA,YACvC,aAAa;AAAA,YACb,YAAY;AAAA,UACd,CAAC;AAAA,UACD,QAAQ,WAAW;AAAA,QACrB,CAAC;AACD,qBAAa,SAAS;AAAA,MACxB,SAAS,YAAP;AACA,qBAAa,SAAS;AACtB,YAAI,WAAW,SAAS,cAAc;AACpC,gBAAM,IAAI,MAAM,+CAA+C;AAAA,QACjE;AACA,cAAM;AAAA,MACR;AAEA,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAM,IAAI,MAAM,qBAAqB,SAAS,UAAU,SAAS,gBAAgB,WAAW;AAAA,MAC9F;AAEA,YAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,UAAI,CAAC,KAAK,WAAW,CAAC,KAAK,QAAQ,CAAC,KAAK,CAAC,KAAK,QAAQ,CAAC,EAAE,SAAS;AACjE,cAAM,IAAI,MAAM,yCAAyC;AAAA,MAC3D;AAEA,UAAI;AACJ,UAAI;AACF,cAAMC,WAAU,KAAK,QAAQ,CAAC,EAAE,QAAQ,WAAW;AACnD,sBAAc,KAAK,MAAMA,QAAO;AAAA,MAClC,SAAS,YAAP;AACA,gBAAQ,MAAM,iCAAiC,KAAK,QAAQ,CAAC,EAAE,QAAQ,OAAO;AAC9E,cAAM,IAAI,MAAM,wCAAwC;AAAA,MAC1D;AAEA,YAAM,aAAyB,CAAC;AAGhC,UAAI,gBAAgB,CAAC;AACrB,UAAI,YAAY,cAAc,MAAM,QAAQ,YAAY,UAAU,GAAG;AACnE,wBAAgB,YAAY;AAAA,MAC9B,WAAW,MAAM,QAAQ,WAAW,GAAG;AACrC,wBAAgB;AAAA,MAClB;AAEA,eAAS,IAAI,GAAG,IAAI,cAAc,QAAQ,KAAK;AAC7C,cAAM,MAAM,cAAc,CAAC;AAC3B,mBAAW,KAAK;AAAA,UACd,IAAI,OAAO,SAAS;AAAA,UACpB,MAAM,IAAI,QAAQ,YAAY,IAAI;AAAA,UAClC,aAAa,IAAI,eAAe;AAAA,UAChC,YAAY;AAAA,UACZ,aAAa,CAAC;AAAA,QAChB,CAAC;AAAA,MACH;AAIA,UAAI,aAAa;AACjB,UAAI;AAEF,cAAM,WAAW,QAAQ,MAAM,wBAAwB;AACvD,YAAI,UAAU;AACZ,uBAAa,SAAS,CAAC;AAAA,QACzB;AAAA,MACF,SAAS,GAAP;AAAA,MAEF;AAEA,YAAM,wBAAwB,KAAK,kBAAkB;AAAA,QACnD;AAAA,UACE;AAAA,UACA,OAAO,CAAC;AAAA,UACR,mBAAmB;AAAA,UACnB;AAAA,QACF;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAGA,YAAM,gBAAgB,CAAC,GAAG,YAAY,GAAG,qBAAqB;AAC9D,YAAM,mBAAmB,MAAM;AAAA,QAC7B,IAAI,IAAI,cAAc,IAAI,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,EAAE,OAAO;AAAA,MACxD;AAEA,YAAM,GAAG,eAAe,OAAO,gBAAgB;AAE/C,aAAO;AAAA,IACT,SAAS,OAAP;AACA,cAAQ,MAAM,kCAAkC,KAAK;AACrD,cAAQ,MAAM,kBAAkB,OAAO,WAAW,OAAO,OAAO,KAAK;AAGrE,UAAI,aAAa;AACjB,UAAI;AACF,cAAM,WAAW,QAAQ,MAAM,wBAAwB;AACvD,YAAI,UAAU;AACZ,uBAAa,SAAS,CAAC;AAAA,QACzB;AAAA,MACF,SAAS,GAAP;AAAA,MAEF;AAEA,YAAM,aAAa,KAAK,kBAAkB;AAAA,QACxC;AAAA,UACE;AAAA,UACA,OAAO,CAAC;AAAA,UACR,mBAAmB;AAAA,UACnB;AAAA,QACF;AAAA,QACA;AAAA,QACA;AAAA;AAAA,MACF;AAEA,UAAI,WAAW,WAAW,GAAG;AAE3B,mBAAW;AAAA,UACT;AAAA,YACE,IAAI,OAAO;AAAA,YACX,MAAM;AAAA,YACN,aAAa;AAAA,YACb,YAAY;AAAA,YACZ,aAAa,CAAC;AAAA,UAChB;AAAA,UACA;AAAA,YACE,IAAI,OAAO;AAAA,YACX,MAAM;AAAA,YACN,aAAa;AAAA,YACb,YAAY;AAAA,YACZ,aAAa,CAAC;AAAA,UAChB;AAAA,UACA;AAAA,YACE,IAAI,OAAO;AAAA,YACX,MAAM;AAAA,YACN,aAAa;AAAA,YACb,YAAY;AAAA,YACZ,aAAa,CAAC;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAEA,YAAM,GAAG,eAAe,OAAO,UAAU;AACzC,aAAO;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA,EAIA,MAAM,qBACJ,OACA,YACA,WACA,SACA,KACA,uBAA+B,GAC/B,WACmB;AACnB,UAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAEhD,UAAM,iBAAiB,WAAW,SAAS;AAC3C,UAAM,oBAAoB;AAC1B,UAAM,uBAAuB;AAE7B,YAAQ,IAAI,cAAc,gDAAgD,WAAW,wBAAwB,mCAAmC,sCAAsC,WAAW,SAAS,6BAA6B;AAEvO,UAAM,aAAuB,CAAC;AAC9B,QAAI,iBAAiB;AAGrB,aAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,YAAM,WAAW,WAAW,CAAC;AAG7B,UAAI,IAAI,GAAG;AACT,gBAAQ,IAAI,WAAW,kEAAkE;AACzF,cAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,iBAAiB,CAAC;AAAA,MACrE;AAEA,UAAI;AACF,gBAAQ,IAAI,IAAI,IAAI,KAAK,WAAW,4CAA4C,SAAS,oBAAoB,iCAAiC;AAC9I,cAAM,kBAAkB,MAAM,KAAK;AAAA,UACjC;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,cAAM,eAAe,gBAAgB,MAAM,GAAG,oBAAoB;AAClE,YAAI,aAAa,WAAW,sBAAsB;AAChD,kBAAQ,KAAK,IAAI,IAAI,KAAK,WAAW,iCAAuB,SAAS,aAAa,gBAAgB,gCAAgC,qCAAqC,aAAa,SAAS;AAAA,QAC/L;AACA,mBAAW,KAAK,GAAG,YAAY;AAC/B;AACA,gBAAQ,IAAI,IAAI,IAAI,KAAK,WAAW,wBAAmB,aAAa,sBAAsB,SAAS,mBAAmB,uBAAuB;AAAA,MAC/I,SAAS,OAAP;AACA,gBAAQ,MAAM,IAAI,IAAI,KAAK,WAAW,wDAAmD,SAAS,SAAS,KAAK;AAEhH,cAAM,kBAAkB,KAAK,gBAAgB;AAAA,UAC3C,CAAC,QAAQ;AAAA,UACT;AAAA,UACA;AAAA,QACF;AAEA,cAAM,eAAe,gBAAgB,MAAM,GAAG,oBAAoB;AAClE,mBAAW,KAAK,GAAG,YAAY;AAC/B,gBAAQ,IAAI,IAAI,IAAI,KAAK,WAAW,uCAAkC,aAAa,sBAAsB,SAAS,mBAAmB,uBAAuB;AAAA,MAC9J;AAAA,IACF;AAEA,YAAQ,IAAI,wBAAwB,WAAW,yBAAyB,kBAAkB,WAAW,mBAAmB;AAGxH,UAAM,kBAA4B,CAAC;AACnC,UAAM,oBAAoB,oBAAI,IAAsB;AAGpD,eAAW,UAAU,YAAY;AAC/B,UAAI,CAAC,kBAAkB,IAAI,OAAO,UAAU,GAAG;AAC7C,0BAAkB,IAAI,OAAO,YAAY,CAAC,CAAC;AAAA,MAC7C;AACA,wBAAkB,IAAI,OAAO,UAAU,EAAG,KAAK,MAAM;AAAA,IACvD;AAGA,YAAQ,IAAI,4CAA4C,WAAW,sBAAsB;AACzF,eAAW,CAAC,YAAY,OAAO,KAAK,kBAAkB,QAAQ,GAAG;AAC/D,YAAM,WAAW,WAAW,KAAK,OAAK,EAAE,OAAO,UAAU;AACzD,cAAQ,IAAI,mCAAmC,UAAU,QAAQ,eAAe,QAAQ,0BAA0B;AAAA,IACpH;AAGA,eAAW,CAAC,YAAY,OAAO,KAAK,kBAAkB,QAAQ,GAAG;AAE/D,YAAM,gBAAgB,QAAQ,MAAM,GAAG,oBAAoB;AAC3D,UAAI,cAAc,WAAW,sBAAsB;AACjD,gBAAQ,KAAK,gDAAsC,oBAAoB,cAAc,iCAAiC,gCAAgC;AAAA,MACxJ;AACA,sBAAgB,KAAK,GAAG,aAAa;AACrC,YAAM,WAAW,WAAW,KAAK,OAAK,EAAE,OAAO,UAAU;AACzD,cAAQ,IAAI,mCAAmC,UAAU,QAAQ,uBAAuB,cAAc,8BAA8B,uBAAuB;AAAA,IAC7J;AAEA,UAAM,gBAAgB,WAAW,SAAS;AAC1C,QAAI,gBAAgB,WAAW,eAAe;AAC5C,cAAQ,KAAK,gDAAsC,0BAA0B,6BAA0B,WAAW,+BAA+B,gBAAgB,QAAQ;AAAA,IAC3K,OAAO;AACL,cAAQ,IAAI,6CAAwC,gBAAgB,mBAAmB,sCAAsC,WAAW,uBAAuB,sBAAsB;AAAA,IACvL;AAMA,UAAM,GAAG,iBAAiB,YAAY;AACpC,YAAM,GAAG,GACN;AAAA,QACC;AAAA,MACF,EACC;AAAA,QACC,gBAAgB;AAAA,QAChB;AAAA,SACA,oBAAI,KAAK,GAAE,YAAY;AAAA,QACvB;AAAA,MACF,EACC,IAAI;AAAA,IACT,GAAG,GAAG,KAAK,wBAAwB;AAEnC,WAAO;AAAA,EACT;AAAA,EAEA,MAAc,kCACZ,YACA,WACA,SACA,sBACA,OACmB;AAEnB,QAAI,KAAK,OAAO,OAAO,SAAS;AAC9B,cAAQ,IAAI,6DAAsD;AAClE,YAAM,aAAuB,CAAC;AAC9B,iBAAW,YAAY,YAAY;AACjC,cAAM,eAAe,MAAM,KAAK,gBAAgB,UAAU,WAAW,sBAAsB,KAAK;AAChG,mBAAW,KAAK,GAAG,YAAY;AAAA,MACjC;AACA,aAAO;AAAA,IACT;AAEA,UAAM,aAAa,UAAU,UAAU,UAAU;AACjD,UAAM,iBAAiB,WAAW,SAAS;AAG3C,UAAM,iBAAiB,WAAW,IAAI,OAAK,KAAK,EAAE,SAAS,EAAE,aAAa,EAAE,KAAK,IAAI;AAErF,UAAM,SAAS,oGAA8F,6DAA6D,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uDAMpI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sDAMD,UAAU;AAAA,EAC3D,UAAU,aAAa,OAAO;AAAA,gBAChB;AAAA,iCACiB;AAAA,iDACa;AAAA,oCACV;AAAA,IAChC,UAAU,aAAa,OAAO;AAAA,eACnB;AAAA,+BACgB;AAAA,8CACe;AAAA,oCACV;AAAA,IAChC;AAAA,gBACY;AAAA,4CACyB;AAAA,4DACgB;AAAA;AAAA;AAAA,0CAGlB;AAAA,EACrC;AAAA;AAAA;AAAA,UAGQ,UAAU;AAAA,YACR,UAAU,UAAU,UAAU;AAAA,aAC7B,UAAU;AAAA,8BACO,QAAQ,UAAU,GAAG,GAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAO1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAOsB;AAAA;AAAA;AAAA;AAAA,mDAIA;AAAA;AAAA;AAAA;AAAA;AAM/C,QAAI;AACF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,GAAK;AAE5D,UAAI;AACJ,UAAI;AACF,mBAAW,MAAM,MAAM,8CAA8C;AAAA,UACnE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,eAAe,UAAU,KAAK,OAAO,OAAO;AAAA,UAC9C;AAAA,UACA,MAAM,KAAK,UAAU;AAAA,YACnB,OAAO;AAAA,YACP,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,OAAO,CAAC;AAAA,YAC5C,iBAAiB,EAAE,MAAM,cAAc;AAAA,YACvC,aAAa;AAAA,YACb,YAAY;AAAA;AAAA,UACd,CAAC;AAAA,UACD,QAAQ,WAAW;AAAA,QACrB,CAAC;AACD,qBAAa,SAAS;AAAA,MACxB,SAAS,YAAP;AACA,qBAAa,SAAS;AACtB,YAAI,WAAW,SAAS,cAAc;AACpC,gBAAM,IAAI,MAAM,+CAA+C;AAAA,QACjE;AACA,cAAM;AAAA,MACR;AAEA,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAM,IAAI,MAAM,qBAAqB,SAAS,UAAU,SAAS,gBAAgB,WAAW;AAAA,MAC9F;AAEA,YAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,UAAI,CAAC,KAAK,WAAW,CAAC,KAAK,QAAQ,CAAC,KAAK,CAAC,KAAK,QAAQ,CAAC,EAAE,SAAS;AACjE,cAAM,IAAI,MAAM,yCAAyC;AAAA,MAC3D;AAEA,UAAI;AACJ,UAAI;AACF,cAAM,kBAAkB,KAAK,QAAQ,CAAC,EAAE,QAAQ,WAAW;AAC3D,sBAAc,KAAK,MAAM,eAAe;AAAA,MAC1C,SAAS,YAAP;AACA,gBAAQ,MAAM,iCAAiC,KAAK,QAAQ,CAAC,EAAE,QAAQ,OAAO;AAC9E,cAAM,IAAI,MAAM,wCAAwC;AAAA,MAC1D;AAEA,YAAM,iBAAiB,YAAY,cAAc,CAAC;AAClD,YAAM,aAAuB,CAAC;AAC9B,YAAM,OAAM,oBAAI,KAAK,GAAE,YAAY;AAEnC,iBAAW,gBAAgB,gBAAgB;AACzC,cAAM,eAAe,aAAa;AAClC,cAAM,YAAY,aAAa,aAAa,CAAC;AAG7C,YAAI,WAAW,WAAW,KAAK,OAAK,EAAE,SAAS,YAAY;AAG3D,YAAI,CAAC,UAAU;AACb,qBAAW,WAAW;AAAA,YAAK,OACzB,EAAE,KAAK,YAAY,MAAM,aAAa,YAAY,KAClD,aAAa,YAAY,EAAE,SAAS,EAAE,KAAK,YAAY,CAAC,KACxD,EAAE,KAAK,YAAY,EAAE,SAAS,aAAa,YAAY,CAAC;AAAA,UAC1D;AAAA,QACF;AAEA,YAAI,CAAC,UAAU;AACb,kBAAQ,KAAK,aAAa,uEAAuE,WAAW,IAAI,OAAK,EAAE,IAAI,EAAE,KAAK,IAAI,GAAG;AAEzI,gBAAM,QAAQ,eAAe,QAAQ,YAAY;AACjD,cAAI,QAAQ,WAAW,QAAQ;AAC7B,uBAAW,WAAW,KAAK;AAC3B,oBAAQ,IAAI,4BAA4B,SAAS,MAAM;AAAA,UACzD,OAAO;AACL;AAAA,UACF;AAAA,QACF;AAGA,iBAAS,IAAI,GAAG,IAAI,UAAU,UAAU,WAAW,OAAO,OAAK,EAAE,eAAe,SAAS,EAAE,EAAE,SAAS,sBAAsB,KAAK;AAC/H,gBAAM,WAAW,UAAU,CAAC;AAC5B,cAAI,YAAY,OAAO,aAAa,YAAY,SAAS,KAAK,GAAG;AAC/D,uBAAW,KAAK;AAAA,cACd,IAAI,UAAU,SAAS,SAAS,MAAM,WAAW,OAAO,OAAK,EAAE,eAAe,SAAS,EAAE,EAAE,UAAU,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC;AAAA,cACzJ,YAAY,SAAS;AAAA,cACrB,UAAU,SAAS,KAAK;AAAA,cACxB,UAAU,UAAU;AAAA,cACpB,SAAS,UAAU;AAAA,cACnB,QAAQ,UAAU;AAAA,cAClB,QAAQ;AAAA,cACR,WAAW;AAAA,YACb,CAAC;AAAA,UACH;AAAA,QACF;AAGA,cAAM,sBAAsB,WAAW,OAAO,OAAK,EAAE,eAAe,SAAS,EAAE,EAAE;AACjF,YAAI,sBAAsB,sBAAsB;AAC9C,kBAAQ,KAAK,YAAY,SAAS,kBAAkB,+DAA+D,uBAAuB,qBAAqB;AAC/J,gBAAM,kBAAkB,KAAK,gBAAgB;AAAA,YAC3C,CAAC,QAAQ;AAAA,YACT;AAAA,YACA,uBAAuB;AAAA,UACzB;AACA,qBAAW,KAAK,GAAG,gBAAgB,MAAM,GAAG,uBAAuB,mBAAmB,CAAC;AAAA,QACzF;AAAA,MACF;AAGA,UAAI,WAAW,SAAS,gBAAgB;AACtC,gBAAQ,KAAK,aAAa,WAAW,4BAA4B,sDAAsD;AACvH,cAAM,gBAAgB,WAAW;AACjC,cAAM,kBAAkB,KAAK,gBAAgB;AAAA,UAC3C;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,cAAM,SAAS,iBAAiB;AAChC,mBAAW,KAAK,GAAG,gBAAgB,MAAM,GAAG,MAAM,CAAC;AAAA,MACrD;AAEA,aAAO,WAAW,MAAM,GAAG,cAAc;AAAA,IAC3C,SAAS,OAAP;AACA,cAAQ,MAAM,+CAA+C,KAAK;AAClE,YAAM;AAAA,IACR;AAAA,EACF;AAAA,EAEA,MAAc,+BACZ,UACA,WACA,SACA,OACA,OACmB;AAEnB,QAAI,KAAK,OAAO,OAAO,SAAS;AAC9B,cAAQ,IAAI,6DAAsD;AAClE,aAAO,KAAK,gBAAgB,UAAU,WAAW,OAAO,KAAK;AAAA,IAC/D;AAEA,UAAM,aAAa,UAAU,UAAU,UAAU;AACjD,UAAM,SAAS,+DAA4D,8CAA8C,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uDAMnF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sDAMD,UAAU;AAAA,EAC3D,UAAU,aAAa,OAAO;AAAA,gBAChB;AAAA,iCACiB;AAAA,iDACa;AAAA,oCACV;AAAA,0DACgB;AAAA,qCACf;AAAA,wDACgB;AAAA,IACjD,UAAU,aAAa,OAAO;AAAA,eACnB;AAAA,+BACgB;AAAA,8CACe;AAAA,oCACV;AAAA,8CACU;AAAA,uCACP;AAAA,iDACU;AAAA,IAC7C;AAAA,gBACY;AAAA,4CACyB;AAAA,4DACgB;AAAA,iDACd;AAAA,gEACkB;AAAA;AAAA;AAAA;AAAA,eAI9C,SAAS,UAAU,SAAS;AAAA,UACjC,UAAU;AAAA,YACR,UAAU,UAAU,UAAU;AAAA,aAC7B,UAAU;AAAA,8BACO,QAAQ,UAAU,GAAG,GAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2EAQiB;AAAA,6BAC3C,UAAU,0BAA0B,UAAU;AAAA;AAGrE,QAAI;AACF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,IAAK;AAE9D,UAAI;AACJ,UAAI;AACF,mBAAW,MAAM,MAAM,8CAA8C;AAAA,UACnE,QAAQ;AAAA,UACR,SAAS;AAAA,YACP,gBAAgB;AAAA,YAChB,eAAe,UAAU,KAAK,OAAO,OAAO;AAAA,UAC9C;AAAA,UACA,MAAM,KAAK,UAAU;AAAA,YACnB,OAAO;AAAA,YACP,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,OAAO,CAAC;AAAA,YAC5C,iBAAiB,EAAE,MAAM,cAAc;AAAA,YACvC,aAAa;AAAA,YACb,YAAY;AAAA,UACd,CAAC;AAAA,UACD,QAAQ,WAAW;AAAA,QACrB,CAAC;AACD,qBAAa,SAAS;AAAA,MACxB,SAAS,YAAP;AACA,qBAAa,SAAS;AACtB,YAAI,WAAW,SAAS,cAAc;AACpC,gBAAM,IAAI,MAAM,+CAA+C;AAAA,QACjE;AACA,cAAM;AAAA,MACR;AAEA,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAM,IAAI,MAAM,qBAAqB,SAAS,UAAU,SAAS,gBAAgB,WAAW;AAAA,MAC9F;AAEA,YAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,UAAI,CAAC,KAAK,WAAW,CAAC,KAAK,QAAQ,CAAC,KAAK,CAAC,KAAK,QAAQ,CAAC,EAAE,SAAS;AACjE,cAAM,IAAI,MAAM,yCAAyC;AAAA,MAC3D;AAEA,UAAI;AACJ,UAAI;AACF,cAAM,kBAAkB,KAAK,QAAQ,CAAC,EAAE,QAAQ,WAAW;AAC3D,sBAAc,KAAK,MAAM,eAAe;AAAA,MAC1C,SAAS,YAAP;AACA,gBAAQ,MAAM,iCAAiC,KAAK,QAAQ,CAAC,EAAE,QAAQ,OAAO;AAC9E,cAAM,IAAI,MAAM,wCAAwC;AAAA,MAC1D;AAEA,YAAM,YAAY,YAAY,aAAa,CAAC;AAC5C,YAAM,UAAoB,CAAC;AAG3B,eAAS,IAAI,GAAG,IAAI,UAAU,UAAU,QAAQ,SAAS,OAAO,KAAK;AACnE,cAAM,WAAW,UAAU,CAAC;AAC5B,YAAI,YAAY,OAAO,aAAa,YAAY,SAAS,KAAK,EAAE,SAAS,GAAG;AAC1E,kBAAQ,KAAK;AAAA,YACX,IAAI,UAAU,SAAS,SAAS,MAAM,QAAQ,UAAU,KAAK,IAAI,KAAK,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC;AAAA,YAC5G,YAAY,SAAS;AAAA,YACrB,UAAU,SAAS,KAAK;AAAA,YACxB,UAAU,UAAU;AAAA,YACpB,SAAS,UAAU;AAAA,YACnB,QAAQ,UAAU;AAAA,YAClB,QAAQ;AAAA,YACR,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,UACpC,CAAC;AAAA,QACH;AAAA,MACF;AAGA,UAAI,QAAQ,SAAS,OAAO;AAC1B,gBAAQ,KAAK,YAAY,QAAQ,iCAAiC,SAAS,sCAAsC,QAAQ,QAAQ,QAAQ;AACzI,cAAM,kBAAkB,KAAK,gBAAgB,gBAAgB,CAAC,QAAQ,GAAG,WAAW,QAAQ,QAAQ,MAAM;AAC1G,cAAM,SAAS,QAAQ,QAAQ;AAC/B,gBAAQ,KAAK,GAAG,gBAAgB,MAAM,GAAG,MAAM,CAAC;AAAA,MAClD;AAGA,YAAM,eAAe,QAAQ,MAAM,GAAG,KAAK;AAC3C,cAAQ,IAAI,6CAA6C,SAAS,mBAAmB,QAAQ,qCAAqC,aAAa,sBAAsB,QAAQ;AAC7K,aAAO;AAAA,IACT,SAAS,OAAP;AACA,cAAQ,MAAM,yCAAyC,SAAS,SAAS,KAAK;AAC9E,cAAQ,MAAM,kBAAkB,OAAO,WAAW,OAAO,OAAO,KAAK;AAErE,YAAM,kBAAkB,KAAK,gBAAgB,gBAAgB,CAAC,QAAQ,GAAG,WAAW,KAAK;AACzF,aAAO;AAAA,IACT;AAAA,EACF;AAAA,EAEQ,gBACN,UACA,WACA,OACA,OACU;AACV,UAAM,aAAa,UAAU,UAAU,UAAU;AACjD,UAAM,UAAoB,CAAC;AAG3B,UAAM,oBAA8C;AAAA,MAClD,IAAI;AAAA,QACF,cAAc,qBAAkB,SAAS;AAAA,QACzC,cAAc,SAAS,WAAW;AAAA,QAClC,WAAW,SAAS,8BAA2B;AAAA,QAC/C,cAAc,SAAS,WAAW;AAAA,QAClC,gBAAgB,SAAS,WAAW;AAAA,QACpC,UAAU,SAAS,mBAAmB;AAAA,QACtC,qCAAkC,SAAS,WAAW;AAAA,QACtD,gBAAgB,SAAS,WAAW;AAAA,MACtC;AAAA,MACA,IAAI;AAAA,QACF,aAAa,kBAAkB,SAAS;AAAA,QACxC,cAAc,SAAS,WAAW;AAAA,QAClC,aAAa,SAAS,0BAA0B;AAAA,QAChD,aAAa,SAAS,gBAAgB;AAAA,QACtC,aAAa,SAAS,WAAW;AAAA,QACjC,QAAQ,SAAS,yBAAyB;AAAA,QAC1C,gCAAgC,SAAS,WAAW;AAAA,QACpD,oBAAoB,SAAS,WAAW;AAAA,MAC1C;AAAA,MACA,IAAI;AAAA,QACF,cAAc,mBAAmB,SAAS;AAAA,QAC1C,aAAa,SAAS,WAAW;AAAA,QACjC,YAAY,SAAS,4BAA4B;AAAA,QACjD,oBAAiB,SAAS,WAAW;AAAA,QACrC,YAAY,SAAS,WAAW;AAAA,QAChC,SAAS,SAAS,4BAA4B;AAAA,QAC9C,wCAAwC,SAAS,WAAW;AAAA,QAC5D,yBAAsB,SAAS,WAAW;AAAA,MAC5C;AAAA,IACF;AAEA,UAAM,YAAY,kBAAkB,UAAU,QAAQ,KAAK,kBAAkB;AAE7E,aAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,YAAM,WAAW,UAAU,IAAI,UAAU,MAAM;AAC/C,cAAQ,KAAK;AAAA,QACX,IAAI,UAAU,SAAS,SAAS,MAAM;AAAA,QACtC,YAAY,SAAS;AAAA,QACrB,UAAU;AAAA,QACV,UAAU,UAAU;AAAA,QACpB,SAAS,UAAU;AAAA,QACnB,QAAQ,UAAU;AAAA,QAClB,QAAQ;AAAA,QACR,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,MACpC,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,EACT;AAAA;AAAA,EAGA,MAAM,oBACJ,OACA,iBACA,KACmB;AACnB,UAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAEhD,UAAM,GAAG,YAAY,OAAO,eAAe;AAE3C,UAAM,GAAG,GACN;AAAA,MACC;AAAA,IACF,EACC;AAAA,MACC,gBAAgB;AAAA,MAChB;AAAA,OACA,oBAAI,KAAK,GAAE,YAAY;AAAA,MACvB;AAAA,IACF,EACC,IAAI;AAEP,WAAO;AAAA,EACT;AAAA;AAAA;AAAA,EAIA,MAAM,oBACJ,OACA,SACA,KAC+B;AAC/B,UAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAEhD,UAAM,GAAG,GACN,QAAQ,gEAAgE,EACxE,KAAK,cAAa,oBAAI,KAAK,GAAE,YAAY,GAAG,KAAK,EACjD,IAAI;AAEP,UAAM,YAAY,MAAM,KAAK,YAAY,eAAe,OAAO;AAG/D,UAAM,uBAAiC,CAAC;AACxC,UAAM,iBAAwB,CAAC;AAE/B,aAAS,IAAI,GAAG,IAAI,UAAU,QAAQ,KAAK;AACzC,YAAM,WAAW,UAAU,CAAC;AAE5B,UAAI,YAAY,SAAS,cAAc,SAAS,WAAW,KAAK,EAAE,SAAS,GAAG;AAE5E,cAAM,SAAS,QAAQ,KAAK,OAAK,EAAE,OAAO,SAAS,QAAQ;AAC3D,YAAI,QAAQ;AACV,+BAAqB,KAAK,MAAM;AAChC,yBAAe,KAAK,QAAQ;AAAA,QAC9B;AAAA,MACF;AAAA,IACF;AAGA,QAAI,qBAAqB,SAAS,GAAG;AACnC,YAAM,GAAG,YAAY,OAAO,oBAAoB;AAChD,cAAQ,IAAI,SAAS,qBAAqB,oDAAoD,QAAQ,eAAe;AAAA,IACvH,OAAO;AACL,cAAQ,KAAK,4CAA4C,QAAQ,4BAA4B,UAAU,4BAA4B;AAAA,IACrI;AAGA,UAAM,GAAG,iBAAiB,SAAS;AAEnC,UAAM,GAAG,GACN,QAAQ,gEAAgE,EACxE,KAAK,cAAa,oBAAI,KAAK,GAAE,YAAY,GAAG,KAAK,EACjD,IAAI;AAEP,WAAO,EAAE,UAAU,eAAe,OAAO;AAAA,EAC3C;AAAA;AAAA,EAGA,MAAM,uBACJ,OACA,aACA,kBACA,KACe;AACf,UAAM,KAAK,IAAI,SAAS,IAAI,MAAoB;AAGhD,QAAI,iBAAiB,SAAS,GAAG;AAC/B,YAAM,GAAG,eAAe,OAAO,gBAAgB;AAAA,IACjD;AAEA,UAAM,GAAG,GACN;AAAA,MACC;AAAA,IACF,EACC;AAAA,MACC,KAAK,UAAU,WAAW;AAAA,MAC1B,KAAK,UAAU,gBAAgB;AAAA,OAC/B,oBAAI,KAAK,GAAE,YAAY;AAAA,MACvB;AAAA,IACF,EACC,IAAI;AAAA,EACT;AAAA;AAGF;AAt4Ba;;;AdLN,IAAM,SAAN,MAAa;AAAA,EAIlB,YACU,KACR;AADQ;AAER,UAAM,iBAAiB,IAAI,eAAe,GAAG;AAC7C,SAAK,mBAAmB,IAAI,iBAAiB,cAAc;AAC3D,SAAK,mBAAmB,IAAI,iBAAiB;AAAA,EAC/C;AAAA,EATQ;AAAA,EACA;AAAA,EAUR,MAAM,MAAM,SAAkB,KAA2C;AACvE,UAAM,cAAc,eAAe;AAGnC,UAAM,eAAe,WAAW,OAAO;AACvC,QAAI;AAAc,aAAO;AAEzB,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,UAAM,OAAO,IAAI;AACjB,UAAM,SAAS,QAAQ;AAEvB,QAAI;AACF,YAAM,QAAQ,WAAW,MAAM,MAAM;AAErC,UAAI,CAAC,OAAO;AACV,eAAO,eAAe,WAAW;AAAA,MACnC;AAEA,YAAM,EAAE,OAAO,OAAO,IAAI;AAC1B,YAAM,CAAC,aAAa,UAAU,IAAI,MAAM,QAAQ,MAAM,GAAG;AAGzD,cAAQ,aAAa;AAAA,QACnB,KAAK;AACH,iBAAO,MAAM,KAAK,cAAc,YAAY,SAAS,QAAQ,WAAW;AAAA,QAC1E,KAAK;AACH,iBAAO,MAAM,KAAK,cAAc,YAAY,SAAS,QAAQ,WAAW;AAAA,QAC1E,KAAK;AACH,iBAAO,IAAI;AAAA,YACT,KAAK,UAAU,EAAE,QAAQ,MAAM,YAAW,oBAAI,KAAK,GAAE,YAAY,EAAE,CAAC;AAAA,YACpE;AAAA,cACE,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;AAAA,YAChE;AAAA,UACF;AAAA,QACF;AACE,iBAAO,eAAe,WAAW;AAAA,MACrC;AAAA,IACF,SAAS,OAAP;AACA,aAAO,YAAY,OAAO,WAAW;AAAA,IACvC;AAAA,EACF;AAAA,EAEA,MAAc,cACZ,QACA,SACA,QACA,aACmB;AACnB,YAAQ,QAAQ;AAAA,MACd,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,YAAY,SAAS,KAAK,KAAK,WAAW;AAAA,MAC/E,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,YAAY,SAAS,KAAK,KAAK,WAAW;AAAA,MAC/E,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB;AAAA,UACjC,OAAO,UAAU;AAAA,UACjB;AAAA,UACA,KAAK;AAAA,UACL;AAAA,QACF;AAAA,MACF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,YAAY,SAAS,KAAK,KAAK,WAAW;AAAA,MAC/E,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,YAAY,SAAS,KAAK,KAAK,WAAW;AAAA,MAC/E,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,eAAe,SAAS,KAAK,KAAK,WAAW;AAAA,MAClF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,sBAAsB,SAAS,KAAK,KAAK,WAAW;AAAA,MACzF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,kBAAkB,SAAS,KAAK,KAAK,WAAW;AAAA,MACrF;AACE,eAAO,eAAe,WAAW;AAAA,IACrC;AAAA,EACF;AAAA,EAEA,MAAc,cACZ,QACA,SACA,QACA,aACmB;AACnB,UAAM,QAAQ,OAAO,UAAU;AAC/B,UAAM,YAAY,OAAO,UAAU;AACnC,UAAM,eAAe,OAAO,UAAU;AAEtC,YAAQ,QAAQ;AAAA,MACd,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,qBAAqB,SAAS,KAAK,KAAK,WAAW;AAAA,MACxF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,mCAAmC,OAAO,KAAK,KAAK,WAAW;AAAA,MACpG,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,qBAAqB,OAAO,KAAK,KAAK,WAAW;AAAA,MACtF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,sBAAsB,SAAS,KAAK,KAAK,WAAW;AAAA,MACzF,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,yBAAyB,WAAW,KAAK,KAAK,WAAW;AAAA,MAC9F,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,0BAA0B,SAAS,KAAK,KAAK,WAAW;AAAA,MAC7F,KAAK;AACH,eAAO,MAAM,KAAK,iBAAiB,iCAAiC,cAAc,KAAK,KAAK,WAAW;AAAA,MACzG;AACE,eAAO,eAAe,WAAW;AAAA,IACrC;AAAA,EACF;AACF;AApHa;;;ADEb,IAAO,cAAQ;AAAA,EACb,MAAM,MAAM,SAAkB,KAAU,KAA0C;AAChF,UAAM,SAAS,IAAI,OAAO,GAAG;AAE7B,WAAO,MAAM,OAAO,MAAM,SAAS,GAAG;AAAA,EACxC;AACF;;;AsBpBA;AAEA,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAP;AACD,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;AvBZJ,IAAM,mCAAmC;AAAA,EAE9B;AAClB;AACA,IAAO,sCAAQ;;;AwBTnB;AAwBA,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AzB3ChB,IAAM,iCAAN,MAAoE;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EARS;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,iCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAlBM;AAoBN,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,CACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B;AAAA,IAEA,cAA0B,CAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD;AAAA,IAEA,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": ["extractConclusion", "extractTextStats", "Database", "urls", "content"]
}
